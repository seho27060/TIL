# Load Balancing

## 부하 분산(Load Balancing)

> **부하분산** 또는 **로드 밸런싱**(load balancing)[[1]](https://ko.wikipedia.org/wiki/%EB%B6%80%ED%95%98%EB%B6%84%EC%82%B0#cite_note-:1-1)은 컴퓨터 네트워크 기술의 일종으로 둘 혹은 셋이상의 [중앙처리장치](https://ko.wikipedia.org/wiki/%EC%A4%91%EC%95%99%EC%B2%98%EB%A6%AC%EC%9E%A5%EC%B9%98 "중앙처리장치") 혹은 [저장장치](https://ko.wikipedia.org/wiki/%EC%A0%80%EC%9E%A5%EC%9E%A5%EC%B9%98 "저장장치")와 같은 컴퓨터 자원들에게 작업을 나누는 것을 의미한다. - 위키 백과

- 많은 작업량을 분산하여 처리하는 분산시스템
  
  - 유저에서 요청을 받는 User Facing Server가 한개이면 많은 유저 트래픽을 감당하지 못하는 문제가 발생한다.
  
  - 단일 실패 지점(Single Failure Point)이기 때문이다. 이때 User Facing Server가 죽는다면 고치기 전까지 서비스는 먹통이 된다.

- 한 서버의 성능을 높이는 **스케일업(Scale-up)** 의 한계를 보완하여 **스케일아웃(Scale-out)** 작업시에 적용된다.

### 부하 분산 장치(Load Balancers)

- 응용 프로그램 서버가 모인 클러스터에서 네트워크 트래픽을 분산해 주는 장치
  
  - 서버 클러스터와 네트워크 허브 사이에 위치한다.

- 서버에 업무를 분산시켜서 특정 응용 프로그램 서버의 병목(bottleneck) 현상을 예방한다.

- 응용 프로그램 서버의 상태를 지속적으로 감시하여 사용 가능한 서버에만 트래픽을 보낸다. -> 신뢰성과 가용성 확보

- 부하 분산 장치의 종류
  
  - 하드웨어 부하 분산 장치 : 부하 분산을 위해 설계된 하드웨어 장치. 
  
  - 소프트웨어 부하 분산 장치 : 다목적 컴퓨터에서 수행되는 로직으로 하나의 프로그램

### 부하 분산과 네트워크 계층

- OSI 7 Layer Model

- 부하 분산 장치가 트래픽을 검사하고 응용 프로그램 서버로 라우팅할 때 Network Layer(3계층)나 Transport Layer(4계층), Application Layer(7계층)에서 작동한다.

#### Layer 4, Transport

- 클라이언트로부터 TCP 패킷을 받아 부하 분산 방식에 따라 백엔드 서버로 전달

- TCP 패킷만 확인하기 때문에 가장 비용이 적은 방식

#### Layer 7, Application

- HTTP 메시지 헤더를 기반으로 라우팅

- TCP패킷 뿐만아니라 HTTP헤더의 내용도 확인한다.

- 로드 밸런서가 다양한 클러스터에 연결할때, HTTP헤더의 내용에 따라 각기 다른 부하 분산 방식을 사용하여 트래픽을 할당할 수 있다.

- 상위 계층에서 작동하므로 하위 계층의 L4 로드밸런서의 기능을 포함한다.

### 부하 분산 방식 및 알고리즘

#### L4 로드밸런싱

1. Round Robin(라운드 로빈) : Uniform Load Distribution으로, 모든 서버에 각각 1개의 요청씩 순차적으로 보낸다.

2. Weighted Round Robin(가중 라운드 로빈) : 각 서버에 보내는 트래픽의 양을 조절하여 보낸다.
   
   - 각 서버에 가중치를 할당하고 그에 따라 트래픽을 할당한다.
   
   - 각 서버의 하드웨어의 성능이 다르거나, 버전 업데이트 등으로 서버간 차이가 발생할때 사용한다.

3. Source IP Hash Motivation(소스 IP 해시) : 트래픽 분산 중 특정 사용자의 요청을 특정 서버에만 할당하는 방법
   
   - 장바구니와 같이 한 서버와의 세션을 유지해야 하는 경우
   
   - 요청에 대한 IP를 한개의 서버에 연결하여 요청을 분산, 유지한다.
- 문제 상황
  
  - 라운드 로빈 로드 밸런서에서 서버 1에는 적은 자원의 요청, 서버 2와 서버 3에는 많은 자원의 요청이 갈 경우. 모든 트래픽을 동일하게 분산하였다 하여도 **각 요청에서 요구하는 자원**이 다를 수 있다.
  
  - 위 3개의 방식은 모두 각 서버의 상황, 요청마다 다른 요구 자원 등을 고려하지 않았으므로, 이는 곧 클러스터 전체의 과부하를 불러 일으킨다.
  
  - 각 서버의 작업량을 적극적으로 모니터링하는 아래와 같은 해결책이 필요하다.
4. Least Connection(최소 연결) : 모든 서버가 처리할 요청이 이미 많은 상태로 인지한다.
   
   - 각 서버의 연결을 측정하여 가장 적은 연결을 갖는 서버에 작업을 할당한다.
   
   - 가장 작은 연결은 적은 부하를 갖는 서버로 인지함

5. Weighted Response Time(가중 응답 시간) : 각 서버에 주기적으로 상태 확인 요청을 보내 서버의 응답 시간을 측정한다.
   
   - 서버마다 측정된 응답 시간을 기반으로 부하 분산 알고리즘은 서버마다의 **가중치를 조정**한다.

6. Agent Based Policy(요원 기반 정책) : 요원(Agent)를 활용하여 백그라운드에서 서버의 부하를 모니터링한다.
   
   - CPU 사용률, 네트워트 트래픽의 요청과 응답, 디스크 작의 개수, 메모리 사용량 등등등
   
   - 자체적인 성능값을 측정하여 이를 기반하여 각 서버(노드)에 **최적의 작업량을 할당**한다.

#### L7 로드밸런싱

1. URL 스위칭(URL Switching) : 특정 하위 URL들을 특정 서버로 처리한다.
   
   - 특정 URL을 서버가 아닌 별도 스토리지의 객체 데이터에 바로 연결하는 방법

2. 컨텍스트 스위칭(Context Switching) : 클라이언트가 요청한 특정 리소스에 대해 특정 서버로 연결한다.
   
   - 이미지 파일에 대한 요청의 확장자를 참조하여 별도로 구정된 이미지 파일이 있는 서버/스토리지로 연결

3. 쿠기 지속성(Persistence with Cookies) : 쿠키 정보를 바탕으로 클라이언트가 이전에 연결했던 동일 서버에 계속 할당한다.

---

- 레퍼런스

> [Java 를 활용한 분산 시스템 및 클라우드 컴퓨팅](https://www.udemy.com/course/java-distributed-system/)
