[TOC]

# 마이크로서비스 아키텍쳐 : 패턴과 핵심 기술, MSA(MicroService Architecture)

- udemy 강의 참고

## Section_00

### Section Detail

#### index1

##### detail-index1

## Section 01. MSA 소개

### MSA의 등장 배경

- 점차 크기가 증가하는 모놀리식 서비스의 한계
  
  - 배포시 마다의 부하 증가
  
  - 몸집이 커지는 서비스의 복잡함을 예측할 수 없음

- 각 도메인 별로 여러 분리된 서비스(seperated serviecies)의 결합

## Section 02. MSA 개념과 주요 특징

### MSA 소개 : 전통적 개발 방법론 및 Monolithic 소개

- 전통적으로 전체 기능을 단일 코드베이스로 개발

- 대규모로 단일 코드베이스로 구성된 서비스의 빌드/배포

#### Monolithic System 장점과 단점

##### 단점

- scale out 시 전체 시스템을 확장해야 하는 비효율
  
  - == 필요한 부분(기능)만 scale out이 안됨

- 빌드/배포 시간의 비효율적 소모

- 작은 수정에도 전체 시스템 빌드/배포
  
  - 시스템자체가 크다보니...부하가 매우 큼

- 서비스 자체 내부에서 결합도가 매우 커 기능간 의존관계가 매우 큼
  
  - 유지보수간 수정에 복잡도 증가

- 결국 민첩한(agile) 배포가 불가함.

##### 장점

- 상대적으로 운영에 용이함

- 트랜잭션 관리가 쉬움

#### Monolithic System의 종류

- Single Monolithic System
  
  - 가장 일반적인 형태

- Modular Monolith
  
  - 모듈화된 구성
  
  - MSA의 좋은 대안(된다면)
  
  - 모듈간 결합도 검증을 주기적으로 점검해야함

- Distributed Monolithic System
  
  - 분산된 Monolith
  
  - 코드베이스가 분리되었지만, MSA가 아님
    
    - 코드베이스가 분리되었지만, 서로간 결합이 강하여 자율적 빌드/배포가 불가한 상황

#### Always truths

- 상황과 자원에 적합한 대안이 존재하는 것이지, 항상 맞는 정답은 없다.  

### MSA 개념, 장점, 단점

- MicroService Architecture
  
  - 애플리케이션을 자율적인 다수의 서비스로 분리 개발
  
  - 분리된 서비스는 HTTP와 같은 네트워크를 통해 통신
  
  - 분리된 서비스는 자율적 빌드/배포 가능

- MSA의 부각 이유 
  
  - 요구사항의 빠른 반영 필요
  
  - 다양한 영역에서의 IT 기술 적용
  
  - Cloud, Docker, k8s, Netflix OSS 와 같은 기술적 지원의 증가

#### 장점

- 빠른 Delivery
  
  - 각 서비스들의 독립적 개발, (네트워크 통신에 의한) 느슨한 결합

- 탄력적, 선택적 확장
  
  - 필요한 부분의 서비스만 수정
  
  - 확장 역시 필요부분에 한정되므로 비용 감소

- Polyglot Architecture 지원
  
  - 서비스별 적절한 기술(프로그래밍 언어, 프레임워크 등) 선택 가능

- 실험과 혁신 가능성
  
  - 기술의 혁신이 필수적인 급변하는 비즈니스 시장에서 기술 시험 또는 기술 부채 해결에 용이함

- 대체 가능성
  
  - 기존 서비스에 사용된 언어/프레임워크를 새롭게 개발 가능
  
  - 서비스간 결합도가 낮으므로 용이함
  
  - 3-4명의 개발자가 2주만에 개발할 수 있는게 적절한 사이즈(정답은 없다)

- 기술 부채 경감
  
  - 기술적 변경/교체 가능성이 높아 기술 부채 해결에 용이함

#### 단점

- 컴퓨팅 자원의 비효율성

- 운영관리의 어려움(모니터링 대상 증가)

- 좀 더 다양하고 복잡한 장애 상황 발생

- 단위 테스트 컴포넌트 테스트 난이도 증가

- DB 트랜잭션 처리 어려움
  
  - 분산환경에서의 트랜잭션 난이도 증가

### MSA 주요 특징

- 서비스 기반 컴포넌트화

- 분산된 거버넌스/ 데이터 관리

#### 서비스를 통한 컴포넌트화

- MSA에선 서비스 단위를 컴포넌트로 정의
  
  - 특정 비즈니스 기능 담당
  
  - 독립적 프로세스

#### 비즈니스 역량에 따른 조직 구성

- Conway의 법칙 : 시스템을 설계하는 조직은 그 조직의 소통 구조를 닮은 아키텍쳐를 만든다

- 전톻적인 기술에 따른 조직 구성(DB, BE, FE등 기술로만 이뤄진 팀으로 조직이 구성)

- 서비스에 따른 조직 구성(1개 서비스를 위한 여러 역량을 팀 내부에서 갖춤)

- 개발부터 운영까지 이어지는..devOps

#### 분산된 거버넌스/ 데이터 관리

- 중앙에 강력한 표준, 절차 준수가 강요되지 않음

- 스스로 효율적인 방법론과 도구, 기술을 찾아 적용

- 단일 통합 데이터베이스가 아닌, 서로 각각의 데이터베이스를 갖음

- 다른 서비스 데이터를 접근시에는 API를 활용함

#### 인프라 자동화

- 다수의 서비스, 인스턴스가 운영되므로 인프라 자동화가 필수적

#### 장애 방지 설계

- MSA의 경우 특정 서비스의 장애가 전체 서비스 장애로 전파될 수 있음

- 서비스의 이상 동작 감지에 민감해야 함

- 가능하다면 "자동 복구"가 가능하도록 설계되야함.

## Section 03. MSA 도입을 위한 역량 및 필요조건

### MSA 도입 조건

- 사업/ 조직적 측면
  
  - MSA가 중장기적 business benefit을 올릴 수 있는가?
  
  - 고위 경영진의 확고한 의지
  
  - MSA 전환은 코드뿐만 아닌 조직과 프로세스의 개선 작업 필

- 기술적 측면
  
  - Rapid Provisioning : 클라우드 환경, Docker/K8s를 통한 인프라 자동화
  
  - 정교한 Monitoring 및 장애관리
  
  - 자동화 된 배포

- MSA 도입 시기
  
  - MSA 도입 비용이 크다는 점 인식
  
  - Monolith의 단점들이 Business에 부정적 영향이 너무 클 때

- 던져봐야 할 질문
  
  - SW 관련 현재 조직의 문제 및 목표는 무엇?
    
    - 단순 신기술이라는 이유로 도입하는건 아니지
  
  - MSA가 현재 조직의 문제와 목표를 해결해줄 수 있는가?
  
  - 

### MSA 역량 모델 Part 1

#### MSA 서비스 역량 모델

- 획일화된 모델이 없음

#### 역량 분류

- 핵심 역량 - 서비스 별 배포되는 SW 패키지 필수 요소
  
  - 서비스 Listener - HTTP 등 Listener가 애플리케이션에 내장 되어야함
    
    - Spring => SpringBoot 와 같은 자체 내장 Endpoint 
  
  - Endpoint - Application
  
  - 서비스 구현 - 단일 책임 원칙을 지키는 높은 응집도
    
    - Hexagonal Architecture : 외부 시스템(인프라, DB)가 무엇이든 간에 비즈니스 핵심 로직은 영향받지 않아야 한다.
  
  - 데이터 저장(DB) - 데이터소스는 하나의 서비스에 한정되야 한다.[]()

- 지원 역량 - 지원 기술 및 설계 패턴

- 인프라 역량 - 컨테이너 및 컨테이너 오케스트레이션
  
  - 클라우드 - On Demand로 적은 공수로 리소스 프로비저닝 가능
  
  - 컨테이너 런타임 - Docker를 통한 컨테이너 구성
  
  - 컨테이너 오케스트레이션 - 많은 수의 컨테이너 관리 역량
    
    - 배포, 모니터링 등 운영 관리 비용 최소

- 프로세스 및 통제 역량 - DevOps 및 문서화 등

### MSA 역량 모델 Part 2

#### 지원 역량

##### Service Discovery

- MSA 도입 시 서비스 개수 및 인스턴스 개수 급증

- 어떤 서비스가 다른 서비스의 물리적인 정보(ip, port)들을 유지하는 건 비효율적

- 따라서 중앙에서 시스템의 모든 서비스에 대한 정보를 유지하여 서비스들은 다른 서비스를 호출시 필요한 정보를 중앙에서부터 불러와 사용함
  
  - 서비스의 정보가 변경되어도 중앙에서 관리되므로 MSA에서의 많은 변경에도 문제없이 호출 가능하도록 한다.

##### Config Server

- 모놀리식에서는 설정 정보를 자체 설정 파일이나 OS 환경변수로 관리

- MSA에서는 설정 관리가 복잡해진다
  
  - 20개 서비스 \* 5개 환경 => 100개 설정 파일 필요

- 환경마다 새롭게 빌드/패키징
  
  - 서비스 100개면 100개 모두 재배포 필요

- 설정 정보를 Application 파일에서 완전히 분리한다.
  
  - 중앙 Config Server에서는 설정 관리한다.
  
  - 서비스는 Application 실행시 중앙서버에서 Config 불러와 사용

##### API Gateway

- 다양한 서비스들에 대한 단일 진입 점

- 인증, 인가, 로깅, 필터링 등 공통 처리 수행

- 다양한 요청을 받아 분류하여 각각의 서비스에 전달

##### SW Defined Load Balancer

- MSA에서는 인프라 토폴로지가 매우 복잡하여 전동적 로드밸런서는 사용이 비효율적

- 서비스를 호출하는 클라이언트에서 SW로 로드밸런싱을 하는 방법
  
  - 클라이언트(서비스 A)에서 내재된 SW가 로드밸런

##### Circuit Breaker

- 서비스의 장애를 대응 가능한 장애 방지 설계

- MSA에서는 1개 서비스 장애가 전체로 이어질 수 있다

- 특정 서비스의 장애는 해당 서비스의 장애로만 격리되어야만 한다.
  
  - 서비스간 서킷브레이커가 서비스간 장애 발생을 판단하여 Circuit을 차단한다.

##### Distributed Tracing

- 분산 추적

- 한개 API 호출 시 다양한 서비스에 분산되어 에러 추적이 어렵다

- 서비스간 모든 호출에 추적 ID를 삽입하여 단일 API 트랜잭션의 활동을 파악

##### Data Lake

- MSA에서는 데이터 파편화 가능성이 존재한다.

- 비정형 원시 데이터를 그대로 저장
  
  - Hadoop, HDFS와 같은 대용량 처리 기술 활용
  
  - 데이터 분석이 필요시에 데이터 가공에 대한 고민

- 전통적 ETL이 아닌 실시간 Data Ingestion 활용
  
  - ELK

##### Messaging

- MSA는 메시징을 이용한 서비스 간 협력 설계 방식 권고

- 메시징(이벤트) 주도 설계는 서비스 간 결합도를 낮출 수 있다

- 고가용성 메시징 솔루션 활용
  
  - RabbitMQ, Kafka

#### 프로세스 및 통제 역량

##### DevOps

- 애자일과 같이 DevOps는 MSA 성공을 위한 필수 요소

- 자동화된 CI/CD, QA

- DevOps 조직 구성되어 한 팀에서 개발, 배포, 운영, 모니터링이 되어야 함

##### 자동화 도구

- 다양한 형태의 다수 서비스를 테스트, 배포, 운영해야 하므로 자동화할 수 있는건 해야한다.

##### 컨테이너 레지스트리

- MSA에서 필수적인 컨테이너 사용

- 컨테이너 핵심인 이미지 관리
  
  - Docker Hub, GCR,...

##### 문서화

- 빠른 변화에 대응하는 인터페이싱 제공 문서

- 웹으로 열람 가능해야함
  
  - REST Docs, Swagger 

##### 참조 아키텍처 및 라이브러리

- 탈중앙화된 MSA는 비효율성을 야기할 수 있다.
  
  - 서로 다른 아키텍처로 인한 유지 보수성 약화

- 조직의 기술 별 참조 모델 중요
  
  - 참조 아키텍처는 프레임워크화
  
  - 또는 사용 기술(버전, 도구)의 통일

### MSA 성숙도 모델

- 조직의 성숙도 상태 진단

- 현재 우리의 단계는 어디인가 판단하는 모델
  
  - 다음 단계로 무엇을 해야하는지 가이드

- MSA의 표준 성숙도 모델은 없지만 두개의 모델 제안
  
  - Rajesh RV
  
  - Rishi Singh

#### Rajesh RV 제안 성숙도 모델

- Level 0(모놀리식) \~ Level 3(API 중심)으로 구성됨

#### Rishi Singh 제안 성숙도 모델

- 총 9가지 영역에서 4단계의 성숙도 모델 제안
  
  - 4단계 성숙도 : Early, Inception, Expanding, Mature
  
  - Expading은 현실적 MSA => Mature는 이상적 MSA로 보면된다

##### 기능적 분할 영역

- Early : Business 역량에 따른 기능 분할

- Inception : Modular Monolith, 서비스간 명확한 Interface

- Expanding : 도메인 주도 설계에 의한 잘 분할 된 서비스

- Mature : 이벤트 기반의 협력, 조회와 명령의 분할

##### Data 영역

- Early : 서비스 간 저장소 공유, ACID 기반 Transaction

- Inception : 일부 새로운 서비스들에 대한 독립 저장소

- Expanding : 모든 서비스들의 독립 저장소, Polyglot Persistence, Eventual Consistency

- Mature : Event 기반 데이터 관리, Event Sourcing, CQRS

##### Testing 영역

- Early : 수동/자동 Testing 혼재

- Inception : 완전 자동화 된 Testing 수행

- Expanding : Chaos Engineering

- Mature : Consumer Driven Contract, 고객 페르소나 기반 E2E Testing

##### Infrastructure 영역

- Early : CI/Build

- Inception : CD, 중앙 집중형 Logging

- Expanding : Container/Orchestration

- Mature : 완전 자동화 된 Provisioning 지원하는 Paas

##### Deployment 영역

- Early : Script 기반, 호스트 당 다중 서비스 배포

- Inception : VM 당 단일 서비스 배포

- Expanding : Container 당 단일 서비스 배포, Immutable Infra, Blue/Green Deployment

- Mature : Multi-Datacenter 배포

##### Monitoring 영역

- Early : APM

- Inception : Centralized Logging System

- Expanding : Container Monitoring

- Mature : Distributed Tracing, Trace as a Service, Synthetic Transaction

##### Governance 영역

- Early : 중앙집중화 된 Governance

- Inception : 일부 Monolith, 일부 Microservices의 Shared Governance Model

- Expanding : 완전 분산 Governance

- Mature : 참조 아키텍처 및 참조 방법론 등 지원
  
  - Expanding에서 완전 분산되고 다시 Mature에서 중앙집중되는 흐름

##### Team Sttructure 영역

- Early : Dev, QA, Ops 등 기술 별 조직

- Inception : 일부 Cross Functional 팀

- Expanding : 제품 기반 개발팀과 이를 지원하는 Platform 팀(운영, 모니터링 등)

- Mature : 완전한 제품 기반 DevOps 팀

##### Architecture 영역

- Early : ESB를 사용하는 SOA 기반 아키텍쳐 또는 Modular Monolithic

- Inception : Monolith 시스템에 신규 기능을 MSA로 개발

- Expanding : 모든 비즈니스 기능이 MSA로 분리되어 서로 Network 인터페이싱

- Mature : Event 기반, Serverless

## Section 04: MSA 분리 전략

### MSA 서비스 분리 원칙

#### 서비스 분리 전략

- 단계적 마이그레이션/ 처음에는 크게 추후에는 작게 분리/ 서비스 분리의 "공식"은 없다

#### 작고 분리가 쉬운 서비스로 워밍업

- MSA 성공적 전환을 위한 사전 준비사항
  
  - Cloud, Deployment Pipeline, Container, Monitoring

- 본격적 MSA 분리 전 간단한 서비스 분리하여 역량 내재화
  
  - 한 두개 테스트로 분리하여 인프라 등을 준비
  
  - 작은 Pilot 서비스로 내부 의존성이 가장 적은 기능을 선택한다.

#### 핵심 기능의 분리

- 분리할 핵심 기능의 도메인을 명확하게 해야함
  
  - 비즈니스 팀 구조를 기반으로 분리
  
  - 도메인 주도 설계 적용 : 고객 발생 이벤트를 시작점으로 부터 도메인 분리

- 핵심 기능은 다른 기능들과의 결합도가 높으므로
  
  - 이를 위한 상세한 의존성 분석 과정 필요
  
  - 정적 분석 프로세스(Method Call, Inheritance, Table Join etc)

#### 데이터의 분리

- MSA 전환의 가장 큰 목적 중 하나인 서비스들의 독립적 배포를 위함

- 가장 피해야할 Anti-Pattern 중 하나가 서비스 별 공유 DB를 갖는 것
  
  - 공유 DB의 사용은 서비스간 결합도를 높이게 된다.

- 독립 저장소 및 데이터 Migration 전략 수립이 동반되어야 함

#### 분리 대상 선정

- MSA 전환 첫 단계로 조믹의 목표를 명확하게 수립
  
  - 가장 문제가 되는 기능이 무엇?
  
  - 비즈니스 요구사항 변경이 빈번할 기능?
  
  - 잦은 코드 수정으로 빌드/배포를 유발하는 기능?

- 서비스 내 변경의 관점에서 분리 대상 점검
  
  - 코드 커밋 히스토리를 파악하여 기능 별 빈도 분석
  
  - 프로젝트 로드맵 기반 향후 크게 수정될 기능 선정

#### 코드의 재사용 vs 재개발

- 분리 대상 서비스 확정 후 재사용/재개발 고민 필요

- 재사용의 경우 효율적으로 보이나 많은 문제 발생 가능
  
  - 오랜 기간 유지보수된 코드의 예로
  
  - 기술 부채 또는 오래된 기술 자체
  
  - 그 동안의 수없이 반영된 요구사항으로 현재 코드들이 현재 비즈니 도메인이 명확하게 반영되지 않을 가능성이 있다

- 재작성의 경우
  
  - 요구사항을 다시 파악하여 기능에 대한 비즈니스 도메인 명확화 가능

#### 진화적인 서비스 분리

- 서비스 분리 시 가장 큰 고민 중 하나가 분리될 서비스의 크기

- 원칙 : Go Macro, Then Micro
  
  - 우선 크게 분리하고 필요한 경우 재설계를 통해 더 작게 분리

- 서비스 크기가 너무 커도, 너무 작아도 문제이므로 반복적인 과정으로 진화적인 서비스 분리가 이뤄져야 함

- 서비스 크기에 대한 휴리스틱
  
  - Tow Pizza Team : 피자 2판으로 개발/운영이 가능한 서비스 크기
  
  - 한 사람의 머리로 전체 관리 가능한 수준
  
  - 2주 안에 완전 재작성 될 수 있는 수준

#### 반복/ 점진적 분리

- 전체 Monolith => MSA 전환은 길고 비용이 많이 드는 여정

- 크고 원대한 목표와 계획은 실패할 가능성이 높으므로, 작고 명확한 계획의 여러 단계 추진이 유리

- 한번에 하나씩 단계적으로 분리
  
  - The only thing a Big Bang re-architecture guarantees is a Big Bang! - Martin Fowler

- MSA 전환 중 클라이언트로부터의 Request를 신규 서비스로 전환

- Monolith에서 Method 호출하던 의존성을 모두 신규 서비스로 전환

#### MSA와 함께 신기술의 도입

- MSA는 혁신과 실험을 가능하게 한다만
  
  - 도입 초기의 실험/혁심은 복잡도를 증가한다

- step by step로 진행 필요

#### 서비스 분리와 조직

- 서비스를 분리하여 새로운 서비스를 만들 전담 팀 필요
  
  - 기존 기능을 유지보수하며 MSA 분리까지 하기 어려움

- 기존 모놀리식 기능도 계속 유지보수 되어야 함

- Cross Functional TFT 구성 : 기획, 디자인, 개발, 운영

- 첫 MSA 분리 성공까지 TFT인력은 다른 업무가 없어야 한다.

### 응집도와 결합도 그리고 SRP

- MSA 주요 3개념: 응집도(Cohesion), 결합도(Coupling), 단일 책임 원칙(SRP)

#### 응집도와 결합도

- > A structure is stable if cohesion is highm and coupling low

##### 결합도

- 기능들이 서로 협력하여 전체 시스템 구성 => 완전 독립 기능은 일반적이지 않다.
  
  - 의존성은 항상 존재

- 최대한 의존성을 줄이도록 경계를 짓는 것이 주요 포인트

##### 응집도

- 서로 연관된 부분을 한곳으로 모아 놓은 형태

- 같이 수정되는 부분끼리 수정 후 빌드, 배포를 통해 운영
  
  - 서비스로 분류되어 Microservices 구성을 갖게됨

##### 단일 책임 원칙

- 객체지향 프로그래밍 원칙 중 하나

- 객체는 변경에 대한 이유는 단 한가지여야 한다.

- 서비스 변경 이유는 하나의 비즈니스 영역으로 비롯되어야 한다.

- Refactoring - Code bad smell(잘못된 경우 예시)
  
  - Divergent Change : 한 클래스가 다른 이유로 다른 방법으로 자주 변경되는 경우
  
  - Shotgun Surgery : 변경을 할 때 마다 많은 클래스를 수정하는 경우

### 도메인 주도 설계

#### 분리할 서비스의 식별 전략

- MSA 설계시 서비스를 어떻게 식별하는 가?
  
  - Art(워크샵, 이벤트스토밍) + Science(코드 의존성 분석, 데이터 의존성 분석)

#### 서비스 분리와 도메인 주도 설계(DDD)

- DDD는 MSA의 서비스를 식별하는 도구를 제공
  
  - DDD : Domain-Driven Design

- 도메인 전문가와 개발자간 소통의 필요

- 도메인이란?
  
  - 소프트웨어를 개발하는 대상 영역
  
  - 복잡한 비즈니스나 현실세계의 문제

#### 도메인 주도 설계

- 도메인의 이해를 최우선시하는 모델링 기법

- 개발자가 구축하기 전 도메인에 대한 깊은 이해가 필요

- 도메인, 도메인 모델, 코드를 밀접하게 연관
  
  - 서로간 소통을 위해 "언어"를 통일해야함
  
  - 도메인 모델 : 도메인을 모든 사람이 동일 관점에 이해하고 공유 가능하도록 단순화 한 것

#### Big Ball of Mud

- DDD중 안 좋은 예시

- 요구사항 추출 => 분석 => 설계 => 구현의 단계를 따름

- 계속 추가되는 요구사항

- 우선순위가 높은 것 부터, 낮은 것 까지 하나의 큰 덩어리(설계)로 얽히게 된다.

##### Big Ball of Mud 원인

- 조직에서 SW 설계에 충분한 노력을 들이지 않음

- 개발자는 도메인보다 기술에 너무 몰두, 많은 문제를 기술적으로만 해결하려 함

- 도메인의 이해없이 개발자 상상속의 추상화가 설계 됨

- 결과적으로 도메인 전문가의 멘탈 모델과 실제 구현체 사이의 큰 차이를 야기한다.

#### 어떻게 도메인 탐색, 언어 구축?

- 도메인은 만드는 것이 아닌, 이미 있는 것을 탐색하고 식별해내는 것

- 반복적인 탐색(또는 도메인 전문가, 개발자간 소통)을 통해 도메인 모델을 정제해가야 한다.

#### 도메인 주도 설계의 세부 개념

- 전략적 설계
  
  - 유비쿼터스 언어의 정의
  
  - 바운디드 컨텍스트의 식별

- 전술적 설계
  
  - 도메인을 코드로 구현하기 위한 상세 패턴의 적용

#### 전략적 설계

- MSA 도출을 위해 비즈니스 상 전략적으로 중요한 것을 찾아 중요도에 따라 분류하는 단계

- 두가지 주요 개넘
  
  - 유비쿼터스 언어 : 도메인 전문가 - 개발자가 공통으로 사용하는 언어
  
  - 바운디드 컨텍스트 : 도메인을 분류하고 그 사이를 절충하는 경계

##### 전략적 설계의 필요성

- 애자일 프로젝트 관리 시스템의 개발 사례

- 애자일 작업 중 추가되는 요구사항으로 Ball of mud를 일으킴

#### 서브 도메인

- 전체 비즈니스 도메인을 이해 가능한 하위 영역으로 분리
  
  - 핵심 서브도메인: 다른 경쟁자와 차별화를 만들 수 있는 비즈니스 영역
  
  - 지원 서브 도메인: 비즈니스에 필수적이지만, 핵심은 아닌 영역
  
  - 일반 서브 도메인: 시스템에 필요하지만 큰 공부를 들일 필요없는 영역

- 분리한 영역의 우선 순위를 확인하여 투자의 정도를 결정

- Problem Space : 해결해야 하는 도메인 - 서브 도메인들의 집합

#### 바운디드 컨텍스트

- 같은 의미를 갖는 동일한 맥락의 경계 또는 범위
  
  - 유비쿼터스 언어로 표현 됨

- Solution Space : 해결책을 실제 구현 - 바운디드 컨텍스트들의 집합

#### 유비쿼터스 언어와 바운디드 컨텍스트

- 상품을 Product라는 1개 테이블과 1개 클래스로 설계한다면?
  
  - 컨텍스트 경계가 사라져 의미가 모호해진다

- 여러 컨텍스트가 걸쳐져 혼란을 야기할 수 있다
  
  - User, Member, Account가 하나의 domain 패키지로 관리되는 경우

- 각 문맥별로 한 개념의 이름을 명확하게 재정의할 필요가 있다
  
  - 카탈로그 컨텍스트의 상품은 Product
  
  - 재고 에서는 Stock
  
  - 주문에서는 OrderedItem

- DDD에서는 비슷하지만 서로 다른 개념들을 각기 다른 바운디드 컨텍스트 내부로 분리한다.

- 명확하게 재정의된 개념들은 각각의 바운디드 컨텍스트 내부에서 분류, 이는 MSA 설계에 우선순위를 선정할 수 있다.

### Microservice 분리 프로세스

#### 서비스 분리 프로세스

- 프로세스
  
  1. 후보 서비스 도출 : 위크샵으로 분리 대상 서비스 후보 선정
  
  2. 분리 준비 : 자동화 테스트 준비/ 불필요 개체 제거/ 의존성 분석 재점검
  
  3. 의존성 분석 및 서비스 확정 : 분리 대상 기능들의 외부 의존성 분석/ 분리 대상 기능 확정
  
  4. 서비스 분리 : 분리 대상 기능의 코드들을 패키지 모듈화/ 기존 시스템-분리 대상 서비스 간 호출 관계 수정/ 데이터베이스 분리/ 신규 서비스의 독립 프로젝트 구성

##### 분리 대상 서비스 후보 선정

- 워크샵(모든 이해 관계자가 참여하는 정성적 도메인 도출)을 통해 서비스 분리 대상 후보 선정

- 동시에 실제 코드/데이터 레벨에서 의존성 분석 실행

##### 자동화 테스트 준비

- MSA는 일종의 SW Reengineering
  
  - SW Reengineering : 기능의 변경없이 SW 내부 구조를 변경하는 활동

- 코드 수정에도 기능이 변경되지 않았음을 증명하는 유일한 방법 테스트

- 테스트 케이스가 없다면
  
  - 의존성을 분석하여 분리 대상 기능을 중심으로라도 테스트 케이스 작성

##### 불필요 개체 제거

- 코드를 최대한 Compact하게 재작성하여 복잡도를 최소화

- 정적분석을 통한 미사용 개체 도출 및 제거
  
  - 미사용 개체는 불필요한 의존성을 생성

##### 분리 대상 후보들의 의존성 분석

- 정적 분석 툴 등을 사용하여 결과 도출

- 도출 결과에 따라 같은 맥락을 갖는 기능끼리 패키지로 분류
  
  - 분류된 패키지간 의존성을 리스트업하여 재분류

- 데이터베이스 또한 의존성분석이 필요
  
  - 테이블 간 외래키 분석, 제약 조건 분석 등 진행

##### 분리 대상 기능 확정

- 워크샵

- 의존성 분석 결과 공유 및 분리 기능 확정

- 각 의존성의 개수 및 형태 공유

- 데이터베이스 의존성 결과 공유

##### 분리 대상 기능 코드 패키지 모듈화

- 새로은 브랜치에 분리 대상 기능을 패키지로 모듈화

- Domain 객체, 공통 유틸, 상수에 대한 의사 결정 필수

##### 기존 시스템과 분리 대상 서비스의 호출 관계 수정

- 기존 시스템과 분리 대상 서비스의 의존 분석

- 메소드 호출을 REST API등의 호출로 변경

- 완전 분리전에는 동일 서버 호출하도록 유지

##### 데이터베이스 분리

- 서비스 별 스키마/ 서비스 별 데이터베이스/ Polyglot 서비스 베이스 등으로 결정

- 외래키, 제약조건, 트랜잭션 제거/ Join을 애플리케이션 Join으로 변경
  
  - 트랜잭션의 경우 가능한 경우의 시뮬레이션

##### 신규 서비스를 독립 프로젝트로 구성

- 새로운 독립 프로젝트 생성

- 패키지로 취합한 파일들을 새로운 프로젝트로 복사

- 기존 시스템과 신규 서비스간 호출 정보 수정

- 테스트 및 배포

## Section 05: MSA를 위한 기술

### Spring Boot와 Spring Cloud

#### Spring Framework

- Spring - Spring Boot
  
  - Auto Configuration
  
  - 
  
  - Autuator

#### Spring Cloud

- MSA 최적화 개발을 위한 오픈소스

- 분산 환경에 적용 가능한 다양한 아키텍처 패턴 구현

- 기존 Spring App과 쉽게 호환됨

##### Spring Cloud와 Netflix OSS

- Netflix OSS는 Netflix에서 MSA를 운영하면 쌓아온 노하우를 오픈소스로 공개

- Spring Cloud와 통합된 Spring Cloud Netflix 제공

#### Spring Cloud의 한계

- Java 만 주로 사용 가능

- MSA는 Polyglot Architecture를 권장

- 대안으로 Kubernetes, Istio등의 조합 사용 가능

### Container와 Docker

#### Container

- 외부 환경으로부터 격리된 프로세스

- Application을 표준화 된 단위로 패키징하여 동일 방법으로 배포하기 위한 기술

- Application Code뿐만 아니라 외부 환경을 하나로 패키징
  
  - Runtime, Libraries, Configuration..etc

- 인프라의 가변성은 환경에 영향을 끼치고, 어플리케이션 실행은 환경에 영향을 받는다.
  
  - Application이 의존하는, 주위 환경의 차이를 없애면 실행간의 차이를 줄일 수 있다

#### Docker

- 컨테이너 기반의 오픈소스 가상화 플랫폼

- 다양한 프로그램, 실행환경을 컨테이너로 추상화하여 동일 인터페이스를 제공

- 프로그램의 배포 및 관리를 단순하게 한다.

##### Docker 특징

- 높은 확정성

- OS환경, 클라우드 벤더 등에 종속적이지 않음

- 쉽고 빠르게 서버 환경 구축 가능

- 서로 다른 언어로 구성된 어플리케이션들을 동일한 방식으로 실행 가능
  
  - Docker container run 과 같은 명령어

- 재현 가능한 이미지 
  
  - 기존의 가상 머신 이미지는 재현이 어려우나, Docker에서는 Dockerfile이라는 파일로 이미지를 어떻게 만드는지 재현 가능하다.

##### 컨테이너

- 격리된 공간에서 프로세스가 동작

- 가상화 기술의 하나지만 기존 방식과는 차이가 있다

- 기존의 가상화 방식은 주로 OS를 가상화하나, 호스트 OS위에 게스트 OS 전체를 가상화하여 사용하는 방식

##### 이미지

- 컨테이너 실행에 필요한 파일, 설정 등 포함

- 컨테이너는 이미지를 실행한 상태

- 같은 이미지에서 여러 개의 컨테이너를 생성

##### 이미지와 컨테이너

- 이미지 : 실행 어플리케이션 및 미들웨어의 정보를 담는 스냅샷

- 컨테이너 : 이미지를 실행시킨 인스턴스

- 이미지 : 컨테이너 => Java Class : Object

- 1개 이미지로 여러개의 서버를 동일한 환경으로 실행 가능

### Container Orchestaration을 위한 Kubernetes

- 쉽게 확장이 가능한 컨테이너의 경우, 그 수가 너무 많기 때문에 수동으로 관리가 어렵다.

- 대규모 분산 환경에서 수 많은 컨테이너를 관리하기 위한 도구

#### Kubernetes 특징

- 멀티 호스트에서 컨테이너 관리

- 컨테이너 배포 및 서로 간 네트워크 관리

- 컨테이너 감시, 업데이트

- 장애 발생 시 자동 복구

#### Kubernetes 철학

##### Immutable Infrastructure

- 기존에는 서로 다른 시기에 구매한 장비들을 유지 보수하며 상태 관리

- 클라우드 환경에서는 자원들을 간단하게 구축하거나 파기 가능
  
  - 한번 구축한 인프라를 수정하지 않고 파기

- 원하는 상태를 만들어서 새로운 환경을 구축

- 예시로, Java Version을 올려아하는 경우 기존에는 서버에 접속하여 명령어로 업데이트 진행했으나
  
  - Immutable Infra 방식은 업데이트 된 이미지를 생성하여 새로운 서버를 구축하여 컨테이너 배포/ 기존 서버는 파기

##### Declarative Configuration

- 명령형 : 프로세스를 명시하여 순차적으로 진행/ 선연형 : 특정 상태의 단계를 명령
  
  - k8s에서는 pod 3개로가 선연형/ pod 3개 추가 가 아님

- 원하는 상태를 기술하여 k8s에 적용
  
  - 원하는 상태 = 시스템이 되야하는 모습

- Desired State : k8s클러스터의 원하는 상태
  
  - 어떤 컨테이너들이 어떤 노드에 실행되는지
  
  - 현재 상태를 실시간 모니터

##### Self Healing

- 장애 발생 시 자동으로 복구

- 사람의 개입을 최소

### Kubernetes 구조와 Objects 소개

#### k8s의 구조

- Master에 API서버와 상태 저장소를 두고

- 각 서버(node)의 에어전트(kubelet)와 통신하는 구조

##### Master

- k8s 클러스터를 관리

- 노드 상태 파악

- 컨테이너를 어떤 노드에서 가동할지 선택

- etcd 분산 저장소를 사용하여 클러스터의 정보를 저

##### API 서버

- 모든 요청을 처리하는 마스터의 핵심

- 모든 컴포넌트는 API 서버를 통해 소통

- 인증 및 인가 기능도 보유

##### 스케줄러

- 컨테이너를 어떤 노드에 가동할지 결정하는 컴포넌트

- 노드들의 정보를 파악하여 컨테이너를 가동할 노드 선택

##### 컨트롤러 매니저

- k8s클러스터 상태 감시

- desired state를 유지하는 감시

- 실시간 감지로 상태가 예상과 다를 경우 적절한 조치 수행

##### 분산 데이터 저장소 etcd

- 분산 key-value 저장소

- 클러스터의 모든 설정, 상태 데이터 저장

- 스케줄러, 컨트롤러 매니저들이 API 서버 통해 etcd의 데이터 조회 및 갱신

##### 노드

- 컨테이너가 가동되는 서버

- 다수의 노드로 클러스터 구성

- 클라우드의 경우 가상머신이 노드가 됨 
  
  - ec2

##### kubelet

- 컨테이너를 실제로 생성하는 주체

- 마스터로부터 생성 요청을 받으면 컨테이너 생성

- 컨테이너의 상태를 감사하는 역할

- 컨테이너의 상태를 API 서버로 전송

##### kube proxy

- 각 노드에서 실행되는 네트워크 프록시

- 노드의 네트워크 규칙 유지 관리

#### k8s Object

- 대규모 분산환경에 필요한 요소들이 추상화되어 있음

- 컨테이너, 애플리케이션 수행 방식, 네트워크 등을 추상화한 것

- Application 및 배포/ 네트워크/ 설정 정보 관리/ 배치 잡 관리 등 동작하는 것들

##### Pod

- k8s에서 배포할 수 있는 가장 작은 단위

- 한 개 이상의 컨테이너와 스토리지, 네트워크 속성을 가짐

- 1개 pod에 속한 컨테이너는 스토리지와 네트워크를 공유하고, 서로 localhost로 접근할 수 있다.

- 컨테이너를 하나만 사용하는 경우도 반드시 pod로 관리

##### ReplicaSet

- Pod를 여러 개 복제하여 관리

- Pod를 생성하고 개수를 유지하려면 ReplicaSet을 사용해야 한다

- ReplicatSet이라는 복제 개수, 생성 Pod의 설정 정보를 포함한다.

##### Deployment

- k8s에서 실제 배포를 진행하는 기본 단위

- Rolling과 Recreate와 같은 배포 전략

- 배포 Revision 관리 및 Roll back

- 등 배포와 관련된 다양한 기능과 옵션을 제공 

##### DaemonSet

- 클러스터 전체에 Pod를 띄울때 사용하는 Controller

- 항상 모든 Node에 특정 Pod이 실행됨

- 새로운 Node가 추가되면 자동으로 Pod 실행 됨

- 로그 수집기, 모니터링 에이전트 등을 실행하는 용도

##### StatefulSet

- k8s 대부분 Controller는 stateless

- StatefulSet은 상태를 유지하는 Pod을 위한 Controller

- Volume을 사용해서 데이터를 저장하고 Pod 재기동시에도 유지 가능
  
  - DB에 사용

##### Service

- 네트워크와 관련된 Object

- Pod 간 연결 및 Pod와 외부 네트워크 연결

- ReplicaSet으로 Pod가 여러개 복제됐을 경우 내부 LB

- 내부 DNS에 서비스 등록하여 서비스 디스커버리 역할

- Pod에 대한 L4 LB 수행

##### Ingress

- 외부 트래픽을 받는 Object

- http/ https 등 L7 레벨로 라우팅 규칙, LB 규칙 포함

- Service도 외부 노출이 가능하지만 L4 레벨만 가능

- 일반적으로 k8s 클러스터를 외부로 노출할때 사용

##### Manifest 파일

- k8s에서 선언적 설정을 위한 파일

- YAML 파일로 작성

- 리소스 종류와 원하는 상태 입력

- Master Node로 명세를 제시

### Service Mesh와 Istio

- Service Mesh : MSA 구성에서 수 많은 서비스들이 서로 관계를 갖는 형태
  
  - SW를 배포하는 클러스터와 함께 위치하는 추가 Layer

#### Service Mesh

- Microsevice(Pod)간 통신은 Service Mesh Layer의 Mesh Logic에 따라 진행된다.

- MSA 핵심 중 하나인 Inter Service Communication(내부적 호출)
  
  - 내부적 호출에 대한 표준적인 방법 필요
  
  - 그리고 자동화 된 제어가 필요하나 k8s에서는 제공하지 않는다.

- 서비스간 통신 관리에 필요 요소
  
  - Service Discovery, LB, timeout, retry, routing, circuit breaking
  
  - Spring Netflix Eureka 등 여러 기술이 제공하는 기술이나, Java/Spring 기반이 아니라면 대안이 없다

- Java/Spring 기반이 아닌 Application 레벨이 아닌 Infrastructure레벨에서 구현한 기술이 Istio

#### Istio

- Service Mesh를 구현하는 구현

- Application Code를 거의 수정하지 않고 다양한 기능을 추가할 수 있다
  
  - LB, Traffic Control, Policy Layer, Automatic Metrics-Logs-Traces, Service to Service authentication and authorization

##### Istio Architecture

- Data Plane : 실제 Pod들이 위치한 영역

- Control Plane : Data Plane의 요소들을 관리하는 영역

- Data Plane에 놓인 Pod 속 Service(Container) A가 Service B를 호출하면
  
  - Proxy A가 요청을 가로채고, Service B를 향하는 Proxy B로 송신한다.
  
  - Proxy 간은 LB, traffic 등과 같은 정책을 검토 관리하며
  
  - 이때 Proxy들은 Control Plane에 의해 동작한다.

##### Traffic Management

- 버전 별로 배포 후 Percentage로 Traffic 조정
  
  - 수 많은 Container를 배포 중에 컨테이너 간 버전 차이가 발생 할 수 있는데, 이때 배포 비율에 따라 트래픽 비중을 조정

- 컨텐츠 기반으로도 트래픽 관리 가능

- Client Resilience
  
  - 원격 자원 장애로부터 클라이언트를 보호하는 패턴
  
  - Client-Side LB, Health Check

#### Data Plane

##### Envoy

- 서비스 간 통신 Proxy 기능하는 오픈 소스

- Istio의 핵심이 되는 모듈

- Traffic Management, Telemetry 제공

- 모든 서비스 간 호출은 Envoy Proxy를 통한다.

- Sidecar container로 모든 Pod에 배포된다

- nginx와 같은 High Performance Server/ Circuit Breaking 등과 같은 Advanced Load Balancing/ Telemetry와 같은 Observability를 제공한다.

- Low Level Code로 Istio를 통해 Envoy를 쉽게 사용할 수 있다.
  
  - Istio + k8s 조합으로 사용되며
  
  - Kubernetes CRD(Custom Resource Definition)으로 yaml과 같이 사용할 수 있다.

#### Control Plane

- Galley :k8s manifest 파일을 Istio가 이해할 수 있는 구조로 변환하는 모듈

- Pilot : 설정 정보를 Envoy Proxy가 이해할 수 있는 형태로 변환
  
  - 설정 정보를 Envoy Proxy들에게 전파
  
  - 사용자는 Envoy의 복잡한(Low Level) 설정에 대해 알 필요가 없어진다.

- Citadel : TLS 인증서 관리 역할
  
  - 클러스터 내부에 TLS/SSL을 적용하여 정책을 통일할 수 있다.

- Mixer 
  
  - Policy Check, Telemetry의 기능을 제공
  
  - Policy Check : Rate limiting(특정 서비스 호출 초당 제한), white list, black list 제공
  
  - 다양한 백엔드를 연동 가능한 Adopter 제공

## Section 6: MSA를 위한 아키텍쳐 패턴

### 서비스 디스커버리 패턴의 이해

#### 서비스 디스커버리

- MSA와 같은 분산 환경에서는 Network를 통한 API 호출이 필수
  
  - 보통 서비스 호출을 위해 위치 정보(IP, Port, URI)를 알아야 한다

- 전통적인 구조에서는 서비스의 위치 정보는 고정적이다.

- Cloud 기반의 MSA 환경에서는 모든 것이 변화한다
  
  - 인스턴스의 개수, IP 등이 Scale Out, Fail Over, Upgrade 등으로 지속적으로 변화된다.
  - 이러한 환경에서 클라이언트는 변화하는 서비스의 위치정보를 알아야 한다.

##### MSA에서 서비스 디스커버리의 중요성

- 새로운 인스턴스들이 언제든 추가되거나 제거된다

- 물리적 위치를 정적으로 저장하는 방식(Cofig 파일)은 비효율적

- 따라서 서비스의 물리적 위치를 몰라도 호출이 가능해야 한다.
  
  - 서비스의 논리적 이름만으로도 호출 가능
  
  - MSA 내 인스턴스의 변화에도 유동적으로 호출이 가능해진다.

##### 서비스 디스커버리 종류

- Client-Side Service Discovery

- Server-Side Service Discovery

##### Client-Side 서비스 디스커버리

- Client가 원격 자원의 주소 정보를 조회하고 유지

- Client가 Service Regisitry로부터 서비스들의 주소 정보 조회
  
  - 각각의 Microservice(인스턴스)들은 Service Registry에 정보 등록
  
  - Client는 원하는 Service 정보를 조회하고 이를 기반으로 Service 호출
  
  - 이외로도 Service Resitry에 등록된 인스턴스 정보를 통해 LB 동작
  
  - 또는 Health Check를 통해 호출 유무를 결정하기도 한다.
  
  - 호출때마다 Service Resitry가 아닌 캐싱된 정보를 활용하기도 한다.

- Client가 원격 자원들의 주소 정보 기반으로 LB 수행
  
  - Client가 자체 LB 알고리즘 보유

- 장점
  
  - Service Registry를 제외하고 추가 Component 불필요
  
  - LB 등 별도 관리 불필요
  
  - Client Code로 LB하므로 다양한 로직 추가 가능

- 단점 
  
  - Client 언어와 Framework 별 LB 로직 개발 필수
  
  - LB 및 장애 내성에 대한 책임이 모두 Client에 존재
  
  - 조직 통합적 관리 어려움

##### Server-Side 서비스 디스커버리

- Client는 원격 서비스 디스커버리의 정보 유지 안함

- Client는 LB를 통해 원격 서비스 호출

- LB는 인스턴스 목록을 Service Registry로부터 조회

- 장점
  
  - Client에 LB 등 추가 개발 불필요
  
  - 원격 서비스 호출에 대한 모든 기능이 LB로 추상화
  
  - k8s는 기본적으로 Server-Side 서비스 디스커버리

- 단점 
  
  - 서비스 디스커버리 기능이 있는 LB 별도 설치 관리 필요

#### Service Registry

- 서비스 정보를 등록하고 서비스 정보를 조회 가능한 Database

- 외부에 서비스 등록 API와 서비스 조회 API 노출 필요

- 항상 최신 정보를 유지하며 HA가 필수

##### Service Registry - 최신정보 유지

- 서비스 인스턴스로부터 주기적으로 Heartbeat 확인

- Client 입장에서는 Eventual Consistency 고려해야한다.

##### Service Registry 고가용성

- Service Registry를 Active/Active 구조로 유지

- Client에서 원격 서버 정보를 Caching하는 전략

### 서비스 디스커버리 패턴의 적용

#### Spring Cloud Netflix Eureka

- Netflix Eureka로부터 파생되어 Spring Cloud에 커스터마이징된 프로젝트

- 대규모 분산 환경에서 서비스 디스커버리 지원

- Eureka Server와 Eureka Client로 구성

- 서비스들이 Eureka Client가 되며 실행 시점에 Eureka Server에 자기 자신의 정보를 등록

#### Spring Cloud Netflix Eureka 기능

- 서비스 등록

- 클라이언트의 서비스 탐색

- 정보 공유

- 상태 모니터링

#### Eureka 아키텍쳐

- 서비스가 생성되면 자신의 정보를 에이전트에 등록

- 클라이언트는 에이전트를 이용하여 서비스 위치 검색 가능

- 에이전트들은 클러스터링 가능, 각자 정보를 다른 노드에 공유

- 모든 서비스의 인스턴스는 에이전트에게 상태정보 전송 

#### Eureka의 특징

- 고가용성
  
  - 서비스의 정보를 여러개의 노드가 공유하고 동시 동작하는 Active/Active 구조로 고가용성 만족

- 피어 투 피어 구조
  
  - 서비스 디스커버리 클러스터의 모든 노드들이 서비스의 상태 공유

- 장애 내성
  
  - 에이전트는 인스턴의 비정상 상태를 감지하고 제거
  
  - 사람의 개입없이 가

- 회복성
  
  - 클라이언트는 서비스의 정보를 로컬에 캐싱(Ribbon)
  
  - 서비스 디스커버리가 가용하지 않을때 캐시 정보로 서비스 접근

- 부하 분산
  
  - 클라이언트 요청을 서비스 노드에 적절히 분산

##### Eureak와 Ribbon

- 서비스 호출 시 마다 정보를 질의하는 방식은 비효율적

- Ribbon은 에이전트로부터 받은 정보를 로컬에 캐싱

- 캐싱 정보로 서비스를 호출

- 주기적으로 에이전트를 호출하여 정보를 갱신

- Ribbon은 Client-Side LB 기능도 수행
  
  - Service Registry로 부터 받은 서비스의 인스턴스 목록을 기반으로 LB

### 설정 외부화 패턴의 이해

#### 설정 정보 관리

- SW 개발 시 설정 정보는 반드시 필요한 사항

- Enterprise Application에는 엄청나게 많은 수의 설정 정보 존재

- 설정 정보에 문제가 있을 시
  
  - Application의 에러 발생 및 중단
  
  - 기동 중 Runtime 시 비정상 동작

#### 기존 설정 정보 관리

- 소스코드 상에 상수로 관리

- Json, properties..또는 OS 환경 변수로 관리

- 100개의 인스턴스가 있을 경우, 서비스의 설정 변경
  
  - 설정 수정 후 빌드 시 100개 인스턴스에 배포
  
  - 특정 시점에 신/구 설정이 공존
  
  - 특정 인스턴스에 배포/OS 환경 설정 변경 누락 가능성 존재
  
  - 결과적으로 MSA Scale-out의 장애물이 됨

- 환경 별ㄹ 빌드를 매번 새로 해야함
  
  - 빌드 시점에 어떤 환경 변수 파일을 이용할 것인지 결정
  
  - 단일 Build Artifact로 모든 환경에 배포를 하는 것이 Best Practice

#### MSA에서의 설정 관리

- 다수의 서비스, 다수의 환경, 다수의 인스턴스 존재

- 모든 인스턴스/서비스는 사람의 개입을 최소화하면서 신속하게 시작되어야 함

- Human Error는 최소화

#### 설정의 외부화

- 설정 정보를 배포되는 코드에서 완전히 분리

- 중앙 저장소에 설정 정보 저장

- 서버 시작 시 중앙 저장소에서 설정 정보 fetch

- 설정 변경 시 재빌드/배포 없이 모든 인스턴스가 실시간 반영 가능

##### 설정 외부화 패턴

- 설정 정보는 중앙 저장소에 존재

- 인스턴스 시작 시 중앙 저장소에서 설정 조회

- 설정이 변경되면 서비스에서 설정 데이터를 갱신

- 설정 정보 형상관리 도구를 이용하여 다수 Review 후에 변경

### 설정 외부화 패턴의 적용

#### 설정 외부화를 위한 기술

- Spring Cloud Config, Kubernets ConfigMap, Zookeeper...etc

#### Spring Cloud Config

- Spring Project 활용하여 설치 및 설정 용이

- Spring Boot Application과 용이하게 통합 가능

- Git과 통합 가능

- Client/Server 구조
  
  - Spring Cloud Config Client
  
  - Spring Cloud Config Server

- Service 인스턴스들이 모두 Config Client가 됨

- Config Server는 신규 Spring Boot 기반 Application을 생성하여 배포해야한다.
  
  - Maven, Annotation, YAML 설정만 필요하며 Source Code 개발은 불필요함

### Spring Cloud Config 활용 아키텍처

- Service는 Service Resitry에 Config Server 정보 조회 => Config Server에 API 설정 정보 조회 => Config Server는 Git/DBMS에 query로 정보 조회 후 Service로 전달

- Service는 최소한의 Config 정보만 갖으며 그 외 정보는 Config Server를 통해 정보를 조회한다.

### 회로차단기 패턴의 이해

- 회로차단기 : Circuit Breaker

#### 분산 시스템의 장애

- 어떤 장애도 없는 시스템은 없다.

- 장애 대응 시스템 구축은 필수
  
  - 시스템의 중복성을 더하는 방식으로 장애 대응 : 핵심 서버 클러스터링, 인프라 분산
  
  - 위와 같은 기존 방식은 개별 시스템이 완전히 실패하는 경우 적절하다

- 동기식 호출이 대부분인 MSA 환경에서 일부 서비스의 성능 저하가 전체 시스템의 장애로 연결되는 경우가 존재

- 서비스의 성능 저하를 감지하고 빠르게 대응하는 것이 중요

#### MSA 환경에서의 장애

- MSA에서의 장애는 Monolith 환경보다 복잡한 양상을 보인다.
  
  - 많은 수의 다양한 인스턴스들이 서로 Network로 협업하므로

- 특정 서비스/인스턴스의 Failure 뿐만 아니라 성능 저하가 장애로 연결
  
  - 특정 API 트랜잭션에 대해 10개 서비스 협업중 특정 1개 서비스 성능 저하 발생하는 경우

- 트래픽이 몰릴 시 클라이언트는 성능 저하된 서비스를 반복 호출
  
  - 성능 저하된 서비스로부터 응답 시간은 점점 느려진다.
  
  - 호출하는 클라이언트 자원도 점점 고갈

- 서비스 성능저하는 시간이 지나며 전체 시스템에 전파됨
  
  - 요청의 응답 지연으로 thread pool이 다 차게 되어 전체 시스템을 연쇄적으로 요청 불가 상태가 전파됨

#### 클라이언트 회복성 패턴

- 원격 서비스의 비정상 동작에 대해 클라이언트를 보호

- 사람이 개입하여 클라이언트를 보호하는 것이 아닌 호출하는 주체가 자신을 보호하는 패턴
  
  - 원격 자원의 성능 저하가 시스템 전체로 전파되지 않게 함 : 빠른 실패, 실패의 격리

- Client-Side Load Balancing 
  
  - 클라이언트가 인스턴스 목록을 기반으로 부하 분산
  
  - 인스턴스 문제 감지 시 호출 목록에서 제거

- Circuit Breaker Pattern
  
  - 원격 서비스에 대한 호출 정보를 집계
  
  - 비정상 서비스를 반복적으로 호출하지 않도록 제어

- Fallback Pattern
  
  - 원격 서비스 호출 실패 시 대안이 있는지 확인

- Bulkhead Pattern
  
  - 장애발생한 소수 원격 서비스에 대한 호출이 클라이언트의 모든 자원을 고갈시키지 않도록 서비스 별 호출 자원을 격리

##### Client-Side Load Balancing

- Ribbon은 Eureka로부터 인스턴스 목록 조회

- 인스턴스 목록에 기반하여 LB 수행

- 인스턴에 주기적으로 Ping 전송 후 Health check

- 비정상 인스턴스를 LB 대상에서 제외

##### Circuit Breaker Pattern

- 전기회로 차단기 개념을 차용한 패턴

- SW 회로차단기는 원격 서비스의 호출을 모니터링하여, 호출이 특정 횟수 실패할 경우 해당 원격 자원을 반복적으로 호출하지 않도록 요청 차단

- Client-Side LB의 경우 인스턴스 단위로 적용되나, Circuit Breaker Pattern은 인스턴스 집합인 Service 단위로 적용된다.

##### Fallback Pattern

- Circuit 차단 시 대체 행동을 정의
  
  - 예외를 발생 시키는 대신 한다

- 다른 데이터베이스를 호출하거나, 향후 처리를 위해 Retry queue에 넣거나 하드코딩된 결과를 응답

##### Bulkhead Pattern

- 원격 자원에 대한 호출을 자원 별 스레드 풀로 격리하여 관리
  
  - Service A를 호출하기 위한 스레드 풀, Service B를 호출하기 위한 스레드 풀..과 같이 스레드 풀들을 격리하여 할당
  
  - 특정 자원의 성능 저하가 다른 자원의 스레드 풀에 영향주지 않음

#### 클라이언트 회복성 패턴의 핵심

- 빠른 실패(fail fast)
  
  - 실패를 최대한 빨리 인지함으로써 시스템 전체 전파를 방지
  
  - 부분적인 장애가 완전한 장애보다 났다.

- 원만한 실패(fail gracefully)
  
  - fallback을 이용하여 원격 호출 실패 시 대체 경로를 사용하여 시스템을 동작하도록 한다.

- 원활한 회복(recover seamlessly)
  
  - 실패한 자원이 정상화되면 회로차단기가 사람의 개입없이 해당 자원에 대한 차단을 해제 후 접근 허용
  
  - 수 백, 수 천개의 서비스의 대규모 클라우드 기반 시스템에서 원활한 회복이 매우 중요

### 회로차단기 패턴의 적용

#### Hystrix

- Circuit Breaker, Fallback, Bulkhead Pattern 구현 난이도 높음
  
  - 스레드 관리에 대한 해박한 지식
  
  - 구현 후에도 테스팅 비용 높음

- Hystrix는 Netflix에서 2011년부터 프로덕션에서 사용

#### Hystrix의 주요 기능

- Circuit Breaker
  
  - 원격 호출에 대한 특정 단위 별 Circuit Breaker 생성
  
  - 호출에 대한 모든 통계
  
  - 원격 자원의 호출을 중간에서 관리
  
  - 원격 자원 종류에 상관없이 적용 가

- Fallback 
  
  - Exception 발생 시 대체 코드 정의

- Thread Isolation
  
  - 실제 호출을 새로운 thread가 intercept하여 대신 호출
  
  - Hystrix에 의해 관리되는 Thread

- Timeout
  
  - 동일한 정책의 Timeout 적용 가능
  
  - Socket, Connection, Read,..etc

### API Gateway 패턴의 이해

- 시스템 내부 모든 서비스에 대한 API 호출의 Gate 담당

- 특정 서비스에 대한 API 호출이 실제 서비스 도달 전/후 다양한 기능 수행
  
  - 라우팅
  
  - 인증/인가
  
  - 로깅
  
  - 기타 공통 로직 처리

- 라우팅은 nginx 등 웹서버를 사용 가능하지만, 공통 로직은 적용 불가함

#### MSA Cross Cutting Concerns

- MSA 환경에서는 서비스마다 언어/프레임워크가 상이

- Cross Cutting Concerns
  
  - 각 서비스 마다 동이랗게 적용해야 하는 기능 집합
  
  - 인증/인가, 로깅, 분산 추적
  
  - 서비스 별로 각자 개발하는것은 비효율적
    
    - 100%동일하게 동작하는 것도 보장이 안됨

- 공통 라이브러리 사용
  
  - 이렇게 되면 모든 서비스들이 의존하며 라이브러리 변경시 연관 서비스가 모두 재배포되야함

- 공통 코드가 개발되어 있는 자체 프레임워크 도입

- Cross Cutting Concerns을 서비스들과 독립적으로 구성

- 단일 정책 지점을 만들어 모든 호출이 해당 지점을 통과 후 각 서비스로 라우팅

### API Gateway 패턴의 적용

#### API Gateway를 위한 기술 및 서비스

- Netflix Zull, Spring Cloud Gateway,..etc

##### Netflix Zuul

- Netflix에서 만든 오픈 소스 API 게이트웨이

- Spring Cloud로 통합

- Service Discovery, Ribbon, Hystrix 통합

##### Netflix Zuul Routing

- ...

---

- 레퍼런스

> 
