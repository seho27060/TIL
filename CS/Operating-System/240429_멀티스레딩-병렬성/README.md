[TOC]

# 고성능을 강조한 Java 멀티스레딩, 병행성 및 병렬 실행 프로그래밍 전문가되기

## Section 01: 개요

### 개요와 운영 체제 기초

- 동시성(Concurrency) : 1개 코어에 여러 작업을 분산시켜 순차적으로 작업함으로, 유저 인터페이스에 반응성을 주며 작업이 동시에 일어나는 것 처럼 보이는 것

- 병렬성(Parallelism): 멀티스레드와 같이 실제로 병렬적으로 작업이 진행되는 

### 운영체제 기초

#### Context switch

- 운영체제에 1개의 코어는 여러 프로세스로 동작중인 app위의 여러 스레드를 1번에 1개씩 처리한다.  
  
  - process a에 1\~4 thread, process b에 1 \~ 2 thread가 있다고 할때 process마다의 thread들의 처리 순서를 정하는 것을 context switch 라고 한다.

- 이는 동시성을 이뤄낼 수 있으나, 그 대가로 많은 비용이 발생한다.
  
  - 다른 스레드로 전환시 기존 스레드의 정보를 저장하여 변환한다.

#### Threads scheduling

- 컨텍스트 스위치를 위해 스레드 계획을 생성할 때 어떤 순서로 계획을 만들까?
  
  - 작업 시간이 가장 짧은 순서대로 혹시, 가장 긴 순서대로 계획을 생성하면 기준의 반대가 되는 작업은 영원히 실행되지 않을 수 있다.

- 효율적인 스레드 계획을 위해 운영체제는 스레드를 타임 슬라이스 라는 단위로 분할한다.
  
  - 이를 에포크라는 작업 단위에 할당한다. 즉 1개 스레드는 한번에 작업이 완료되지 않는다.

- 많은 데이터를 공유하는 작업은 멀티스레드 아키텍처가 적절하다.
  
  - 스레드의 생성과 폐기는 프로세스보다 빠르며
  
  - 같은 프로세스 내부에서 스레드간 전환은 프로세스 간 전환보다 빠르다.

- 보안과 안정성이 중요한 작업의 경우 멀티 프로세싱 아키텍쳐가 적절하다
  
  - 작업간 독립되어 같은 자원을 사용하지 않는 경우에도 서로 분리된 프로세스로 작업하는 것이 용이하다.

## Section 02: 스레딩 기초 -스레드 생성

### 스레드 생성 - 1부, 스레드의 기능과 디버깅

- `Thread`객체를 생성후 `Runnable` 구현체에 작업 내용을 할당하면 스레드에 작업이 할당되어 실행된다.

- 만약 스레드 내 작업 중 예상하지 못한 예외가 발생한다면, `.setUncaughtExceptionHandler`를 통해 적절한 대응이 가능하다.

### 스레드 생성 - 2부, 스레드 상속

- `Thread` 클래스를 상속하여 필요에 의한 새로운 스레드 객체로 확장할 수 있다.

- 역할에 맞는 스레드 객체 확장으로 다형성과 객체 지향 프로그래밍을 준수할 수 있다.

- 객체간 위계를 잇는 상속은 각각의 역할(책임)을 명확하게 구분한다.

## Section 02: 스레딩 기초 - 스레드 조정

### 스레드 종료 및 Daemon 스레드

#### 스레드 종료

- 스레드는 생성된 순간부터 할당된 작업이 끝난 이후까지도 컴퓨터 자원을 점유하기 때문에, 작업이 끝난 스레드는 적절한 순간에 종료(Termination)시켜야 한다.

- 또는 스레드가 오작동을 일으키거나, 애플리케이션을 종료시키기 위해 스레드를 종료한다.
  
  - 스레드가 1개라도 남아있을 경우에 애플리케이션을 종료되지 않는다.

#### Thread.interrupt

- 실행중인 스레드를 중지시키라는 명령을 전달하는 메서드

- 시간이 많이 소요되는 작업에서 일정 시간이 지나면 동작 중지하도록 한다.

- `Runnable`에서 실행 중인 메서드 내에서도, `thread.isInterrupted`라는 메서드를 통해 스레드 중지를 요청받았는지 확인하여 스레드를 중지 시킨다.

#### Daemon Threads

- 백그라운드에서 실행되는 스레드로, 메인 스레드가 종료되어도 애플리케이션 종료를 막지 않는다.

- `.setDaemon`을 통해 데몬 스레드로 설정할 수 있으며, 해당 스레드의 동작은 애플리케이션의 종료를 방지하지 않는다.

### 스레드 연결

- 스레드들은 서로 독립적으로 동작한다.

- 스레드의 동작 순서는 개발자가 통제할 수 없다.

- 하지만 1개 스레드가 다른 스레드에 의존한다면, 스레드의 순서를 통제할 수 있다.

- 이때 사용하는 메서드가 `Thread.join()`이다.

## Section 04: 성능 최적화

### 성능 및 지연 시간 최적화 개요

- 성능 기준, 정의

- 멀티스레드 애플리케이션의 성능

- 레이턴시

#### 성능 기준

- 레이턴시, 즉 트랜잭션의 속도를 성능 기준으로 측정(초당 30프레임 동영상을 보여주는 앱)
  
  - 레이턴시(Latency) : 지연시간, 시간 단위로 측정되는 작업 하나의 완료 시간

- 처리량, 머신러닝과 같이 대량 데이터를 일정 시각마다 처리
  
  - 스루풋(Throughput): 일정 시간동안 완료한 작업의 량, 시간 단위의 작업 량

- 이렇듯 어플리케이션의 목적에 따라 성능 측정 기준이 다르다.

#### Latency

- 하나의 작업을 처리하는 시간을 나타내는 레이턴시를 성능 측정으로 사용한다면 아래 질문을 고려해야 한다.

- 하나의 작업을 원하는 만큼의 하위 작업으로 나눈다면 적절한 하위 작업의 개수 N은 몇일까?
  
  - 보통 컴퓨터의 코어 개수로 고려한다.
  
  - 이 경우는 코어 개수로 나눈 N개의 스레드 하위 작업이 interruption없이 동작할때 최적의 구현을 보일 수 있다.(모든 스레드는 runnable한 상태여야 한다)
  
  - 또한 시스템에서 CPU를 과용하지 않아야 한다.

- 작업을 여러 하위 작업으로 분할한다고 할때, 이때 분할에 소요되는 시간과 자원은 얼마인가?
  
  - 작업 분할 비용, 하위 작업 수행을 위한 스레드 계산, 스레드의 실행 시간, 모든 하위 작업의 결과에 대한 집계, 하위 작업을 하나의 결과로 총합하는 과정 등등
  
  - 이와 같이 작업 분할에도 비용이 들어가며, 싱글 스레드와 멀티 스레드의 작업 소요시간별로 소요되는 시간를 나타낸 그래프 상 교차점이 분할의 최적의 타이밍이다.

- 어떤 작업이든 하위 작업으로 분할할 수 있을까?
  
  - 작업은 3개의 종류로 구분된다.
  
  - 본질적으로 병행 가능하며 하위 작업으로 쉽게 분할되는 작업
  
  - 분할이 불가능하며, 처음부터 끝까지 싱글 스레드로 동작하는 작업
  
  - 부분적으로 분할 가능하나, 나머지 부분은 싱글 스레드로 동작하는 작업

### 처리량 최적화

- 처리량(Throughput) : 주어진 기간에 완료되는 작업의 수

#### 처리량 산출 접근법

##### 하위 작업 세분화(Breaking Tasks into Subtasks)

- 어떤 작업을 완료하는데 Latency = T일때, 하위작업으로 세분화하여 작업할 경우 처리량은 1이거나 1/T가 된다.

- 이상적인 산정으로 빠르게 작업을 끝낼 수 있지만, 세분화된 하위작업을 스케줄링하는데 다시 비용이 소모되어 비효율적인 작업이 될 수 있다.

##### 병렬 작업(Running Tasks in Parallel)

- 각 작업을 별개 스레드에 할당하는 방법으로, 작업 간은 독립적인 구조로 스케줄링이나 작업 완료 순서가 얽매이지 않아 추가 비용이 발생하지 않는다.

#### Thread Pooling

- 사전에 정한 스레드의 개수로 작업을 수행하며, 대기열의 작업들이 각 스레드에 배정되어 작업이 수행된다.

- 모든 스레드에 작업이 할당되어 지연될 경우, 대기열의 작업은 빈 스레드가 발생할때까지 대기한다.
  
  - Fixed Thread Pool Executor(고정 스레드풀 실행자)

- 1개 머신에서 **보통 적절한** 스레드의 개수는 cpu 코어의 개수와 같다.

## Section 05: 스레드 간 데이터 공유

### 스택 및 힙 메모리 영역

#### 스택 메모리 영역

##### 스택(Stack)

- 메서드가 실행되는 메모리 영역

- 인수 또는 로컬 변수가 저장된다.

- 어떤 메서드가 실행되면, "스택" 이라는 공간에 메서드 별로 "스택 프레임"이 할당되어 인수 또는 로컬 변수가 할당된다.
  
  - 이때 각 메서드 별로 할당된 스택 프레임끼리 갖는 인수 또는 변수 값은 서로 알지 못한다.(독립적이다)
  - 메서드의 실행에 따라 스택에는 LIFO로 "쌓이게"되며, 메서드의 실행이 끝나면 할당된 스택 프레임또한 무효화(invalidate)된다.

- 스택에 할당된 변수들은 특정 스레드에만 한정되므로, 다른 스레드에서 해당 변수에 접근이 불가하다.

- 스택이 생성될때 정적으로 생성되며 런타임이 변경 불가하다.
  
  - 따라서 너무 깊은 구조로 스택이 생성되면 메모리가 남지 않는 StackOverFlow가 발생한다.

#### 공유 메모리 영역

##### 힙(Heap)

- 모든 스레드가 힙에 있는 모든 데이터를 공유하고 언제나 접근이 가능하다.

- **모든 객체**는 힙에 할당된다.
  
  - String, Object, Collection, 클래스 멤버, 정적 변수 etc..

- 힙은 JVM 가비지 컬렉터에 의해 관리된다. 
  
  - 객체는 참조하는 값이 존재한다면 힙에 저장되는데, 참조하는 값이 모두 사라진다면 가비지 컬렉터에 의해 수거된다.

- 이때 참조(Reference)와 객체(Object)를 구분에 유의한다.
  
  - 참조의 경우, 생성 시 스택에 저장되지만 부모 객체에 포함되는 클래스의 멤버로서 참조가 생성되면 힙에 저장된다.
  
  - 객체의 경우, 구분없이 힙에 저장된다.

### 리소스 공유와 임계 영역 개요

#### 스레드간 리소스 공유

##### 리소스(Resource)

- 컴퓨터 영역에서의 데이터 똔또는 어떤 상태를 일컬음

- 스레드간 공유 가능한 자원의 예로 힙(Heap)이 있다.

##### 스레드간 리소스 공유의 필요성

- 문서 작성과 저장이 서로 다른 스레드로 동작하여 문서라는 리소스를 공유할 경우

- 작업 큐라는 공유 리소스에  대기중인 작업 스레드를 할당하여 작업이 생길때마다, 공유 리소스를 참고하여 작업 스레드에 작업을 할당하는 경우

- 멀티스레드 어플리케이션에서 서로 다른 스레드로 여러개의 CRUD 트랜잭션을 수신하여 데이터베이스로 전달하는 경우

##### 스레드간 리소스 공유의 문제

- 공유 리소스에 접근하여 CRUD가 서로 다른 스레드들로 작업하는 경우, 원자적 작업(Atomic Operation)이 불가하다.

##### 원자적 작업

- Atomic Operation, 하나 또는 여러개 집합의 작업으로 다른 시스템이 보기에 동시에 실행되는 거 처럼 보이는 작업

- 모두 완료되거나, 모두 완료되지 않거나(All or Nothing)의 단일 단계로 중간 상태를 확인할 수 없다.

## Section 06: 병행성 문제와 솔루션

### 임계 영역과 동기화

#### 임계 영역(Critical Section)

- 서로 다른 스레드가 동일한 공간에 작업을 하여 원자적 작업으로 동작하지 않도록 방지하기 위해 임의의 영역을 부여하는 것

- 즉, 동시 실행되지 않게 보호해야 하는 코드가 있는 영역을 임계 영역(Critical Section)이라고 한다.

##### Synchronized

- 여러개의 스레드가 코드 블록이 전체 메서드에 액세스할 수 없도록 하는 Locking Machanism

- monitor와 lock 2가지 방식을 사용한다.
  
  - monitor: 어떤 클래스 하위에 synchronized가 할당된 메서드들은 1개 스레드에 의해서만 동작하게 되며, 또 다른 스레드는 해당 키워드가 할당된 메서드에 접근할 수 없다.
  
  - lock: 어떤 객체를 선언하여 메서드 내부에서 synchronized(Object)와 같이 특정 영역에 한정하여 임계 영역을 지정할 수 있다.
  
  - lock과 같은 방식은 1개 메서드 내부에서 여러개의 동기화 객체를 선언하여 같은 수의 임계영역을 지정하거나, 임계영역인 부분과 그렇지 않은 부분을 분리할 수 있어 사용자가 원하는 부분에 임계영역을 할당할 수 있어 유연성이 높다.

##### Reentrant

- Synchronized block은 Reetrant, 즉 재진입 가능하다.

- 이는 Synchronized block내에서 어떤 스레드 A가 작업중에 해당 블록 내부에 할당된 Synchronized block을 만나면 스레드 A는 제한없이 내부에 할당된 Synchronized block에 접근 가능하다.
  
  - 즉, 같은 동기화 블록 내부에 할당된 하위 동기화 블록은 동일한 스레드가 작업이 가능하다.

### 원자적 연산과 Volatile 및 메트릭의 실용 예시

#### 원자적 연산(Atomic operations)

- 대부분의 연산은 비원자적 연산이다.

- 모든 레퍼런스 할당은 원자적 연산이다.

- long과 double을 제외한 원시적 타입 할당도 원자적 연산이다
  
  - long과 double은 길이가 64비트로 java가 보장해주지 않는다.
  
  - 하지만 volatile 키워드를 double이나 long 형식의 변수값에 추가하면 원자적 연산이 가능하다.

### 경쟁 상태 및 데이터 경쟁

#### 경쟁 상태(Race condition)

- 공유 리소스에 여러 스레드가 접근하는 경우/ 어떤 스레드가 공유 리소스를 수정하는 경우/ 스레드 스케줄링에 따라 잘못된 결과가 산출되는 경우

#### 데이터 경쟁(Data Race)

- 종종 컴파일러와 CPU가 성능 최적화를 위해 비순차적으로 명령을 처리하는 경우가 있다.
  
  - 논리에 위반되지 않는 한에 따라 명령문의 순서를 자유롭게 재배열하여 수행한다.
  
  - 이를 통해 프로그램 처리 속도가 빨라진다.

- 컴파일러는 명령 재정렬로 벡터화, 프리페치..를 통해 효율적으로 명령을 수행하고, CPU는 다른 하드웨어에 명령을 수행하게 한다...

- 이와 같이 Java는 semantic 이전의 순서는 보장하지 않지만, 몇가지 예외가 있다.
  
  - Synchronized 키워드를 통한 동기화
  
  - volatile을 통한 공유 변수 선언
  
  - 이를 통해 의도하지 않는 동시 실행을 방지할 수 있으며, 사용자가 원하는 결과를 보장할 수 있다.

### 락킹 기법과 데드락

#### 락킹 기법(Locking Strategy)

- 멀티 스레드 애플리케이션을 구축시에 세밀한(fine-grained) 락킹과 성긴(coarse-grained) 락킹을 선택할 수 있다.

- coarse-grained Locking: 전체 리소스에 락킹하는 방법. 동시실행을 미연에 방지할 수 있는 안전한 방법이나, 최악의 경우 멀티 스레드 구조가 무의미하게 모든 스레드의 작업들이 순차적으로 동작할 수 있다.

- fine-grained Locking: 개별 리소스별로 락킹하는 방법.

#### 데드락(Deadlock)

- 세밀한 락킹으로 개별 리소스별로 락킹을 주면, 리소스 접근중 락킹 명령이 충돌하여 데드락 상태에 빠질 수 있다.

- 서로 다른 스레드 A, B가 같은 리소스에 A가 먼저 락킹하고 B가 락킹하는 경우, 먼저 A로 인해 락킹된 공유 자원 접근을 위해 B는 무한정 대기 상태에 빠지게 되어 작동 불능이 된다.

##### 데드락의 발생 조건

- 상호 배제 조건(Mutual Exclusion): 한번에 한 스레드만 단독으로 리소스에 접근이 가능하다.

- 점유와 대기(Hold and Wait): 최소 1개 스레드가 자원을 점유하면서, 다른 자원의 접근을 대기한다.

- 비선점 할당(non-preemptive allocation): 스레드가 사용 완료할 때까지 리소스를 사용할 수 없는 상황, 다른 스레드의 리소스를 가져올 수 없다.

- 순환 대기(Circular wait): 스레드 A가 점유 중인 자원 a를 스레드 B가 대기하고, 동시에 스레드 B가 점유 중인 자원 b가 스레드 A가 대기하는 순환하는 형태

- 위 4가지 조건이 만족되면 데드락이 발생한다.

##### 데드락 해결법

- 순환 대기를 예방함으로 미연에 방지가 가능하다.
  
  - 동일한 순서로 공유 리소스를 락킹하고, 모든 코드에 해당 순서를 적용한다.

## Secton 07: 락킹 심화

### ReentrantLock 1부 - tryLock과 인터럽트 가능 락

#### ReentrantLock

- 동기화 블록과 달리 명확한 락킹과 언락킹이 필요하다

- synchronized와 같이 키워드로 사용한다

- ```java
  Lock lockObject - new ReentrantLock();
  ...
  ...
  public void use() {
      try{
          lockObject.lock(); => 락킹 지정
          do something
      } finally {
          lockObejct.unlock(); => 언락킹 지정
      }
  }
  ```

        synchronized와 구분되게 메서드 전체가 아닌 부분적으로 락킹을 수행한다.

- .lock 사용 후, 잊지 않고 .unlock을 위해 finally 구문에 언락킹을 지정한다.

- ReentrantLock는 락의 공정성(Lock's fairness)를 제어하는데 유용하다.
  
  - 1개 스레드는 공유 자원을 여러번 락킹하여 자유롭게 접근이 가능하지만, 다른 스레드들은 락킹의 기회를 얻는데 시간이 소요되어 결국 애플리케이션 동작의 효율성의 저하를 불러 일으킨다. 따라서 필요한 순간에 공정성 플래그를 사용하는 것이 중요하다.

##### tryLock

- 락킹 객체의 .tryLock() 메서드를 통해 논리값으로 락킹 가능 여부를 확인할 수 있는 메서드

- 락 객체가 어떤 상태에 있는 tryLock을 사용하여 상태를 확인 할 수 있다

- 락킹 기회를 얻기 위해 스레드가 지연, 대기하는 경우를 제어 가능하여 빠른 반응성이 필요한 로직에 사용된다.

### Reentrant의 읽기/쓰기 및 락 데이터베이스 구현

#### ReentrantReadWriteLock

- 경쟁 상태를 개선을 하기 위한 상호 배제 해결에 사용된다.

- 예를 들어,
  
  - 캐시에 접근하는 4개의 reader와 1개의 writer가 있을때, 경쟁 상태를 방지하기 위해 어떻게 해야 할까.
  
  - 일반적으로 reader(읽기 작업)까리는 큰 문제가 되지 않는다.
  
  - 하지만 reader만 있거나, 읽기 작업이 소요되는 시간이 크다면 문제가 발생한다.

- I/O 작업을 구분하지 않는 ReentrantLock 과 다르게 읽기와 쓰기를 구분하여 각 작업 간 스레드의 접근 여부가 달라져 보다 빠른 작업 수행이 가능하다.

##### ReadLock, WriteLock

- ReentrantReadWriteLock 객체에는 ReadLock, WriteLock 두 개의 락 객체가 존재 하며, 두 객체는 이름대로 읽기 작업과 쓰기 작업을 수행한다.
- ReadLock의 경우 여러 스레드가 접근이 가능하나, WriteLock의 경우 1개의 스레드만 접근이 가능하다.
  - 병렬 작업으로 인한 데드락 방지 또는 데이터의 일관성과 무결성을 유지한다.

## Section 08: 스레드 간 통신

### 세마포어 - 확장 가능한 생성자, 소비자 구현

- 세마포어(Semaphore) : 허가하고, 권한을 부여한다. 사용자 수를 특정 리소스나 리소스 그룹을 제한하는 데 사용 가능. 
  
  - 리소스를 단 1명에게만 허락하는 락(lock)과 다르게, 사전에 지정한 수 만큼 리소스 접근이 허가한다.

- `semaphore.acquire()`로 리소스를 접근하며, 이는 락킹과 같다.
  
  - acquire - lock, release - unlock과 대응된다

##### 세마포어와 락의 차이

- 세마포어는 소유자 스레드 개념이 없다. 여러개의 스레드가 허락되기 때문에

- 같은 스레드가 세마포어를 여러번 얻을(acquire) 수 있다.

- 세마포어를 얻지(acquire)않은 스레드도 세마포어를 릴리스(release)할 수 있다.
  
  - 이를 스레드 간 통신이라고 한다.

- 생산자-소비자(Producer - Consumer) 시나리오에서는 이런 세마포어의 특성이 적합하여 세마포어가 사용된다.

##### 생산자 - 소비자 시나리오

- 어떤 객체를 생산하는 Producer와 객체를 소비하는 Consumer가 있고, 공유 자원인 대기열이 있다고 하자.

- Producer와 Consumer는 서로 공유 자원의 접근을 세마포어의 특성에 의해 제어가능하다.

- 이러한 상황에서 Producer가 생산(접근)할때, Producer는 Consumer를 릴리즈하고/ Consumer가 소비(접근)할때, Consumer는 Producer를 릴리즈한다.

### 조건 변수 - 다목적, 스레드 간 통신

#### 스레드 간 통신(Inter-thread Communication)

- Thread 객체의 interrupt, join과 세마포어의 스레드 간 acquire, release가 예시가 된다.
  
  - interrupt의 경우 스레드 A가 스레드 B에 신호를 보내 작업을 중지
  
  - join의 경우, 스레드 A가 스레드 B를 join하여 cpu사용을 포기하고 대기한다. 스레드 B의 작업이 끝나면 스레드 B가 대기중인 스레드 A에 신호를 보내고 스레드 A는 자원을 사용한다.
  
  - Semaphore의 경우, join과 같은 방식으로 acquire로 사용 또는 대기하고 release로 사용 이후 대기 중 스레드에 사용 가능 신호를 보내 작업을 진행한다.

- 조건 변수(Condition Variable)로서 세마포어
  
  - acquire() 메서드를 사용하는건, 사용 가능한 권한의 수가 0보다 많은지 확인하는 것 과 같다.
  
  - 조건이 성립하지 않으면 대기 상태로 돌아가며, 다른 스레드가 release() 로 신호를 보내면 다시 사용 가능 권한 개수를 확인하여 명령을 수행한다.

- 조건 변수는 언제나 lock과 연관있다.
  
  - lock은 원자적 확인과 공유 변수의 수정을 확인한다.

### 조건 변수로서의 객체 - wait(), notify(), notifyAll()

#### wait(), notify() 그리고 notifyAll()

- Java의 Object 클래스는 wait(), notify(), notifyAll() 메서드를 갖으며, 모든 클래스는 Object 클래스를 상속받기 때문에 앞의 3개의 메서드를 사용 가능하다

- 따라서 어떤 객체든 synchronized 키워드를 통해 조건 변수(condition variable)이나 락(lock)으로 사용 가능하다.
  
  - wait() : 다른 스레드가 현재 스레드를 깨워주기 전 까지 대기한다
    
    - 대기 상태에서는 해당 스레드는 어떤 cpu도 사용하지 않는다.
    
    - 다른 스레드에서 notify() 또는 notifyAll() 메서드로 wait 상태 스레드를 깨우는 신호를 보내는 방법으로 wait 상태의 스레드를 깨울 수 있다.
    
    - 이를 위해서는 객체는 동기화 상태가 되어야 한다.
  
  - notify(), notifyAll() : 1개 스레드나 모든 스레드에 깨우는 신호를 보낸다.

#### 백프레셔(backpressure) 적용

- 생성자(Producer)메서드와 소비자(Consumer)메서드가 있을때, 임의의 제한 값을 설정한다.

- 작업 량을 큐로 설정하여 큐의 크기가 N이라고 가정하고, 생성자 메서드 호출 시 현재 큐의 크기가 N이라면, wait()로 생성자를 대기시킨다.

- 소비자 메서드의 경우, 현재 작업 량이 N - 1 이라면 notifyAll()을 통해 위에서 대기 중인 생성자 메서드를 깨우고 작업 량을 추가한다.

- 위와 같은 사전에 정의한 작업량에 따른 로직을 추가하여 적정 정도의 작업을 수월하게 수행할 수 있다.

## Section 09: Lock-Free 알고리즘, 데이터 구조 및 기술

#### 논블로킹 및 Lock-Free 작업 개요

##### 락(Lock)의 문제

- 경쟁 상태, 데이터 경쟁과 같은 병행성 문제를 락을 이용해 해결할 수 있으나, 언제나 그렇듯 무조건 정답은 아니다. 항상 2가지 이상의 해결책이 존재하며, 개발자의 판단에 따라 적절한 해결책을 선택해야 한다.

- 아래는 락을 사용하는 어플리케이션에서 발생 가능한 문제이다.
  
  - 데드락(DeadLocks) : 데드락 검출과 검증을 위한 해결은 비용이 많이 든다. 또한 락을 사용한다면 발생 가능하게 된다.
  
  - 느린 임계 영역(Slow Critical Section): 1개의 락을 사용하는 멀드 스레드에서, 어떤 1개의 스레드가 단일로 존재하는 락을 오랫동안 사용할 수 있다. 이로 인해 다른 스레드들의 작업 속도를 늦추게 된다.
  
  - 우선순위 역전(Priority Inversion): 리소스 하나와 그 리소스의 락을 공유할 때 발생한다. 운영체제는 스레드들에 우선순위를 할당하여 작업을 스케줄링하는데, 이때 낮은 우선순위 스레드가 락을 먼저 얻게되어 높은 우선순위 스레드가 락을 얻지 못해 어플리케이션의 로직이 정상적으로 작동하지 않게 된다.
  
  - 스레드의 락 점거(Thread Not Releasing a lock, Kill Tolerance): 스레드가 락을 지닌채 죽거나 인터럽트되는 경우 락을 반환하지 못하게 된다. 그 결과 모든 다른 스레드들은 대기 상태가 된다.
  
  - 성능 오버헤드: 스레드 A가 락을 갖고, 스레드 B가 락을 갖으려고 시도하나 대기상태로 진입하면 컨텍스트 스위치로 스레드 B는 스케줄에서 벗어나게 되고(scheduled out) 락이 릴리스되면 다시 컨텍스트 스위치로 스케줄에 인입된다(scheduled back) 이러한 과정은 추가적인 오버헤드를 발생시키며 빠른 처리가 필요한 시스템에서 지연 문제로 이어진다.

#### Lock Free Techniques

- 락을 사용하는 이유는, 여러 스레드가 공유 자원에 접근할 때 어떤 1개의 스레드가 공유 자원을 수정하여 비원자적 실행(Non atomic operation)이 발생하기 때문이다.

- Lock Free 프로그래밍이란 연산을 활용하여 단일 하드웨어 실행을 보증하는 것이다.
  
  - 단일 하드웨어 실행이란 원자적 실행으로 안전한 스레드 실행(Thread safe)이 가능하다.

- 데이터 경쟁을 피하는 다른 방법으로 volatile을 사용하거나, Java 10에서 제공하는 atomic 클래스를 활용하는 것이다.

#### 원자적 레퍼런스, CompareAndSet, Lock-Free 고성능 데이터 구조

##### AtomicReference\<T>

- 클래스의 객체에 대한 레퍼런스를 감싸줘 해당 레퍼런스를 원자적 연산이 가능하도록 한다.
  - `AtomicReference(V initialValue)` , `V get()`, `void set(V newValue)`
- `compareAndSet(V expectedValue, V newValue)`는 원자적 연산 중인 값의 기댓값과 현재 값(newValue)을 비교하여 boolean을 반환한다. 

##### CAS - ComapreAndSet

- 모든 원자적 클래스(Atomic Class) 내부에서 사용 가능하다.

- 단일 하드웨어 실행으로 컴파일되며, 많은 원자적 연산이 내부적으로 CAS를 사용함을 알 수 있다.

###### Lock-Free 데이터 구조

- 위의 AtomicReference나 CompareAndSet을 통해 기존의 데이터 구조(Stack..etc)를 thread safe하며 락을 사용하지 않는 데이터 구조로 구현이 가능하다.

- 이때 Lock-Free를 지향하는 것은 성능을 추구할 수 있다.

## Section 10: 고성능 IO를 위한 스레딩 모델

### 블로킹(Blocking) IO 소개

#### IO란?

- cpu, memory로 구성된 컴퓨터는 다양한 입/출력 장치(키보드, 마우스, 네트워크 카드)를 통해 입력과 출력(Input and Output)을 실행한다.

- cpu에 의해 작동되는 프로그램은 os의 개입없이 언제든 메모리에 접근할 수 있으나, 입/출력 장치의 경우 해당 장치의 실행은 cpu에 연결된 컨트롤러와의 통신을 통해 IO가 발생한다.

- OS에 의해 컨트롤러 작동하여 cpu에 값을 전달하거나, DMA(Direct Memory Access)를 cpu로부터 부여받은 장치만이 메모리에 접근이 가능하다.

- 입/출력이 없는 상태의 장치는 cpu에 영향을 주지 않아, 그 시간동안 cpu는 다른 장치의 입/출력을 처리하거나 프로그램을 실행한다. 만약 장치에서 입/출력이 완료되어 대기중인 연결된 컨트롤러에 신호를 보내면 cpu는 실행중인 작업을 잠시 멈추고 입/출력이 완료된 장치에 의한 작업을 수행한다
  
  - 이를 Blocking IO라고 한다.(IO 작업에 의해 스레드가 할당되어 blocking 되는 현상)

#### Thread Pooling

- 사전에 할당된 스레드 풀의 개수만큼 스레드 작업을 대기시켜놓고, 작업이 가능한 스레드에 작업을 할당하여 효율적인 멀티 스레딩이 가능하다.

- 이때 컴퓨터의 코어 개수와 스레드 풀의 크기를 같게하면 하드웨어를 완전히 사용 가능하다.

- 이러한 스레드 풀링은 항상 cpu에서 실행되는 작업만 포함되며, 블로킹 IO나 블로킹 call은 포함되지 않는다.

##### IO-Bound Application

- 흔한 실제 서비스의 웹 어플리케이션에서 여러 사용자에게 http request를 수신하여 데이터베이스에 IO작업을 하는 로직에서, http request에 대한 작업을 싱글 스레드에 의해 수행한다.

- 이따 사용자 요청에 의해 데이터베이스에 아주 오래 걸리는 IO작업이 일어나면, 1개 스레드는 해당 IO작업을 수행하게 되고 그 대기 시간동안 cpu는 어떤 작업도 수행하지 못한다. 결국 이는 서비스 작동의 지연으로 연결된다.

#### 중요한 관점

- 컴퓨터의 코어 수 만큼 스레드 풀을 할당한다고 해도, 그 개수 만큼 지연을 유발하는 IO 작업이 각 스레드에 할당되면 (스레드 풀 크기 = 코어의 개수)는 생각했던 것 만큼 효율적이지 않을 수 있다. 

- 블로킹 호출이 얼마없다고 하여도, 해당 블로킹 호출 작업들이 반복되고 스레드풀이 지연되면 성능의 저하로 연결된다.

### 작업당 스레드/ 요청당 스레드 모델

-  IO 바운드 애플리케이션을 튜닝하여 고성능을 내는 방법을 알아보자

#### 작업 단위 스레드 모델(Thread-Per-Task Threading model)

- 작업 단위에 따라 스레드 풀의 개수를 설정하는 방법

- 100개 작업을 한다면 스레드 풀의 개수를 100개로 설정하여 작업을 진행한다. 이는 하드웨어의 동작 성능을 향상할 수 있다.

- 단점으로, 작업 단위와 스레드 간 적절하지 않은 스레드 개수의 할당으로 비효율을 야기할 수 있다.
  
  - 스레드는 비싼 비용을 소요하는데, 너무 많은 스레드는 너무 많은 메모리 소비로 애플리케이션에 충돌을 일으키거나 너무 작은 스레드는 적은 작업량과 cpu 사용률을 보인다.

##### 스레싱(Threadshing)

- OS가 시스템을 관리하면서 대부분의 cpu가 사용되는 현상

- 비효율적인 스레드 풀 개수 할당으로 잦은 컨텍스트 스위칭이 발생하여, cpu의 잦은 스레드 스케줄링으로 이어진다. cpu의 사용 비용이 큰 컨텍스트 스위칭으로 다른 작업에 사용할 자원이 사라진다.

### 코어당 스레드 모델을 사용한 비동기 논-블로킹 IO

#### 작업 단위 스레드 모델의 다른 이슈

- 스레드가 블로킹 IO 연산을 수행시 다른 연산을 못한다.

- 또한 외부 서비스 연동 중 대기시간이 길어져 제어의 역전(Inversion Of Control) 현상이 발생하여 안정성이 떨어질 수 있다.

#### 논-블로킹 IO(Non-Blocking IO)

- 기존에 스레드가 블로킹 연상을 수행시, 스레드는 해당 작업의 결과를 대기하지만, 논블로킹 연산에서는 스레드는 일단 연산에 대한 요청을 상대에게 송신하고 바로 다음 작업이 착수한다.
  
  - 첫번 째 요청의 작업을 수행하면서 논블로킹 io 작업의 결과를 대기하는게, 아닌 다음 두번 째 요청을 수신 후 할당된 작업을 수행한다.

- 그러나, 코드 가독성이 떨어지고, 실제 os상에서 논블로킹 메서드를 사용하는 건 매우 어려운 작업이다.

#### 블로킹 IO vs논-블로킹 IO

- 성능과 안정성에 논 블로킹 io를 사용한 작업 단위 스레드 모델이 우수하다.

- 하지만 코드 가독성, 테스트 용이성, 디버깅에는 블로킹 io를 사용한 작업 단위 스레드 모델이 우위를 점한다.

### 가상 스레드와 고성능 IO

#### 가상 스레드(Virtual Thread)

- 새로운 유형의 스레드이며, JDK 21에서 공개되었다.

- 기존의 스레드는 플랫폼 스레드로서 JVM에서 생성되어 작업을 각 매칭되는 OS 스레드에 전달하여 명령을 수행한다.
  
  - 가상 스레드의 경우 플랫폼 스레드와 달리 OS 스레드와 매칭되는 것이 아닌, JVM 내부에서 완전히 속하여 OS가 아닌 JVM의 관리를 받는다.

- OS의 관리를 통하며 생성과 관리의 비용이 드는 플랫폼 스레드와 달리, 가상 스레드는 JVM의 관리를 통하여 대기 상태에는 heap 메모리에 대기하여 가비지 컬렉터에 의해 필요가 없다고 판단되면 회수된다.
  
  - 이러한 특징으로 저 비용을 여러개의 가상 스레드를 생성할 수 있다.

- 가상 스레드는 JVM 내부에서 객체와 같은 형태로 생성되며, 생성시 JVM 내부의 플랫폼 스레드라는 곳에 마운트된다.
  
  - 이때 플랫폼 스레드는 OS 스레드와 연결되며, 스레드 풀과 같은 역할을 한다.
    
    - 각 가상 스레드는 플랫폼 스레드에 마운트되며 이러한 가상 스레드를 캐리어 스레드라고 한다.
  
  - 가상 스레드 실행이 끝나면, 가상 스레드(캐리어 스레드)와 플랫폼 스레드의 마운트를 끊어내고 JVM의 가비지 컬렉터는 해당 가상 스레드를 청소한다.

- 2개의 플랫폼 스레드가 존재하며 각 명령에 따라 가상 스레드가 생성되어 실행될때, 생성된 가상 스레드는 플랫폼 스레드에 마운트되어 작업을 수행한다.
  
  - 작업이 일시 중지되면, 가상 스레드(캐리어 스레드)는 플랫폼 스레드에 언마운트되어 스냅샷과 같이 힙 메모리 영역에 저장된다.
  
  - 그 다음으로 작업 대기 중인 가상 스레드가 다시 해당 플랫폼 스레드에 마운트되어 작업을 이어간다.

- 위와 같은 스레드 스케줄링은 JVM 내부에서 동작하며 개발자는 이를 제어할 수 없다.
  
  - 이는 스레드 풀 역할을 하는 플랫폼 스레드의 개수는 작업량과 가상 스레드의 생성에 따라 JVM이 생성을 자동으로 결정하여 작업을 수행한다는 의미이다.
  
  - 보통 JVM도 실행중인 하드웨어의 코어 개수만큼을 최대 개수 만큼 플랫폼 스레드의 크기를 생성할 수 있다.

### 고성능 IO와 가상 스레드

#### 가상 스레드의 성능 이점

- 가상 스레드는 단순히 cpu 실행을 의미하는 게 아닌, 여러 작업을 작은 풀(플랫폼 스레드)에서 스케줄링 하는 것이다.

- 가상 스레드에 시간이 오래 소요되는 연산(블로킹 연산, IO 등)이 포함되어 있다면, JVM의 내부 스케줄링을 통해 성능과 처리량에 이점을 가져올 수 있다.

- JVM에 의해 자동으로 스케줄링이 된다는 점이 크게 작용하는데, 가상 스레드가 긴 시간이 소요되는 블로킹 작업을 맞이하면 JVM은 가상 스레드와 플랫폼 스레드를 언마운트하여 힙 메모리에 대기시킨다.
  
  - 그 다음 작업을 다시 다른 가상 스레드에 할당하여 플랫폼 스레드를 통해 작업을 진행하고...블로킹 작업 시 언마운트 후 힙 메모리에 대기시키고..를 반복하며
  
  - 가장 처음 블로킹 작업으로 힙 메모리에 대기중인 가상 스레드 작업에서 블로킹 작업의 응답을 받으면 현재 플랫폼 스레드의 가상 스레드를 언마운트하여, 기존에 대기시켰던 가상 스레드의 작업을 멈췄던 부분부터 다시 실행한다.
  
  - 이러한 특징의 가장 큰 장점은 개발자는 블로킹 API을 블로킹으로 인한 지연을 고려하지 않고 사용할 수 있게 된다.

- 이렇듯 가상 스레드는 블로킹 IO와 작업당 스레드 모델, 논 블로킹 IO와 요청 당 스레드 모델의 각각의 장점만을 사용할 수 있게 된다.



---

- 레퍼런스

> 
