[TOC]

# 빅데이터를 지탱하는 기술

---

## 목차

1. 빅데이터의 기초 지식

2. 빅데이터의 검색

3. 빅데이터의 분산 처리

4. 빅데이터의 축적

5. 빅데이터의 파이프라인

6. 빅데이터 분석 기반의 구축

---

## 1장. 빅데이터의 기초 지식

### 1-1. [배경] 빅데이터의 정착

- 기술(하드웨어, 소프트웨어)의 발달로 인해, 이전에는 처리가 곤란한(버려지는) 대용량의 데이터를 처리할 수 있게 됐다.

### 1-2. 빅데이터 시대의 데이터 분석 기반

- 실시간 처리와 배치 처리, 두가지 방식의 데이터 파이프라인

- 데이터 웨어하우스(data warehouse, WDH) : 수집 raw 데이터를 사용 가능하도록 전처리하여 저장함. 장기간 보관

- 데이터 마트(data mart) : DWH에서 분석에 사용할 데이터를 추출, 처리한, BI를 위한 데이터 세트. 단기간 보관

- 데이터 레이크(data lake, DL) : 발생하는 raw 데이터를 전처리하지 않고 원래의 상태로 저장하는 스토리지

- DWH or DL 중심 데이터 파이프라인 구조
  
  - 데이터 소스
    
    - 데이터 웨어하우스 - 수집된 raw 데이터를 전처리하여 적재
    
    - 데이터 레이크 - 수집 raw 데이터를 원 상태 그대로 적재
  
  - 데이터 마트 - DWH(or DL)의 raw데이터 중 필요에 의해 추출한 데이터 세트
  
  각 요소는 '데이터ETL'로 처리된다.

### 1-3. [속성 학습] 스크립트 언어에 의한 특별 분석과 데이터 프레임

- `pandas`를 활용한 스몰 데이터 분석
  
  - 빅데이터에 대한 분산 처리는 지원 X

- `dataframe` 타입을 활용하여 EDA(exploratory data analysis)가 가능하다.
  
  - `dataframe`만의 데이터 조회 뿐만 아니라 `SQL`을 활용할 수 도 있다.

### 1-4. BI 도구와 모니터링

- 데이터를 시각화하기 위해 BI도구를 많이 사용한다.

- BI도구는 사용가능하도록 "전처리"된 데이터에 대해서만 시각화가 가능하다.

- BI 도구 활용을 위해 전처리 작업을 수행할때, **자동화**가 필요한 부분과 **수작업**해야 하는 경계를 잘 확인하자

## 2장. 빅데이터의 탐색

### 2-1. 크로스 집계의 기본

- 레코드중심의 크로스 테이블과 로우,컬럼 중심의 트랜잭션 테이블
  
  - 보통 데이터는 트랜잭션 테이블로 저장된다.

- 수집 데이터를 `SQL`,`pandas`로 집계(aggregation)하여 데이터 마트를 생성후 BI도구를 통해 시각화한다.
  
  - 시스템 구성은 '데이터 마트의 크기'에 따라 결정된다.
  
  - 너무 작은 데이터 마트는 데이터 손실로 정확한 시각화가 힘들고,
  
  - 너무 큰 데이터 마트는 집계의 의미가 무의미하게 자원을 많이 사용한다.
  
  - 어쩔 수 없는 트레이드 오프 관계이므로 필요에 따른 고려가 필요하다.

### 2-2. 열 지향 스토리지에 의한 고속화

- 수십 GB정도의 스몰 데이터는 대기시간에 대한 걱정이 없다..
  
  - 데이터의 증가에 따라 RDB에서의 지연시간이 발생한다면 어떻게 해야할까.

- **MPP**(massive parallel processing, 대규모 병렬 처리) 아키텍쳐를활용하자.
  
  - Amazon Redshift, Google BigQuery 등이 있다.
  
  - 압축과 분산을 통해 대규모 데이터에 대한 부하를 여러 디스크에 분산하여 데이터 로드에 따른 지연을 줄인다.

- 데이터 베이스의 접근 방식
  
  | 데이터 베이스      | 접근 방식                                                                                                                                              |
  | ------------ | -------------------------------------------------------------------------------------------------------------------------------------------------- |
  | 행 지향 데이터 베이스 | 데이터 접근에 index를 활용한다. 마지막 행에 데이터를 추가하면 되므로 쓰기에 특화. 전체 데이터를 로드해야함.                                                                                   |
  | 열 지향 데이터 베이스 | 행의 index는 의미를 갖는 값이 할당된다. 보통 데이터분석에서는 테이블의 전체 데이터가 아닌 부분 데이터가 필요하다. 열 지향 데이터베이스의 경우 필요 컬럼에 대한 데이터를 조회하므로 행 지향 데이터베이스 보다 선택적 조회가 빠르다.               |
  | MPP 데이터 베이스  | MPP에서는 하나의 쿼리를 다수의 작은 태스크로 분해하고 이를 가능한 한 병렬로 실행한다. 1억 레코드로 이루어진 테이블에서 태스크를 10만 레코드로 구분하여 1000개의 태스크로 나눈다. 1000개 태스크에 대한 결과를 집계하여 모든 결과을 총합하여 산출한다. |

### 2-3. 애드 혹 분석과 시각화 도구

- 애드 혹(ad-hoc)
  
  1. 특정한 문제나 일을 위해 만들어진 관습적인 해결책
  2. 일반화할 수 없는 해결책
  3. 어떤 다른 목적에 적응시킬 수 없는 해결책
  
  정형화된 방법론이 아니라, 특정 상황을 위해서만 적용 가능한 방안 이라고 할 수 있겠다.

- '노트북'을 활용한 애드혹 분석, '대시보드'를 활용한 지속적 모니터링

- 필요에 의한 데이터 마트 구축이 선행된다.

### 2-4. 데이터 마트의 기본 구조

- 팩트 테이블 : 트랜잭션과 같은 사실이 기록된 테이블

- 디멘전 테이블 : 트랜잭션에 활용되는 정보가 저장된 데이터

- 비정규화 테이블 :  데이터 분석을 위해서는 정형화된 데이터 테이블을 분해하여 비정규화하는 과정으로 필요에 의한 여러개의 비정규화 테이블로 재생성한다.
  
  - 규모가 작다면 RDB도 적합하지만 아니라면, MPP 데이터베이스와 같은 열 지향 데이터베이스를 사용하자.

## 3장. 빅데이터의 분산 처리

- Hadoop And Spark

### 3-1. 대규모 분산 처리의 프레임워크

#### Hadoop

- `Hadoop` 기본 구성 요소
  
  - 분산 파일 시스템 - HDFS
  
  - 리소스 관리자 - `YARN`
  
  - 분산 데이터 처리 -` MapReduce`
  
  각 요소는 다른 애플리케이션으로 대체 가능함.

- 분산 데이터 및 처리 엔진
  
  - `MapReduce`의 경우 대용량 데이터를 배치 처리가 목적임
  
  - `Hive`는 사용자의 `SQL`을 적합한 `MapReduce`로 변환하여 실행시킨다.
  
  - 데이터분석을 위한 애드 혹에서는 단순 쿼리가 많이 사용되는데, 이는 대용량 처리에 적합한 `MapReduce`(`Hive`)로는 **오버 헤드**가 발생한다.
  
  - Hive on Tez
    
    - `MapReduce`에 기반한 Hive on MR에서 `Tez`로 넘어옴
    
    - `Tez`의 경우 순차적으로 작업을 처리((1회의 MR 스테이지 종료)하는 MR과 다르게 작업의 처리를 기다리지 않고 다음 작업을 진행한다.
    
    - Hive on Spark 또한 개발이 진행중이다. 

- 대화형 쿼리 엔진
  
  - `MR`, `Tez` 등은 비구조화 데이터를 장기간의 배치 처리를 한정된 리소스로 안정되게 수행한다.
  
  - 데이터분석에 사용되는 작은 규모의 반복적인 쿼리를 위해 대화형 쿼리 엔진 `Impala` 와 `presto`가 등장한다.
    
    - 구조화 데이터에 대한 쿼리를 수행하기에 적합하다.

- `Hadoop`에서는 다수의 쿼리 엔진이 개발되어 있다.
  
  - 이를 '**SQL on Hadoop**'이라고 부른다.

#### Spark

- 하드웨어 자원이 부족한 시기, `MapReduce`의 경우 처리에 disk를 활용함

- 하드웨어의 메모리 자원이 자연스레 증가함에 따라 작업에서 메모리를 적극 활용할 수 있게 되었고, `Spark`라는 프로젝트가 발달하게 됨

- `Spark`는 `Hadoop`을 대체하는게 아닌 `MapReduce`를 대체한다.(위의 `Hadoop` 기본 구성 요소 참고)

- 다양한 스크립트 언어로의 대응

- 내재된 `Spark SQL`과 `Spark Streaming`로 대화형 쿼리와 실시간 처리 기능 사용 가능.

### 3-2. 쿼리 엔진

- `Hive`에 의한 구조화 데이터 생성

- `Presto`에 의한 대화식 쿼리

#### 데이터 마트 구축의 파이프라인

- 원본 데이터를 `Hive`로 대용량 배치 처리로 열 지향 스토리지 형식으로 구조화 데이터로 처리한다.

- 구조화된 데이터를 집계, 결합하여 비정규화 테이블로 데이터 마트로 내보낸다.

- `Hive`에서 만든 각 테이블의 정보는 "Hive 메타 스토어"라는 특별한 데이터베이스에 저장된다.
  
  - 메타스토어는 다른  `SQL on Hadoop`의 쿼리 엔진에서도 참고하여 사용한다.

#### Hive에 의한 구조화 데이터 작성

- `Hive`를 이용한 **데이터 구조화 프로세스**
  
  - raw데이터를 `Hive`상에 불러온다.
  
  - 데이터를 열 지향 스토리지 형식(ORC, parquet)로 변환하여 새로운 테이블로 저장한다.(데이터 구조화)
  
  - 새로운 열 지향 테이블로 데이터에 대한 집계를 처리한다.
  
  데이터 구조화 작업에 시간이 걸릴 수 있지만, 이후 단편적 쿼리(집계)에 대한 소요 시간이 단축된다.

- `Hive`로 비정규화 테이블 작성하기
  
  - 데이터 구조화를 마친 테이블에서 **데이터 마트를 구축**한다.
  
  - 대용량 배치 처리는 `Hive`, 대화형 쿼리 엔진은 `Presto`를 선택한다.
  
  - 비정규화 테이블을 생성하는건 많은 자원이 필요하므로 **효율적으로 쿼리**를 날리는게 중요하다.

- `Hive`의 쿼리 개선하기
  
  - 서브 쿼리 안에서 레코드 수 줄이기 - 초기 단계에서 팩트 테이블 작게하기
    
    비효율적 쿼리 예시
    
    ```sql
    SELECT ...
    FROM DataTable a
    JOIN UserTable b ON b.id = a.user_id
    WHERE b.created_at = '2017-01-01'
    ```
    
    효율적 쿼리 예시
    
    ```sql
    SELECT ...
    FROM (
        SELECT * DataTable
        WHERE time >= TIMESTAMP '2017-01-01 00:00:00'
    ) a
    JOIN UserTable b ON b.id = a.user_id
    WHERE b.created_at = '2017-01-01'
    ```
    
    서브 쿼리로 팩트 테이블을 작게 하여 작업을 수행하는게 확실히 효율적이다.
    
    파이프라인의 구성중 **로그확인을 통해 비효율적 쿼리를 확인하여 개선**하는 작업 역시 필요하다.
  
  - 데이터 편향 피하기
    
    데이터가 균등하게 분포됐다는 가정하에 데이터를 중앙 집합시켜 중복 체크를 하는 `DISTINCT`나 분산처리가 가능한 `GROUP BY`는 문제가 없다.
    
    만약 특정 데이터(30일중 13일에 트래픽 증폭)에 데이터가 편향되었을 경우, 아무리 분산 처리가 되어도 데이터가 편향된 부분은 병목 현상이 발생한다.
    
    비효율적 쿼리
    
    ```sql
    SELECT date, count(distinct user_id) users
    FROM acess_log GROUP BY date
    ```
    
    `dinstinc count` 쿼리는 `GROUP BY`가 분산 처리한 데이터에 중복 처리를 한다.(`dinstinc`는 분산처리 되지 않음)
    효율적 쿼리
    
    ```sql
    SELECT date, count(*) users
    FROM (
        SELECT DISTINCT date, user_id FROM access_log
        ) t
    GROUP BY date
    ```
    
    서브 쿼리를 사용하여 `distict`로 중복이 이미 제거된 테이블에 `GROUP BY`와 같은 분산 처리를 할 경우, 데이터 편향에 의한 병목 현상을 방지 할 수 있다.

#### 대화형 쿼리 엔진 Presto의 구조

- 작은 쿼리를 여러번 실행하는 대화형 데이터 처리에 적합한 대화형 쿼리 엔진 `Presto`를 알아보자.
  
  (`Google Big Query`, `Impala`, `Drill`등 여러 소프트웨어가 있으니 환경과 조건에 따라 선택 사용하자)

- 플러그인 가능한 스토리지 
  
  - 전용 스토리지를 갖지 않으므로 여러 데이터 소스에서 직접 데이터를 읽어 들일 수 있다.
  
  - 구조화 데이터(Structed Data)에서 집계의 목적에 적합하다.
  
  - 하나의 쿼리 안에서 분산 스토리지 상의 팩트 테이블과 `MySQL`의 마스터 테이블을 조인하는 등 여러 데이터 소스에 연결 가능하다.

- CPU 처리의 최적화 
  
  - 작은 규모의 쿼리를 멀티 스레드화 하여 단일 머신으로 병렬하여 최적화된 실행이 가능하다.

- 인 메모리 처리에 의한 고속화 
  
  - 모든 데이터 처리를 메모리상으로 실행한다.

- 분산 결합과 브로드캐스트 결합
  
  - 분산 결합(distributed join)으로 같은 키를 갖는 데이터는 동일 노드에 모인다.
  
  - 브로드캐스트 결합(broadcast join)으로 충분히 작은 테이블를 갖는 노드에 다른 노드의 상대적으로 큰 테이블을 분할하여 데이터를 처리한다.(작은 테이블의 데이터는 복사하여 분할된 큰 테이블에 할당한다)
  
  - 분산 결합과 브로드캐스트 결합은 서로 양립할 수 없다.

#### 데이터 분석의 프레임워크 선택하기

- 많은 옵션(프레임워크)중 어떤 상황에 어떤 옵션을 선택해야 할까?

- MPP 데이터 베이스 - 완성한 비정규화 테이블의 고속 집계

- Hive - 데이터양에 좌우되지 않는 쿼리 엔진

- Presto - 속도 중시 & 대화식으로 특화된 쿼리 엔진

- Spark - 분산 시스템을 사용한 프로그래밍 환경 

### 3-3. 데이터 마트의 구축

- 데이터 마트 구축에 필요한 각종 테이블과 비정규화 테이블을 만들기까지의 흐름

#### 팩트 테이블

- 팩트 테이블 작성에는 추가(append)와 치환(replace) 두가지 방법이 있다.
  
  - 추가 - 데이터를 기존 테이블에 추가(`INSERT INTO`)
  
  - 치환 - 과거 데이터를 포함하여 새로운 테이블로 치환(`CREATE TABLE`)

- 테이블 파티셔닝(table partitioning)
  
  - 테이블을 여러 물리적인 파티션으로 나눔으로 추가로 발생하는 결손, 중복 등의 문제를 해결한다.

- 데이터 마트의 치환
  
  - 테이블을 새로 생성함으로 결손, 중복등의 문제가 발생하지 않는다.
  - 다만 생성에 소요 시간이 커질 수 있으므로 조건과 환경을 고려해야 한다.

#### 집계 테이블

- 팩트 테이블을 어느 정도 모아 집계한 집계 테이블(summary table)

- 집계 테이블로 그 크기를 작게하기 위해 카디널리티(cardinality)를 작게한다.
  
  - cardinality - 각 컬럼이 취하는 값의 범위(특정 기간의 데이터, 성별, 지역별 등)

#### 스냅샷 테이블

- 마스터 데이터처럼 업데이트 가능성이 있는 테이블에 대해 **정기적으로** 테이블을 **통째로** 저장하는 방법

- 스냅샷 테이블을 팩트 테이블과 결합함으로 디멘전 테이블로도 사용한다.

#### 이력 테이블

- 정기적으로 모든 데이터를 스냅샷하는게 아닌, 변경 데이터를 증분으로만 스냅샷하거나 변경이 있을 때마다 그 내용을 기록하는 이력 테이블(history table)

- 테이블의 크기가 비교적 작지만, 어느 순간의 마스터 테이블을 완전히 복원할 순 없다.

#### 디멘전을 추가하여 비정규화 테이블 완성시키기

- 팩트 테이블과 디멘전 테이블을 결합하여 비정규화 테이블을 만든다.

- 카디널리티가 작은 디멘전을 만들어 결합하고, 시각화에 필요하지 않는 칼럼을 가급적 제거함으로 시각화가 쉽게 데이터양이 적은 비정규화 테이블을 생성한다.

- 데이터 집계의 기본형
  
  - 시간에 의한 검색이나 참고하는 컬럼 수를 줄여 팩트 테이블에서 필요 데이터를 추출한다.
  
  - 디멘전 테이블과 결합하여 카디널리티를 작게 하여 데이터 마트에 저장할 컬럼을 선택한다.
  
  - 그룹화하여 측정값을 집계한다.
  
  - 예시
    
    ```sql
    SELECT 
        date_trunc('day',a.time) time,
        date_diff('day','b.min_time) days,
        count(*) count
    FROM (
        # 1. 팩트 테이블로부터 필요 컬럼 추출
        SELECT time, session_id FROM access_log
        # 집계 기간 검색으로 카디너리티 축소
        WHERE time BETWEEN TIMESTAMP '2017-01-01' AND TIMESTAMP '2018-01-01'
    ) a
    # 2. 디멘전 테이블과 결합
    JOIN sessions b ON b.session_id = a.session_id
    # 그룹화
    GROUP BY 1, 2
    ```

## 4장. 빅데이터의 축적

### 4-1. 벌크 형과 스트리밍 형의 데이터 수집

#### 객체 스토리지와 데이터 수집

- 빅데이터는 대부분의 경우 확장성이 높은 분산 스토리지(distributed storage)에 저장된다.

- 기본이 되는 객체 스토리지(object storage)가 있으며 Haddop이라면 HDFS, AWS의 S3가 유명하다.

- 데이터 수집(data ingestion)
  
  - 너무 작은 크기의 파일을 저장하거나
  
  - 너무 큰 크기의 파일 저장은 객체 스토리지에 비효율적이므로,
  
  - 작은 크기의 파일을 합치거나, 큰 크기의 파일을 분할하여 적당한 크기의 데이터로 저장하는게 옳다.

#### 벌크 형의 데이터 전송

- 전통적으로 벌크 형 데이터를 데이터 웨어하우스에 저장한다.

- 이러한 데이터 수집을 위한 **ETL서버**(ETL server)를 필요로 한다.

- 일정 주기로 데이터를 수집하여 데이터 전송의 신뢰성을 갖는다.

- 이러한 벌크 형 데이터 전송은 **워크플로 관리도구**의 사용이 적절하다.

### 스트리밍 형의 데이터 전송

- '웹 브라우저', '모바일 앱', '디바이스' 등에서 즉각적으로 생성되는 데이터의 경우 스트리밍 데이터의 전송을 고려해볼만 하다.

- 다수의 클라이언트에서 계속해서 작은 데이터를 전송하는 **메시지 배송(message delivery)** 을 사용한다.
  
  - 데이터 전송량에 비해 높은 오버헤드가 발생하기 때문에, 서버의 높은 성능을 요구한다.

- NoSQL 데이터베이스가 사용되며 **메시지 큐(message queue)**, **메시지 브로커(message broker)** 등의 중계 시스템으로 일정 간격으로 수집 데이터를 분산 스토리지에 저장한다.

- 웹 브라우저에서의 메시지 배송
  
  - 'Fluetnd', 'Logstash'와 같은 상주형 로그 수집 소프트웨어가 사용된다.
  
  - 또는 자바스크립트로 웹 브라우저에서 직접 메시지를 보내는 **'웹 이벤트 추적(web event tracking)'** 을 사용한다.

- 모바일 앱으로부터의 메시지 배송
  
  - MBaaS(Mobile Backend as a Service)라는 백엔드의 각종 서비스로 벡엔드 데이터 저장소에 저장한 데이터를 벌크형 도구로 수집하거나
  
  - 모바일 용 개발 키드(SDK)로 온/오프라인 상태의 앱에서 SDK 내부에 축적된 데이터를 온라인에 연결시 데이터를 수집한다.

- 디바이스로부터의 메시지 배송
  
  - **'MQTT(MQ Telmetry Transport)'** 라는 TCP/IP로 데이터를 전송하는 프로토콜을 사용한다.
  
  - 일반적으로 **'Pub/Sub 형 메시지 배송(Pub/Sub message delivery)** 의 구조를 갖는다.
  
  - 관리자에 의해 생성된 **'Topic'** 을 클라이언트가 구독(Subscribe)하면 연결되며 메시지를 송수신한다.
  
  - 메시지의 교환을 중계하는 **'MQTT 브로커(MQTT broker)'** 서버와 메시지를 수진하는 **'MQTT 구독자(MQTT subscriber)** 시스템으로 구성된다.

### [성능 X 신뢰성] 메시지 배송의 트레이드 오프

- 클라이언트가 많아질 수록 스트리밍 형의 메시지 배송은 '성능'과 '신뢰성'이 반비례 관계에 놓이게 된다. 그 이유를 알아보자

#### 메시지 브로커

- 서비스의 규모가 커질수록 메시지 배송의 부하는 커진다.

- 클라이언트의 메시지 전송 증가 -> 서버에서의 수신 실패 -> 클라이언트의 재전송 -> 수신 실패...의 과정이 반복적으로 수행되어 서버 부하는 갈수록 커진다.

- 이러한 부하로 인한 메시지 배송 실패를 방지하기 위해 **메시지 브로커**를 사용한다.
  
  - 오픈소스로 **Apache Kafka**와 클라우드 서비스로 **Amazon Kinesis**가 있다.

- 푸쉬 형과 풀 형
  
  - 송신 측의 제어로 데이터를 송신하는 **Push**
  
  - 수신 측의 주도로 데이터를 수신하는 **Pull**
  
  - 메시지 브로커는 데이터 쓰기 속도를 조정하기 위한 완충 부분으로 푸쉬 형에서 풀 형으로 메시지 배송의 타이밍을 변환한다.
  
  - 메시지 브로커에 데이터를 push하는 **생산자(producer)** 와 pull하는 **소비자(consumer)** 로 구성된다.

- 메시지 라우팅
  
  - 1분마다 총 200MB의 200만번의 데이터 전송이 발생하면 스토리지 서버는 200만의 쓰기 작업을 수행해야 하며 이는 매우 부하가 큰 작업이다.
  
  - 메시지 브로커는 이를 해결한다. 메시지 브로커로 200만번의 데이터 푸쉬가 이뤄지고, 이것을 '소비자'에서 풀한다. (**스트림 처리, stream processing**, 짧은 간격으로 차례대로 데이터를 꺼내서 처리함)
  
  - 메시지 브로커에 써넣은 데이터는 복수의 다른 소비자에서 읽어 들일 수 있다. 이를 통해 메시지가 복사되어 데이터를 여러 경로로 분기하는데 이를 '**메시지 라우팅**(message routing)'라고 한다.

### 메시지 배송을 확실하기 실시하는 것은 어렵다.

- 모바일 회선과 같은 낮은 신뢰성의 네트워크나 분산 시스템의 특성상 메시지의 중복과 누락이 발생하며 이는 **신뢰성(reliablity)** 와 직결된다.
  
  - 대부분의 경우 아래 3가지 중 1개를 보장하도록 설계된다.

- **at most once** - 메시지는 한 번만 전송된다. 도중에 전송 실패로 메시지 결손 가능성이 있다.
  
  - 무슨 일이 일어나도 절대로 메시지를 **재전송(retransmission)** 하지 않는다. 보내는 클라이언트가 한번 보내면 수신 확인 없이 해당 전송은 끝난다.

- **exactly once** - 메시지는 손실되거나 중복 없이 한 번만 전달된다.
  
  - 네트워크상의 두 개 노드의 양 방향 통신을 보장하기 위해 **코디네이터(coordinator)** 가 필수적이다.
  
  - 코디네이터로 exactly once가 가능하나..코디네이터의 shut down으로 인한 일시적 부재나, 코디네이터 의존에 의한 성능상의 문제가 발생한다.

- **at least once** - 메시지는 확실히 전달된다. 같은 것이 여러 번 전달된 가능성이 있다.
  
  - 메시지가 재전송되어도 **중복 제거(deduplication)** 하는 구조가 있다면 중복이 없는 것 처럼 보일 수 있다.
  
  - TCP/IP에 의한 네트워크 통신에서 TCP로 메시지의 수신 확인을 위한 'ack' 플래그로 'at least once'을 실현할 수 있다.
    
    - 메시지마다 패킷 번호를 부여하여 중복되는 패킷 번호의 메시지는 제거하는 방법.
  
  - 메시지 배송에 사용되는 오픈소스 소프트웨어는 'at least once'를 보장한다.. 하지만 중복제거는 사용자의 몫이므로 이를 주의하자.

#### 중복 제거는 높은 비용의 오퍼레이션

- TCP의 메시지 시퀀스 번호로 메시지 중복을 확인할 수 있으나.. 분산 시스템에서는 이를 확인하기 위한 중앙 처리가 필요하다. 
  
  - 힘들게 분산시켜놨는데 또 중앙처리하면.. 성능 하락으로 이어진다.
  
  - 이를 위한 대안으로 아래와 같은 방법이 있다.

- 오프셋을 이용한 중복 제거
  
  - 전송 데이터에 이름을 부여해 그것을 작은 메시지로 배송한다.
  
  - 각 메시지는 파일안의 시작 위치(오프셋)을 덧붙여, 메시지가 중복되어도 같은 파일의 같은 위치에 덮어쓰므로 중복 문제가 해결된다.
  
  - 벌크 형 메시지 전송에 적합하나 스트리밍 형에서는 쓰이지 않는다.

- 고유 ID에 의한 중복 제거
  
  - 스트리밍 형 메시지 배송에서 자주 사용되며 모든 메시지에 'UUID(universally Unique IDentifier)'와 같은 고유 ID를 저장한다.
  
  - 메시지가 늘어남에 따라 ID가 폭발적으로 증가하므로 최근에 받은 ID만을 기억하고 그보다 늦게 온 메시지의 중복은 허용하는 타협방안을 적용한다.

- 종단간(End to End)의 신뢰성
  
  - 성능과 신뢰성의 트레이트 오프 관계로..빅데이터의 메시지 배송에서는 종종 신뢰성보다 '효율'을 중시한다.
  
  - 중간 경로에 **'at least once'를 보장**하는 한편, '**중복 제거는 하지 않는 것**'이 **표준적인 구현**이다.

- 신뢰성이 높은 메시지 배송을 실현하려면 중간 경로를 모두 'at least once',로 통일한 후, 클라이언트 상에서 모든 메시지에 고유 ID를 할당하고 경로의 말단에서 중복 제거를 실행해야 한다.

- 고유 ID를 사용한 중복 제거의 방법
  
  - NoSQL 데이터베이스인 Cassandra와 Elasticsearch는 특성상 데이터를 쓸때 고유 ID를 지정해야 하므로 동일 ID의 데이터는 덮어쓰므로 중복 제거가 해결된다.
  
  - 보내온 데이터를 일단 그대로 객체 스토리지에 저장후, 읽어 들이는 단계에서 SQL을 사용하여 중복을 제거한다. 이는 대규모 데이터 처리이므로 메모리에서 실행이 불가능하므로 `Hive`같은 배치형 쿼리 엔진에서 실행한다.

#### 데이터 수집의 파이프라인

- 클라이언트 - 프론트엔드 - 메시지 브로커 - 소비자 - 분산 스토리지(- 중복 제거 - 데이터 구조화) 와 같은 일련의 프로세스로 장기적 데이터 분석을 위한 **'데이터 수집의 파이프라인'** 이 완성된다.

- 위 구조의 모든 요소를 구성하는게 아닌 요구 사항, 기존 시스템의 구조, 여러 환경 제약 등을 고려하여 필요와 목적에 맞게 파이프라인을 구성해야 한다.

- 중복을 고려한 시스템 설계
  
  - 빅데이터를 다루는 시스템은 매우 높은 성능을 요구하기 때문에 (필연적으로 발생하게 되는) 아주 작은 중복은 무시하는 경향이 있다.
  
  - 때문에 '중복이 있어도 문제가 되지 않는' 시스템을 설계하는게 중요하다.
  
  - 트랜잭션과 같이 신뢰성이 중시되는 경우 스트리밍 형 메시지 배송보다는 벌크 형을 선택하는게 좋다.

---

- 레퍼런스

> 빅데이터를 지탱하는 기술
