[TOC]

# 빅데이터를 지탱하는 기술

---

## 목차

1. 빅데이터의 기초 지식

2. 빅데이터의 검색

3. 빅데이터의 분산 처리

4. 빅데이터의 축적

5. 빅데이터의 파이프라인

6. 빅데이터 분석 기반의 구축

---

## 1장. 빅데이터의 기초 지식

### 1-1. [배경] 빅데이터의 정착

- 기술(하드웨어, 소프트웨어)의 발달로 인해, 이전에는 처리가 곤란한(버려지는) 대용량의 데이터를 처리할 수 있게 됐다.

### 1-2. 빅데이터 시대의 데이터 분석 기반

- 실시간 처리와 배치 처리, 두가지 방식의 데이터 파이프라인

- 데이터 웨어하우스(data warehouse, WDH) : 수집 raw 데이터를 사용 가능하도록 전처리하여 저장함. 장기간 보관

- 데이터 마트(data mart) : DWH에서 분석에 사용할 데이터를 추출, 처리한, BI를 위한 데이터 세트. 단기간 보관

- 데이터 레이크(data lake, DL) : 발생하는 raw 데이터를 전처리하지 않고 원래의 상태로 저장하는 스토리지

- DWH or DL 중심 데이터 파이프라인 구조
  
  - 데이터 소스
    
    - 데이터 웨어하우스 - 수집된 raw 데이터를 전처리하여 적재
    
    - 데이터 레이크 - 수집 raw 데이터를 원 상태 그대로 적재
  
  - 데이터 마트 - DWH(or DL)의 raw데이터 중 필요에 의해 추출한 데이터 세트
  
  각 요소는 '데이터ETL'로 처리된다.

### 1-3. [속성 학습] 스크립트 언어에 의한 특별 분석과 데이터 프레임

- `pandas`를 활용한 스몰 데이터 분석
  
  - 빅데이터에 대한 분산 처리는 지원 X

- `dataframe` 타입을 활용하여 EDA(exploratory data analysis)가 가능하다.
  
  - `dataframe`만의 데이터 조회 뿐만 아니라 `SQL`을 활용할 수 도 있다.

### 1-4. BI 도구와 모니터링

- 데이터를 시각화하기 위해 BI도구를 많이 사용한다.

- BI도구는 사용가능하도록 "전처리"된 데이터에 대해서만 시각화가 가능하다.

- BI 도구 활용을 위해 전처리 작업을 수행할때, **자동화**가 필요한 부분과 **수작업**해야 하는 경계를 잘 확인하자

## 2장. 빅데이터의 탐색

### 2-1. 크로스 집계의 기본

- 레코드중심의 크로스 테이블과 로우,컬럼 중심의 트랜잭션 테이블
  
  - 보통 데이터는 트랜잭션 테이블로 저장된다.

- 수집 데이터를 `SQL`,`pandas`로 집계(aggregation)하여 데이터 마트를 생성후 BI도구를 통해 시각화한다.
  
  - 시스템 구성은 '데이터 마트의 크기'에 따라 결정된다.
  
  - 너무 작은 데이터 마트는 데이터 손실로 정확한 시각화가 힘들고,
  
  - 너무 큰 데이터 마트는 집계의 의미가 무의미하게 자원을 많이 사용한다.
  
  - 어쩔 수 없는 트레이드 오프 관계이므로 필요에 따른 고려가 필요하다.

### 2-2. 열 지향 스토리지에 의한 고속화

- 수십 GB정도의 스몰 데이터는 대기시간에 대한 걱정이 없다..
  
  - 데이터의 증가에 따라 RDB에서의 지연시간이 발생한다면 어떻게 해야할까.

- **MPP**(massive parallel processing, 대규모 병렬 처리) 아키텍쳐를활용하자.
  
  - Amazon Redshift, Google BigQuery 등이 있다.
  
  - 압축과 분산을 통해 대규모 데이터에 대한 부하를 여러 디스크에 분산하여 데이터 로드에 따른 지연을 줄인다.

- 데이터 베이스의 접근 방식
  
  | 데이터 베이스      | 접근 방식                                                                                                                                              |
  | ------------ | -------------------------------------------------------------------------------------------------------------------------------------------------- |
  | 행 지향 데이터 베이스 | 데이터 접근에 index를 활용한다. 마지막 행에 데이터를 추가하면 되므로 쓰기에 특화. 전체 데이터를 로드해야함.                                                                                   |
  | 열 지향 데이터 베이스 | 행의 index는 의미를 갖는 값이 할당된다. 보통 데이터분석에서는 테이블의 전체 데이터가 아닌 부분 데이터가 필요하다. 열 지향 데이터베이스의 경우 필요 컬럼에 대한 데이터를 조회하므로 행 지향 데이터베이스 보다 선택적 조회가 빠르다.               |
  | MPP 데이터 베이스  | MPP에서는 하나의 쿼리를 다수의 작은 태스크로 분해하고 이를 가능한 한 병렬로 실행한다. 1억 레코드로 이루어진 테이블에서 태스크를 10만 레코드로 구분하여 1000개의 태스크로 나눈다. 1000개 태스크에 대한 결과를 집계하여 모든 결과을 총합하여 산출한다. |

### 2-3. 애드 혹 분석과 시각화 도구

- 애드 혹(ad-hoc)
  
  1. 특정한 문제나 일을 위해 만들어진 관습적인 해결책
  2. 일반화할 수 없는 해결책
  3. 어떤 다른 목적에 적응시킬 수 없는 해결책
  
  정형화된 방법론이 아니라, 특정 상황을 위해서만 적용 가능한 방안 이라고 할 수 있겠다.

- '노트북'을 활용한 애드혹 분석, '대시보드'를 활용한 지속적 모니터링

- 필요에 의한 데이터 마트 구축이 선행된다.

### 2-4. 데이터 마트의 기본 구조

- 팩트 테이블 : 트랜잭션과 같은 사실이 기록된 테이블

- 디멘전 테이블 : 트랜잭션에 활용되는 정보가 저장된 데이터

- 비정규화 테이블 :  데이터 분석을 위해서는 정형화된 데이터 테이블을 분해하여 비정규화하는 과정으로 필요에 의한 여러개의 비정규화 테이블로 재생성한다.
  
  - 규모가 작다면 RDB도 적합하지만 아니라면, MPP 데이터베이스와 같은 열 지향 데이터베이스를 사용하자.

## 3장. 빅데이터의 분산 처리

- Hadoop And Spark

### 3-1. 대규모 분산 처리의 프레임워크

#### Hadoop

- `Hadoop` 기본 구성 요소
  
  - 분산 파일 시스템 - HDFS
  
  - 리소스 관리자 - `YARN`
  
  - 분산 데이터 처리 -` MapReduce`
  
  각 요소는 다른 애플리케이션으로 대체 가능함.

- 분산 데이터 및 처리 엔진
  
  - `MapReduce`의 경우 대용량 데이터를 배치 처리가 목적임
  
  - `Hive`는 사용자의 `SQL`을 적합한 `MapReduce`로 변환하여 실행시킨다.
  
  - 데이터분석을 위한 애드 혹에서는 단순 쿼리가 많이 사용되는데, 이는 대용량 처리에 적합한 `MapReduce`(`Hive`)로는 **오버 헤드**가 발생한다.
  
  - Hive on Tez
    
    - `MapReduce`에 기반한 Hive on MR에서 `Tez`로 넘어옴
    
    - `Tez`의 경우 순차적으로 작업을 처리((1회의 MR 스테이지 종료)하는 MR과 다르게 작업의 처리를 기다리지 않고 다음 작업을 진행한다.
    
    - Hive on Spark 또한 개발이 진행중이다. 

- 대화형 쿼리 엔진
  
  - `MR`, `Tez` 등은 비구조화 데이터를 장기간의 배치 처리를 한정된 리소스로 안정되게 수행한다.
  
  - 데이터분석에 사용되는 작은 규모의 반복적인 쿼리를 위해 대화형 쿼리 엔진 `Impala` 와 `presto`가 등장한다.
    
    - 구조화 데이터에 대한 쿼리를 수행하기에 적합하다.

- `Hadoop`에서는 다수의 쿼리 엔진이 개발되어 있다.
  
  - 이를 '**SQL on Hadoop**'이라고 부른다.

#### Spark

- 하드웨어 자원이 부족한 시기, `MapReduce`의 경우 처리에 disk를 활용함

- 하드웨어의 메모리 자원이 자연스레 증가함에 따라 작업에서 메모리를 적극 활용할 수 있게 되었고, `Spark`라는 프로젝트가 발달하게 됨

- `Spark`는 `Hadoop`을 대체하는게 아닌 `MapReduce`를 대체한다.(위의 `Hadoop` 기본 구성 요소 참고)

- 다양한 스크립트 언어로의 대응

- 내재된 `Spark SQL`과 `Spark Streaming`로 대화형 쿼리와 실시간 처리 기능 사용 가능.

### 3-2. 쿼리 엔진

- `Hive`에 의한 구조화 데이터 생성

- `Presto`에 의한 대화식 쿼리

#### 데이터 마트 구축의 파이프라인

- 원본 데이터를 `Hive`로 대용량 배치 처리로 열 지향 스토리지 형식으로 구조화 데이터로 처리한다.

- 구조화된 데이터를 집계, 결합하여 비정규화 테이블로 데이터 마트로 내보낸다.

- `Hive`에서 만든 각 테이블의 정보는 "Hive 메타 스토어"라는 특별한 데이터베이스에 저장된다.
  
  - 메타스토어는 다른  `SQL on Hadoop`의 쿼리 엔진에서도 참고하여 사용한다.

#### Hive에 의한 구조화 데이터 작성

- `Hive`를 이용한 **데이터 구조화 프로세스**
  
  - raw데이터를 `Hive`상에 불러온다.
  
  - 데이터를 열 지향 스토리지 형식(ORC, parquet)로 변환하여 새로운 테이블로 저장한다.(데이터 구조화)
  
  - 새로운 열 지향 테이블로 데이터에 대한 집계를 처리한다.
  
  데이터 구조화 작업에 시간이 걸릴 수 있지만, 이후 단편적 쿼리(집계)에 대한 소요 시간이 단축된다.

- `Hive`로 비정규화 테이블 작성하기
  
  - 데이터 구조화를 마친 테이블에서 **데이터 마트를 구축**한다.
  
  - 대용량 배치 처리는 `Hive`, 대화형 쿼리 엔진은 `Presto`를 선택한다.
  
  - 비정규화 테이블을 생성하는건 많은 자원이 필요하므로 **효율적으로 쿼리**를 날리는게 중요하다.

- `Hive`의 쿼리 개선하기
  
  - 서브 쿼리 안에서 레코드 수 줄이기 - 초기 단계에서 팩트 테이블 작게하기
    
    비효율적 쿼리 예시
    
    ```sql
    SELECT ...
    FROM DataTable a
    JOIN UserTable b ON b.id = a.user_id
    WHERE b.created_at = '2017-01-01'
    ```
    
    효율적 쿼리 예시
    
    ```sql
    SELECT ...
    FROM (
        SELECT * DataTable
        WHERE time >= TIMESTAMP '2017-01-01 00:00:00'
    ) a
    JOIN UserTable b ON b.id = a.user_id
    WHERE b.created_at = '2017-01-01'
    ```
    
    서브 쿼리로 팩트 테이블을 작게 하여 작업을 수행하는게 확실히 효율적이다.
    
    파이프라인의 구성중 **로그확인을 통해 비효율적 쿼리를 확인하여 개선**하는 작업 역시 필요하다.
  
  - 데이터 편향 피하기
    
    데이터가 균등하게 분포됐다는 가정하에 데이터를 중앙 집합시켜 중복 체크를 하는 `DISTINCT`나 분산처리가 가능한 `GROUP BY`는 문제가 없다.
    
    만약 특정 데이터(30일중 13일에 트래픽 증폭)에 데이터가 편향되었을 경우, 아무리 분산 처리가 되어도 데이터가 편향된 부분은 병목 현상이 발생한다.
    
    비효율적 쿼리
    
    ```sql
    SELECT date, count(distinct user_id) users
    FROM acess_log GROUP BY date
    ```
    
    `dinstinc count` 쿼리는 `GROUP BY`가 분산 처리한 데이터에 중복 처리를 한다.(`dinstinc`는 분산처리 되지 않음)
    효율적 쿼리
    
    ```sql
    SELECT date, count(*) users
    FROM (
        SELECT DISTINCT date, user_id FROM access_log
        ) t
    GROUP BY date
    ```
    
    서브 쿼리를 사용하여 `distict`로 중복이 이미 제거된 테이블에 `GROUP BY`와 같은 분산 처리를 할 경우, 데이터 편향에 의한 병목 현상을 방지 할 수 있다.

#### 대화형 쿼리 엔진 Presto의 구조

- 작은 쿼리를 여러번 실행하는 대화형 데이터 처리에 적합한 대화형 쿼리 엔진 `Presto`를 알아보자.
  
  (`Google Big Query`, `Impala`, `Drill`등 여러 소프트웨어가 있으니 환경과 조건에 따라 선택 사용하자)

- 플러그인 가능한 스토리지 
  
  - 전용 스토리지를 갖지 않으므로 여러 데이터 소스에서 직접 데이터를 읽어 들일 수 있다.
  
  - 구조화 데이터(Structed Data)에서 집계의 목적에 적합하다.
  
  - 하나의 쿼리 안에서 분산 스토리지 상의 팩트 테이블과 `MySQL`의 마스터 테이블을 조인하는 등 여러 데이터 소스에 연결 가능하다.

- CPU 처리의 최적화 
  
  - 작은 규모의 쿼리를 멀티 스레드화 하여 단일 머신으로 병렬하여 최적화된 실행이 가능하다.

- 인 메모리 처리에 의한 고속화 
  
  - 모든 데이터 처리를 메모리상으로 실행한다.

- 분산 결합과 브로드캐스트 결합
  
  - 분산 결합(distributed join)으로 같은 키를 갖는 데이터는 동일 노드에 모인다.
  
  - 브로드캐스트 결합(broadcast join)으로 충분히 작은 테이블를 갖는 노드에 다른 노드의 상대적으로 큰 테이블을 분할하여 데이터를 처리한다.(작은 테이블의 데이터는 복사하여 분할된 큰 테이블에 할당한다)
  
  - 분산 결합과 브로드캐스트 결합은 서로 양립할 수 없다.

#### 데이터 분석의 프레임워크 선택하기

- 많은 옵션(프레임워크)중 어떤 상황에 어떤 옵션을 선택해야 할까?

- MPP 데이터 베이스 - 완성한 비정규화 테이블의 고속 집계

- Hive - 데이터양에 좌우되지 않는 쿼리 엔진

- Presto - 속도 중시 & 대화식으로 특화된 쿼리 엔진

- Spark - 분산 시스템을 사용한 프로그래밍 환경 

### 3-3. 데이터 마트의 구축

- 데이터 마트 구축에 필요한 각종 테이블과 비정규화 테이블을 만들기까지의 흐름

#### 팩트 테이블

- 팩트 테이블 작성에는 추가(append)와 치환(replace) 두가지 방법이 있다.
  
  - 추가 - 데이터를 기존 테이블에 추가(`INSERT INTO`)
  
  - 치환 - 과거 데이터를 포함하여 새로운 테이블로 치환(`CREATE TABLE`)

- 테이블 파티셔닝(table partitioning)
  
  - 테이블을 여러 물리적인 파티션으로 나눔으로 추가로 발생하는 결손, 중복 등의 문제를 해결한다.

- 데이터 마트의 치환
  
  - 테이블을 새로 생성함으로 결손, 중복등의 문제가 발생하지 않는다.
  - 다만 생성에 소요 시간이 커질 수 있으므로 조건과 환경을 고려해야 한다.

#### 집계 테이블

- 팩트 테이블을 어느 정도 모아 집계한 집계 테이블(summary table)

- 집계 테이블로 그 크기를 작게하기 위해 카디널리티(cardinality)를 작게한다.
  
  - cardinality - 각 컬럼이 취하는 값의 범위(특정 기간의 데이터, 성별, 지역별 등)

#### 스냅샷 테이블

- 마스터 데이터처럼 업데이트 가능성이 있는 테이블에 대해 **정기적으로** 테이블을 **통째로** 저장하는 방법

- 스냅샷 테이블을 팩트 테이블과 결합함으로 디멘전 테이블로도 사용한다.

#### 이력 테이블

- 정기적으로 모든 데이터를 스냅샷하는게 아닌, 변경 데이터를 증분으로만 스냅샷하거나 변경이 있을 때마다 그 내용을 기록하는 이력 테이블(history table)

- 테이블의 크기가 비교적 작지만, 어느 순간의 마스터 테이블을 완전히 복원할 순 없다.

#### 디멘전을 추가하여 비정규화 테이블 완성시키기

- 팩트 테이블과 디멘전 테이블을 결합하여 비정규화 테이블을 만든다.

- 카디널리티가 작은 디멘전을 만들어 결합하고, 시각화에 필요하지 않는 칼럼을 가급적 제거함으로 시각화가 쉽게 데이터양이 적은 비정규화 테이블을 생성한다.

- 데이터 집계의 기본형
  
  - 시간에 의한 검색이나 참고하는 컬럼 수를 줄여 팩트 테이블에서 필요 데이터를 추출한다.
  
  - 디멘전 테이블과 결합하여 카디널리티를 작게 하여 데이터 마트에 저장할 컬럼을 선택한다.
  
  - 그룹화하여 측정값을 집계한다.
  
  - 예시
    
    ```sql
    SELECT 
        date_trunc('day',a.time) time,
        date_diff('day','b.min_time) days,
        count(*) count
    FROM (
        # 1. 팩트 테이블로부터 필요 컬럼 추출
        SELECT time, session_id FROM access_log
        # 집계 기간 검색으로 카디너리티 축소
        WHERE time BETWEEN TIMESTAMP '2017-01-01' AND TIMESTAMP '2018-01-01'
    ) a
    # 2. 디멘전 테이블과 결합
    JOIN sessions b ON b.session_id = a.session_id
    # 그룹화
    GROUP BY 1, 2
    ```

## 4장. 빅데이터의 축적

---

- 레퍼런스

> 빅데이터를 지탱하는 기술
