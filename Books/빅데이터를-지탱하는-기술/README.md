[TOC]

# 빅데이터를 지탱하는 기술

---

## 목차

1. 빅데이터의 기초 지식

2. 빅데이터의 검색

3. 빅데이터의 분산 처리

4. 빅데이터의 축적

5. 빅데이터의 파이프라인

6. 빅데이터 분석 기반의 구축

---

## 1장. 빅데이터의 기초 지식

### 1-1. [배경] 빅데이터의 정착

- 기술(하드웨어, 소프트웨어)의 발달로 인해, 이전에는 처리가 곤란한(버려지는) 대용량의 데이터를 처리할 수 있게 됐다.

### 1-2. 빅데이터 시대의 데이터 분석 기반

- 실시간 처리와 배치 처리, 두가지 방식의 데이터 파이프라인

- 데이터 웨어하우스(data warehouse, WDH) : 수집 raw 데이터를 사용 가능하도록 전처리하여 저장함. 장기간 보관

- 데이터 마트(data mart) : DWH에서 분석에 사용할 데이터를 추출, 처리한, BI를 위한 데이터 세트. 단기간 보관

- 데이터 레이크(data lake, DL) : 발생하는 raw 데이터를 전처리하지 않고 원래의 상태로 저장하는 스토리지

- DWH or DL 중심 데이터 파이프라인 구조
  
  - 데이터 소스
    
    - 데이터 웨어하우스 - 수집된 raw 데이터를 전처리하여 적재
    
    - 데이터 레이크 - 수집 raw 데이터를 원 상태 그대로 적재
  
  - 데이터 마트 - DWH(or DL)의 raw데이터 중 필요에 의해 추출한 데이터 세트
  
  각 요소는 '데이터ETL'로 처리된다.

### 1-3. [속성 학습] 스크립트 언어에 의한 특별 분석과 데이터 프레임

- `pandas`를 활용한 스몰 데이터 분석
  
  - 빅데이터에 대한 분산 처리는 지원 X

- `dataframe` 타입을 활용하여 EDA(exploratory data analysis)가 가능하다.
  
  - `dataframe`만의 데이터 조회 뿐만 아니라 `SQL`을 활용할 수 도 있다.

### 1-4. BI 도구와 모니터링

- 데이터를 시각화하기 위해 BI도구를 많이 사용한다.

- BI도구는 사용가능하도록 "전처리"된 데이터에 대해서만 시각화가 가능하다.

- BI 도구 활용을 위해 전처리 작업을 수행할때, **자동화**가 필요한 부분과 **수작업**해야 하는 경계를 잘 확인하자

## 2장. 빅데이터의 탐색

### 2-1. 크로스 집계의 기본

- 레코드중심의 크로스 테이블과 로우,컬럼 중심의 트랜잭션 테이블
  
  - 보통 데이터는 트랜잭션 테이블로 저장된다.

- 수집 데이터를 `SQL`,`pandas`로 집계(aggregation)하여 데이터 마트를 생성후 BI도구를 통해 시각화한다.
  
  - 시스템 구성은 '데이터 마트의 크기'에 따라 결정된다.
  
  - 너무 작은 데이터 마트는 데이터 손실로 정확한 시각화가 힘들고,
  
  - 너무 큰 데이터 마트는 집계의 의미가 무의미하게 자원을 많이 사용한다.
  
  - 어쩔 수 없는 트레이드 오프 관계이므로 필요에 따른 고려가 필요하다.

### 2-2. 열 지향 스토리지에 의한 고속화

- 수십 GB정도의 스몰 데이터는 대기시간에 대한 걱정이 없다..
  
  - 데이터의 증가에 따라 RDB에서의 지연시간이 발생한다면 어떻게 해야할까.

- **MPP**(massive parallel processing, 대규모 병렬 처리) 아키텍쳐를활용하자.
  
  - Amazon Redshift, Google BigQuery 등이 있다.
  
  - 압축과 분산을 통해 대규모 데이터에 대한 부하를 여러 디스크에 분산하여 데이터 로드에 따른 지연을 줄인다.

- 데이터 베이스의 접근 방식
  
  | 데이터 베이스      | 접근 방식                                                                                                                                              |
  | ------------ | -------------------------------------------------------------------------------------------------------------------------------------------------- |
  | 행 지향 데이터 베이스 | 데이터 접근에 index를 활용한다. 마지막 행에 데이터를 추가하면 되므로 쓰기에 특화. 전체 데이터를 로드해야함.                                                                                   |
  | 열 지향 데이터 베이스 | 행의 index는 의미를 갖는 값이 할당된다. 보통 데이터분석에서는 테이블의 전체 데이터가 아닌 부분 데이터가 필요하다. 열 지향 데이터베이스의 경우 필요 컬럼에 대한 데이터를 조회하므로 행 지향 데이터베이스 보다 선택적 조회가 빠르다.               |
  | MPP 데이터 베이스  | MPP에서는 하나의 쿼리를 다수의 작은 태스크로 분해하고 이를 가능한 한 병렬로 실행한다. 1억 레코드로 이루어진 테이블에서 태스크를 10만 레코드로 구분하여 1000개의 태스크로 나눈다. 1000개 태스크에 대한 결과를 집계하여 모든 결과을 총합하여 산출한다. |

### 2-3. 애드 혹 분석과 시각화 도구

- 애드 혹(ad-hoc)
  
  1. 특정한 문제나 일을 위해 만들어진 관습적인 해결책
  2. 일반화할 수 없는 해결책
  3. 어떤 다른 목적에 적응시킬 수 없는 해결책
  
  정형화된 방법론이 아니라, 특정 상황을 위해서만 적용 가능한 방안 이라고 할 수 있겠다.

- '노트북'을 활용한 애드혹 분석, '대시보드'를 활용한 지속적 모니터링

- 필요에 의한 데이터 마트 구축이 선행된다.

### 2-4. 데이터 마트의 기본 구조

- 팩트 테이블 : 트랜잭션과 같은 사실이 기록된 테이블

- 디멘전 테이블 : 트랜잭션에 활용되는 정보가 저장된 데이터

- 비정규화 테이블 :  데이터 분석을 위해서는 정형화된 데이터 테이블을 분해하여 비정규화하는 과정으로 필요에 의한 여러개의 비정규화 테이블로 재생성한다.
  
  - 규모가 작다면 RDB도 적합하지만 아니라면, MPP 데이터베이스와 같은 열 지향 데이터베이스를 사용하자.

## 3장. 빅데이터의 분산 처리

- Hadoop And Spark

### 3-1. 대규모 분산 처리의 프레임워크

#### Hadoop

- `Hadoop` 기본 구성 요소
  
  - 분산 파일 시스템 - HDFS
  
  - 리소스 관리자 - `YARN`
  
  - 분산 데이터 처리 -` MapReduce`
  
  각 요소는 다른 애플리케이션으로 대체 가능함.

- 분산 데이터 및 처리 엔진
  
  - `MapReduce`의 경우 대용량 데이터를 배치 처리가 목적임
  
  - `Hive`는 사용자의 `SQL`을 적합한 `MapReduce`로 변환하여 실행시킨다.
  
  - 데이터분석을 위한 애드 혹에서는 단순 쿼리가 많이 사용되는데, 이는 대용량 처리에 적합한 `MapReduce`(`Hive`)로는 **오버 헤드**가 발생한다.
  
  - Hive on Tez
    
    - `MapReduce`에 기반한 Hive on MR에서 `Tez`로 넘어옴
    
    - `Tez`의 경우 순차적으로 작업을 처리((1회의 MR 스테이지 종료)하는 MR과 다르게 작업의 처리를 기다리지 않고 다음 작업을 진행한다.
    
    - Hive on Spark 또한 개발이 진행중이다. 

- 대화형 쿼리 엔진
  
  - `MR`, `Tez` 등은 비구조화 데이터를 장기간의 배치 처리를 한정된 리소스로 안정되게 수행한다.
  
  - 데이터분석에 사용되는 작은 규모의 반복적인 쿼리를 위해 대화형 쿼리 엔진 `Impala` 와 `presto`가 등장한다.
    
    - 구조화 데이터에 대한 쿼리를 수행하기에 적합하다.

- `Hadoop`에서는 다수의 쿼리 엔진이 개발되어 있다.
  
  - 이를 '**SQL on Hadoop**'이라고 부른다.

#### Spark

- 하드웨어 자원이 부족한 시기, `MapReduce`의 경우 처리에 disk를 활용함

- 하드웨어의 메모리 자원이 자연스레 증가함에 따라 작업에서 메모리를 적극 활용할 수 있게 되었고, `Spark`라는 프로젝트가 발달하게 됨

- `Spark`는 `Hadoop`을 대체하는게 아닌 `MapReduce`를 대체한다.(위의 `Hadoop` 기본 구성 요소 참고)

- 다양한 스크립트 언어로의 대응

- 내재된 `Spark SQL`과 `Spark Streaming`로 대화형 쿼리와 실시간 처리 기능 사용 가능.

### 3-2. 쿼리 엔진

- `Hive`에 의한 구조화 데이터 생성

- `Presto`에 의한 대화식 쿼리

#### 데이터 마트 구축의 파이프라인

- 원본 데이터를 `Hive`로 대용량 배치 처리로 열 지향 스토리지 형식으로 구조화 데이터로 처리한다.

- 구조화된 데이터를 집계, 결합하여 비정규화 테이블로 데이터 마트로 내보낸다.

- `Hive`에서 만든 각 테이블의 정보는 "Hive 메타 스토어"라는 특별한 데이터베이스에 저장된다.
  
  - 메타스토어는 다른  `SQL on Hadoop`의 쿼리 엔진에서도 참고하여 사용한다.

#### Hive에 의한 구조화 데이터 작성

- `Hive`를 이용한 **데이터 구조화 프로세스**
  
  - raw데이터를 `Hive`상에 불러온다.
  
  - 데이터를 열 지향 스토리지 형식(ORC, parquet)로 변환하여 새로운 테이블로 저장한다.(데이터 구조화)
  
  - 새로운 열 지향 테이블로 데이터에 대한 집계를 처리한다.
  
  데이터 구조화 작업에 시간이 걸릴 수 있지만, 이후 단편적 쿼리(집계)에 대한 소요 시간이 단축된다.

- `Hive`로 비정규화 테이블 작성하기
  
  - 데이터 구조화를 마친 테이블에서 **데이터 마트를 구축**한다.
  
  - 대용량 배치 처리는 `Hive`, 대화형 쿼리 엔진은 `Presto`를 선택한다.
  
  - 비정규화 테이블을 생성하는건 많은 자원이 필요하므로 **효율적으로 쿼리**를 날리는게 중요하다.

- `Hive`의 쿼리 개선하기
  
  - 서브 쿼리 안에서 레코드 수 줄이기 - 초기 단계에서 팩트 테이블 작게하기
    
    비효율적 쿼리 예시
    
    ```sql
    SELECT ...
    FROM DataTable a
    JOIN UserTable b ON b.id = a.user_id
    WHERE b.created_at = '2017-01-01'
    ```
    
    효율적 쿼리 예시
    
    ```sql
    SELECT ...
    FROM (
        SELECT * DataTable
        WHERE time >= TIMESTAMP '2017-01-01 00:00:00'
    ) a
    JOIN UserTable b ON b.id = a.user_id
    WHERE b.created_at = '2017-01-01'
    ```
    
    서브 쿼리로 팩트 테이블을 작게 하여 작업을 수행하는게 확실히 효율적이다.
    
    파이프라인의 구성중 **로그확인을 통해 비효율적 쿼리를 확인하여 개선**하는 작업 역시 필요하다.
  
  - 데이터 편향 피하기
    
    데이터가 균등하게 분포됐다는 가정하에 데이터를 중앙 집합시켜 중복 체크를 하는 `DISTINCT`나 분산처리가 가능한 `GROUP BY`는 문제가 없다.
    
    만약 특정 데이터(30일중 13일에 트래픽 증폭)에 데이터가 편향되었을 경우, 아무리 분산 처리가 되어도 데이터가 편향된 부분은 병목 현상이 발생한다.
    
    비효율적 쿼리
    
    ```sql
    SELECT date, count(distinct user_id) users
    FROM acess_log GROUP BY date
    ```
    
    `dinstinc count` 쿼리는 `GROUP BY`가 분산 처리한 데이터에 중복 처리를 한다.(`dinstinc`는 분산처리 되지 않음)
    효율적 쿼리
    
    ```sql
    SELECT date, count(*) users
    FROM (
        SELECT DISTINCT date, user_id FROM access_log
        ) t
    GROUP BY date
    ```
    
    서브 쿼리를 사용하여 `distict`로 중복이 이미 제거된 테이블에 `GROUP BY`와 같은 분산 처리를 할 경우, 데이터 편향에 의한 병목 현상을 방지 할 수 있다.

#### 대화형 쿼리 엔진 Presto의 구조

- 작은 쿼리를 여러번 실행하는 대화형 데이터 처리에 적합한 대화형 쿼리 엔진 `Presto`를 알아보자.
  
  (`Google Big Query`, `Impala`, `Drill`등 여러 소프트웨어가 있으니 환경과 조건에 따라 선택 사용하자)

- 플러그인 가능한 스토리지 
  
  - 전용 스토리지를 갖지 않으므로 여러 데이터 소스에서 직접 데이터를 읽어 들일 수 있다.
  
  - 구조화 데이터(Structed Data)에서 집계의 목적에 적합하다.
  
  - 하나의 쿼리 안에서 분산 스토리지 상의 팩트 테이블과 `MySQL`의 마스터 테이블을 조인하는 등 여러 데이터 소스에 연결 가능하다.

- CPU 처리의 최적화 
  
  - 작은 규모의 쿼리를 멀티 스레드화 하여 단일 머신으로 병렬하여 최적화된 실행이 가능하다.

- 인 메모리 처리에 의한 고속화 
  
  - 모든 데이터 처리를 메모리상으로 실행한다.

- 분산 결합과 브로드캐스트 결합
  
  - 분산 결합(distributed join)으로 같은 키를 갖는 데이터는 동일 노드에 모인다.
  
  - 브로드캐스트 결합(broadcast join)으로 충분히 작은 테이블를 갖는 노드에 다른 노드의 상대적으로 큰 테이블을 분할하여 데이터를 처리한다.(작은 테이블의 데이터는 복사하여 분할된 큰 테이블에 할당한다)
  
  - 분산 결합과 브로드캐스트 결합은 서로 양립할 수 없다.

#### 데이터 분석의 프레임워크 선택하기

- 많은 옵션(프레임워크)중 어떤 상황에 어떤 옵션을 선택해야 할까?

- MPP 데이터 베이스 - 완성한 비정규화 테이블의 고속 집계

- Hive - 데이터양에 좌우되지 않는 쿼리 엔진

- Presto - 속도 중시 & 대화식으로 특화된 쿼리 엔진

- Spark - 분산 시스템을 사용한 프로그래밍 환경 

### 3-3. 데이터 마트의 구축

- 데이터 마트 구축에 필요한 각종 테이블과 비정규화 테이블을 만들기까지의 흐름

#### 팩트 테이블

- 팩트 테이블 작성에는 추가(append)와 치환(replace) 두가지 방법이 있다.
  
  - 추가 - 데이터를 기존 테이블에 추가(`INSERT INTO`)
  
  - 치환 - 과거 데이터를 포함하여 새로운 테이블로 치환(`CREATE TABLE`)

- 테이블 파티셔닝(table partitioning)
  
  - 테이블을 여러 물리적인 파티션으로 나눔으로 추가로 발생하는 결손, 중복 등의 문제를 해결한다.

- 데이터 마트의 치환
  
  - 테이블을 새로 생성함으로 결손, 중복등의 문제가 발생하지 않는다.
  - 다만 생성에 소요 시간이 커질 수 있으므로 조건과 환경을 고려해야 한다.

#### 집계 테이블

- 팩트 테이블을 어느 정도 모아 집계한 집계 테이블(summary table)

- 집계 테이블로 그 크기를 작게하기 위해 카디널리티(cardinality)를 작게한다.
  
  - cardinality - 각 컬럼이 취하는 값의 범위(특정 기간의 데이터, 성별, 지역별 등)

#### 스냅샷 테이블

- 마스터 데이터처럼 업데이트 가능성이 있는 테이블에 대해 **정기적으로** 테이블을 **통째로** 저장하는 방법

- 스냅샷 테이블을 팩트 테이블과 결합함으로 디멘전 테이블로도 사용한다.

#### 이력 테이블

- 정기적으로 모든 데이터를 스냅샷하는게 아닌, 변경 데이터를 증분으로만 스냅샷하거나 변경이 있을 때마다 그 내용을 기록하는 이력 테이블(history table)

- 테이블의 크기가 비교적 작지만, 어느 순간의 마스터 테이블을 완전히 복원할 순 없다.

#### 디멘전을 추가하여 비정규화 테이블 완성시키기

- 팩트 테이블과 디멘전 테이블을 결합하여 비정규화 테이블을 만든다.

- 카디널리티가 작은 디멘전을 만들어 결합하고, 시각화에 필요하지 않는 칼럼을 가급적 제거함으로 시각화가 쉽게 데이터양이 적은 비정규화 테이블을 생성한다.

- 데이터 집계의 기본형
  
  - 시간에 의한 검색이나 참고하는 컬럼 수를 줄여 팩트 테이블에서 필요 데이터를 추출한다.
  
  - 디멘전 테이블과 결합하여 카디널리티를 작게 하여 데이터 마트에 저장할 컬럼을 선택한다.
  
  - 그룹화하여 측정값을 집계한다.
  
  - 예시
    
    ```sql
    SELECT 
        date_trunc('day',a.time) time,
        date_diff('day','b.min_time) days,
        count(*) count
    FROM (
        # 1. 팩트 테이블로부터 필요 컬럼 추출
        SELECT time, session_id FROM access_log
        # 집계 기간 검색으로 카디너리티 축소
        WHERE time BETWEEN TIMESTAMP '2017-01-01' AND TIMESTAMP '2018-01-01'
    ) a
    # 2. 디멘전 테이블과 결합
    JOIN sessions b ON b.session_id = a.session_id
    # 그룹화
    GROUP BY 1, 2
    ```

## 4장. 빅데이터의 축적

### 4-1. 벌크 형과 스트리밍 형의 데이터 수집

#### 객체 스토리지와 데이터 수집

- 빅데이터는 대부분의 경우 확장성이 높은 분산 스토리지(distributed storage)에 저장된다.

- 기본이 되는 객체 스토리지(object storage)가 있으며 Haddop이라면 HDFS, AWS의 S3가 유명하다.

- 데이터 수집(data ingestion)
  
  - 너무 작은 크기의 파일을 저장하거나
  
  - 너무 큰 크기의 파일 저장은 객체 스토리지에 비효율적이므로,
  
  - 작은 크기의 파일을 합치거나, 큰 크기의 파일을 분할하여 적당한 크기의 데이터로 저장하는게 옳다.

#### 벌크 형의 데이터 전송

- 전통적으로 벌크 형 데이터를 데이터 웨어하우스에 저장한다.

- 이러한 데이터 수집을 위한 **ETL서버**(ETL server)를 필요로 한다.

- 일정 주기로 데이터를 수집하여 데이터 전송의 신뢰성을 갖는다.

- 이러한 벌크 형 데이터 전송은 **워크플로 관리도구**의 사용이 적절하다.

#### 스트리밍 형의 데이터 전송

- '웹 브라우저', '모바일 앱', '디바이스' 등에서 즉각적으로 생성되는 데이터의 경우 스트리밍 데이터의 전송을 고려해볼만 하다.

- 다수의 클라이언트에서 계속해서 작은 데이터를 전송하는 **메시지 배송(message delivery)** 을 사용한다.
  
  - 데이터 전송량에 비해 높은 오버헤드가 발생하기 때문에, 서버의 높은 성능을 요구한다.

- NoSQL 데이터베이스가 사용되며 **메시지 큐(message queue)**, **메시지 브로커(message broker)** 등의 중계 시스템으로 일정 간격으로 수집 데이터를 분산 스토리지에 저장한다.

- 웹 브라우저에서의 메시지 배송
  
  - 'Fluetnd', 'Logstash'와 같은 상주형 로그 수집 소프트웨어가 사용된다.
  
  - 또는 자바스크립트로 웹 브라우저에서 직접 메시지를 보내는 **'웹 이벤트 추적(web event tracking)'** 을 사용한다.

- 모바일 앱으로부터의 메시지 배송
  
  - MBaaS(Mobile Backend as a Service)라는 백엔드의 각종 서비스로 벡엔드 데이터 저장소에 저장한 데이터를 벌크형 도구로 수집하거나
  
  - 모바일 용 개발 키드(SDK)로 온/오프라인 상태의 앱에서 SDK 내부에 축적된 데이터를 온라인에 연결시 데이터를 수집한다.

- 디바이스로부터의 메시지 배송
  
  - **'MQTT(MQ Telmetry Transport)'** 라는 TCP/IP로 데이터를 전송하는 프로토콜을 사용한다.
  
  - 일반적으로 **'Pub/Sub 형 메시지 배송(Pub/Sub message delivery)** 의 구조를 갖는다.
  
  - 관리자에 의해 생성된 **'Topic'** 을 클라이언트가 구독(Subscribe)하면 연결되며 메시지를 송수신한다.
  
  - 메시지의 교환을 중계하는 **'MQTT 브로커(MQTT broker)'** 서버와 메시지를 수진하는 **'MQTT 구독자(MQTT subscriber)** 시스템으로 구성된다.

#### [성능 X 신뢰성] 메시지 배송의 트레이드 오프

- 클라이언트가 많아질 수록 스트리밍 형의 메시지 배송은 '성능'과 '신뢰성'이 반비례 관계에 놓이게 된다. 그 이유를 알아보자

#### 메시지 브로커

- 서비스의 규모가 커질수록 메시지 배송의 부하는 커진다.

- 클라이언트의 메시지 전송 증가 -> 서버에서의 수신 실패 -> 클라이언트의 재전송 -> 수신 실패...의 과정이 반복적으로 수행되어 서버 부하는 갈수록 커진다.

- 이러한 부하로 인한 메시지 배송 실패를 방지하기 위해 **메시지 브로커**를 사용한다.
  
  - 오픈소스로 **Apache Kafka**와 클라우드 서비스로 **Amazon Kinesis**가 있다.

- 푸쉬 형과 풀 형
  
  - 송신 측의 제어로 데이터를 송신하는 **Push**
  
  - 수신 측의 주도로 데이터를 수신하는 **Pull**
  
  - 메시지 브로커는 데이터 쓰기 속도를 조정하기 위한 완충 부분으로 푸쉬 형에서 풀 형으로 메시지 배송의 타이밍을 변환한다.
  
  - 메시지 브로커에 데이터를 push하는 **생산자(producer)** 와 pull하는 **소비자(consumer)** 로 구성된다.

- 메시지 라우팅
  
  - 1분마다 총 200MB의 200만번의 데이터 전송이 발생하면 스토리지 서버는 200만의 쓰기 작업을 수행해야 하며 이는 매우 부하가 큰 작업이다.
  
  - 메시지 브로커는 이를 해결한다. 메시지 브로커로 200만번의 데이터 푸쉬가 이뤄지고, 이것을 '소비자'에서 풀한다. (**스트림 처리, stream processing**, 짧은 간격으로 차례대로 데이터를 꺼내서 처리함)
  
  - 메시지 브로커에 써넣은 데이터는 복수의 다른 소비자에서 읽어 들일 수 있다. 이를 통해 메시지가 복사되어 데이터를 여러 경로로 분기하는데 이를 '**메시지 라우팅**(message routing)'라고 한다.

### 메시지 배송을 확실하기 실시하는 것은 어렵다.

- 모바일 회선과 같은 낮은 신뢰성의 네트워크나 분산 시스템의 특성상 메시지의 중복과 누락이 발생하며 이는 **신뢰성(reliablity)** 와 직결된다.
  
  - 대부분의 경우 아래 3가지 중 1개를 보장하도록 설계된다.

- **at most once** - 메시지는 한 번만 전송된다. 도중에 전송 실패로 메시지 결손 가능성이 있다.
  
  - 무슨 일이 일어나도 절대로 메시지를 **재전송(retransmission)** 하지 않는다. 보내는 클라이언트가 한번 보내면 수신 확인 없이 해당 전송은 끝난다.

- **exactly once** - 메시지는 손실되거나 중복 없이 한 번만 전달된다.
  
  - 네트워크상의 두 개 노드의 양 방향 통신을 보장하기 위해 **코디네이터(coordinator)** 가 필수적이다.
  
  - 코디네이터로 exactly once가 가능하나..코디네이터의 shut down으로 인한 일시적 부재나, 코디네이터 의존에 의한 성능상의 문제가 발생한다.

- **at least once** - 메시지는 확실히 전달된다. 같은 것이 여러 번 전달된 가능성이 있다.
  
  - 메시지가 재전송되어도 **중복 제거(deduplication)** 하는 구조가 있다면 중복이 없는 것 처럼 보일 수 있다.
  
  - TCP/IP에 의한 네트워크 통신에서 TCP로 메시지의 수신 확인을 위한 'ack' 플래그로 'at least once'을 실현할 수 있다.
    
    - 메시지마다 패킷 번호를 부여하여 중복되는 패킷 번호의 메시지는 제거하는 방법.
  
  - 메시지 배송에 사용되는 오픈소스 소프트웨어는 'at least once'를 보장한다.. 하지만 중복제거는 사용자의 몫이므로 이를 주의하자.

#### 중복 제거는 높은 비용의 오퍼레이션

- TCP의 메시지 시퀀스 번호로 메시지 중복을 확인할 수 있으나.. 분산 시스템에서는 이를 확인하기 위한 중앙 처리가 필요하다. 
  
  - 힘들게 분산시켜놨는데 또 중앙처리하면.. 성능 하락으로 이어진다.
  
  - 이를 위한 대안으로 아래와 같은 방법이 있다.

- 오프셋을 이용한 중복 제거
  
  - 전송 데이터에 이름을 부여해 그것을 작은 메시지로 배송한다.
  
  - 각 메시지는 파일안의 시작 위치(오프셋)을 덧붙여, 메시지가 중복되어도 같은 파일의 같은 위치에 덮어쓰므로 중복 문제가 해결된다.
  
  - 벌크 형 메시지 전송에 적합하나 스트리밍 형에서는 쓰이지 않는다.

- 고유 ID에 의한 중복 제거
  
  - 스트리밍 형 메시지 배송에서 자주 사용되며 모든 메시지에 'UUID(universally Unique IDentifier)'와 같은 고유 ID를 저장한다.
  
  - 메시지가 늘어남에 따라 ID가 폭발적으로 증가하므로 최근에 받은 ID만을 기억하고 그보다 늦게 온 메시지의 중복은 허용하는 타협방안을 적용한다.

- 종단간(End to End)의 신뢰성
  
  - 성능과 신뢰성의 트레이트 오프 관계로..빅데이터의 메시지 배송에서는 종종 신뢰성보다 '효율'을 중시한다.
  
  - 중간 경로에 **'at least once'를 보장**하는 한편, '**중복 제거는 하지 않는 것**'이 **표준적인 구현**이다.

- 신뢰성이 높은 메시지 배송을 실현하려면 중간 경로를 모두 'at least once',로 통일한 후, 클라이언트 상에서 모든 메시지에 고유 ID를 할당하고 경로의 말단에서 중복 제거를 실행해야 한다.

- 고유 ID를 사용한 중복 제거의 방법
  
  - NoSQL 데이터베이스인 Cassandra와 Elasticsearch는 특성상 데이터를 쓸때 고유 ID를 지정해야 하므로 동일 ID의 데이터는 덮어쓰므로 중복 제거가 해결된다.
  
  - 보내온 데이터를 일단 그대로 객체 스토리지에 저장후, 읽어 들이는 단계에서 SQL을 사용하여 중복을 제거한다. 이는 대규모 데이터 처리이므로 메모리에서 실행이 불가능하므로 `Hive`같은 배치형 쿼리 엔진에서 실행한다.

#### 데이터 수집의 파이프라인

- 클라이언트 - 프론트엔드 - 메시지 브로커 - 소비자 - 분산 스토리지(- 중복 제거 - 데이터 구조화) 와 같은 일련의 프로세스로 장기적 데이터 분석을 위한 **'데이터 수집의 파이프라인'** 이 완성된다.

- 위 구조의 모든 요소를 구성하는게 아닌 요구 사항, 기존 시스템의 구조, 여러 환경 제약 등을 고려하여 필요와 목적에 맞게 파이프라인을 구성해야 한다.

- 중복을 고려한 시스템 설계
  
  - 빅데이터를 다루는 시스템은 매우 높은 성능을 요구하기 때문에 (필연적으로 발생하게 되는) 아주 작은 중복은 무시하는 경향이 있다.
  
  - 때문에 '중복이 있어도 문제가 되지 않는' 시스템을 설계하는게 중요하다.
  
  - 트랜잭션과 같이 신뢰성이 중시되는 경우 스트리밍 형 메시지 배송보다는 벌크 형을 선택하는게 좋다.

### 4-3. 시계열 데이터의 최적화

- 스트리밍 형의 메시지 배송에서 고려해야할 '메시지가 도착할 때까지의 시간 지연' 문제에 대해 알아보자

#### 프로세스 시간과 이벤트 시간

- 실시간으로 전송되는 데이터의 지연은 자주 발생한다.

- 클라이언트 상에서 메시지가 생성된 시간을 '**이벤트 시간(event time)**', 서버가 처리하는 시간을 '**프로세스 시간(process time)**'이라고 한다.
  
  - 데이터 분석 대상은 '이벤트 시간'으로 생성 이후 처리에 소모되는 프로세스 시간에 의해 문제가 발생한다.

#### 프로세스 시간에 의한 분할과 문제점

- 1월 1일에 발생한 이벤트를 수집한다고 했을때, 해당 일에 메시지를 수집한다고 해서 일괄적인 수집이 가능한게 아니다. 프로세스 시간에 의한 지연으로 이벤트 시간(1월 1일)에서 지난 시간에야 원하는 모든 이벤트를 수집할 수 있다.

- 분산 스토리지에 스트리밍 데이터를 저장하는 경우, 프로세스 시간을 기준으로 데이터를 저장한다.
  
  - 1월 1일의 이벤트를 수집하기 위해선 1달 이후인 2월 1일에 1월달에 저장된 모든 메시지를 검토하여 1월 1일 데이터를 추출한다.
  
  - 하지만 엄청난 양의 데이터를 특정 시간의 데이터를 검색하는건 시간과 자원을 낭비하는 처리이다.
  
  - 위와 같은 처리를 '**풀 스캔(full scan)**'이라고 한다. 이는 시스템 부하를 크게 높이는 요인 중 하나다.

#### 시계열 인덱스

- Cassandra와 같은 분산 데이터베이스에서는 데이터가 '**시계열 인덱스(time-serires index)**'로 대응하는 구조로 데이터 수집시 처음부터 이벤트 시간으로 인덱스 된 테이블을 만들 수 있다.

- 하지만 장기간에 대용량 데이터를 집계하는 경우 분산 데이터베이스는 효율적이지 않다.
  
  - 집계 효율을 높이기 위해 열 지향 스토리지를 지속적으로 만들어야 한다.

#### 조건절 푸쉬다운

- 매일 한번 씩 도착한 데이터를 배치 처리로 변환하여 지속적으로 열 지향 스토리지에 정렬된 형식으로 데이터를 저장할 수 있다.

- 이러한 열 지향 스토리지에는 '칼럼 단위의 통계 정보'를 이용한 최적화가 이뤄진다.
  
  - 동일 프로세스 시간에 처리된 메시지를 이벤트 시간 기준으로 정렬하여 저장 -> 원하는 데이터 추출 가능

- 필요한 최소한으 데이터를 읽도록 하는 최적화를 '**조건절 푸시 다운(predicate pushdown)**'이라고 한다.
  
  - 데이터가 정렬되어 저장된 열 지향 스토리지에서 조건절 푸시 다운을 통해 풀 스캔을 방지할 수 있다.

#### 이벤트 시간에 의한 분할

- 프로세스 시간으로 분할된 데이터베이스에 동일 이벤트 시간 데이터가 여러 파일로 분산된다.

- 이때 이벤트 시간 기준으로 다시 테이블을 분산 할 수 도 있다.
  
  - 테이블을 물리적으로 분리하는 테이블 파티셔닝 중 시간을 이용하여 분할된 테이블을 '**시계열 테이블(time-series table)**'이라고 한다.
  
  - 프로세스 시간으로 분리된 열 지향 스토리지에서 다시 이벤트 시간을 기준으로 시계열 테이블을 생성하면 쿼리 엔진은 특정 시간의 이벤트를 모든 열 지향 스토리지에서 찾는게 아닌 특정 시간의 시계열 테이블에서 데이터를 추출하면 된다.

- 이때 또 발생하는 문제가 1개의 열 지향 스토리지에는 넓은 범위의 이벤트 시간 데이터가 존재하고.. 그 만큼 자잘한 여러 시계열 테이블에 쓰기 작업을 실행한다.
  
  - 이로 인해 분산 스토리지에는 대량의 작은 파일이 생성되고 이는 쿼리엔진의 성능 악화로 이어진다.

#### 데이터 마트를 이벤트 시간으로 정렬하기

- 그래서 또 좋은 방법이 프로세스 시간으로 수집된 열 지향 스토리지에서 다시 이벤트 시간으로 분리된 여러 시계열 데이터로 저장하는게 아닌,

- 1개의 데이터 마트에 저장하면서 이벤트 시간에 의한 정렬을 함께 수행한다.

- 이러면 파일이 조각나 쿼리엔진에 부하를 발생하지 않고 항상 최적의 데이터 마트를 유지할 수 있다.
  
  - 아마 데이터 마트의 구조를 읽고쓰기에 특화되도록 구성해야 하지 않나 싶다.

### 4-4. 비구조화 데이터의 분산 스토리지

#### [기본 전략] NoSQL 데이터베이스에 의한 데이터 활용

- 빅데이터를 위한 분산 스토리지는 확장성과 어떤 데이터이든 저장 가능한 유연성이 요구된다. 

- 그 중 객체 스토리지는 파일을 교체하기 어렵다. 교체를 위해선 통째로 교체를 진행해야 한다.
  
  - 쓰기 작업을 위해 별도 RDB로 스냅샷하거나 다른 '**분산 데이터베이스(distributed database)**'에 저장하도록 한다.
  - 또한 저징 데이터르 집계할 수 있기 까지 열 지향 스토리지를 작성해야 하므로 그 시간이 오래 걸린다. 데이터 기록 직후 활용을 위해서는 실시간 집계와 검색에 적합한 데이터 저장소가 필요하다.

- "**특정 목적에 적합한 NoSQL 데이터베이스**"의 종류에 대해 알아보자.

#### 분산 KVS

- '**분산 KVS(distributed key-value store)**'는 모든 데이터를 키값 쌍으로 저장하도록 설계된 데이터 저장소를 말한다.

- 모든 데이터에 고유의 키를 지정하고 그것을 부하 분산을 위해 이용한다.
  
  - 고유 키가 정해지면 해당 값을 클러스터내의 어느 노드에 배치할 지 결정한다.

- 이러한 구조로 노드 간에 부하를 균등하게 분산하고 노드를 증감하는 것만으로 클러스터의 성능을 변경할 수 있다.
  
  - 마스터 - 슬레이브 구조에서는 마스터 노드가 shut down되면 데이터에 접근할 수 없지만,
  
  - P2P구조에서는 모든 노드가 대등한 관계이기 때문에 단일 실패점이 없다.

#### Amazon DynamoDB

- 클라우드 서비스에 NoSQL이 통합된 예로 AWS의 'Amazon DynamoDB'가 있다.

- DynamoDB는 항상 안정된 읽기 쓰기 성능을 제공하도록 디자인된 분산형 NoSQ 데이터베이스로 하나 또는 두 개의 키에 연결하는 형태로 임의의 스키마리스 데이터를 저장할 수 있다.

- 간단한 분산 KVS보다는 도큐먼트 스토어로 사용 가능하다.

- P2P 분산 아키텍쳐를 갖으며, 미리 설정한 초 단위의 요청 수에 따라 노드가 증감한다.
  
  - 급격한 요청에도 노드를 증가시켜 데이터의 읽기 및 쓰기에 지연을 방지한다.

- DynamoDB의 데이터를 분석하려면 동일 AWS 서비스인 Amazon EMR 및 Amazon Redshift등과 결합하여 Hive에 의한 배치 처리를 실행하거나 데이터 웨어하우스에 데이터를 전송하도록 한다. 또는 고유 기능인 'DynamoDB Streams'를 활용하여 데이터 변경 이벤트를 외부로 전송하여 실시간 스트림 처리가 가능하다.

#### 와이드 칼럼 스토어

- 분산 KVS에서 발전시켜 2개 이상의 임의의 키에 데이터를 저장할 수 있도록 한 것이 '**와이드 칼럼 스토어(wide-columns store)**'이다. 'Google Cloud Bigtable', 'Apache HBase', 'Apache Cassandra'등이 대표적이다.

- 와이드 컬럼 스토어에서는 내부적으로 행 키와 컬럼 명의 조합에 대해 값을 저장한다.
  
  - 테이블에 새로운 행 추가하는 것과 같이 칼럼도 얼마든지 추가할 수 있다.
  
  - 하나의 테이블에 가로와 세로의 2차원(또는 그 이상)에 데이터를 쓸 수 있다.

- 와이드 컬럼 스토어의 데이터 저장 방법
  
  |      | col1   | col2   | ... |
  | ---- | ------ | ------ | --- |
  | row1 | value1 | value2 |     |
  | row2 | value3 | value4 |     |
  | ...  |        |        |     |
  
    위와 같은 데이터를 아래와 같이 저장한다. 
  
  | 행 키  | 칼럼 명 | 값      |     |
  | ---- | ---- | ------ | --- |
  | row1 | col1 | value1 |     |
  |      | col2 | value2 |     |
  | row2 | col1 | value3 |     |
  |      | col2 | value4 |     |

#### Apache Cassandra

- 오픈 소스 와이드 칼럼 스토어로 'Apache Cassandra'가 있다.
- 내부적인 데이터 저장소로 와이드 칼럼 스토어를 이용하면서도 높은 수준의 'CQL'이라는 쿼리 언어가 구현되어 있다.(SQL과 비슷한 감각으로 사용가능)
- 테이블의 스키마를 결정할 필요가 있기 때문에 구조화 데이터만 취급할 수 있다.
  - RDB와 비슷해 보이지만 쿼리의 의미가 다르다. `INSERT INTO`는 '추가 또는 갱신(upsert)'로 동작해 동일한 키를 가진 레코드가 존재하면 덮어쓴다.
- P2P형 분산 아키텍처를 갖으며 지정 키에 의해 결정된 노드에 해당 키와 관련된 모든 값을 저장한다.
  - 사용자 ID를 키로 지정하면 해당 사용자에 대한 기록은 하나의 노드에만 모이고 해당 노드 안에서 쿼리가 실행된다.
  - 1억명의 활성 사용자가 있는 메시지 서비스에서 매일 수십억 레코드가 추가될 때, 사용자 ID를 키로 데이터를 분산하고 메시지의 타임스탬프로 레코드를 분리함으로써 사용자별 타임 라인을 구축할 수 있다.
    - CQL에서는 이러한 거대한 테이블을 '**복합 키(compound key)**'를 이용하여 실현한다.
- 와이드 컬럼 스토어도 분산된 모든 노드에서 데이터를 모아야 하므로 집계작업에 적합하지 않다. 이를 위해 Hive, Presto, Spark 등의 쿼리 엔진을 이용해 데이터를 추출해야 한다.

#### 도큐먼트 스토어

- '**도큐먼트 스토어(document store)**'는 JSON처럼 복잡하게 뒤얽힌 스키마리스 데이터를 그대로의 형태로 저장하고 쿼리를 실행한다.
  
  - 와이드 컬럼 스토어가 '성능 향상'을 목표로 하는 반면, 도큐먼트 스토어는 '데이터 처리의 유연성'을 목적으로 한다.

- 간단한 분산 KVS도 JSON텍스틀 저장할 수 있으나 그에 대한 복잡한 쿼리를 실행할 수 있다고 말할 수 없다.
  
  - 도큐먼트 스토어는 배열과 연상 배열과 같은 중첩 데이터 구조에 대해 인덱스를 만들거나 도큐먼트 일부를 치환하는 식의 쿼리를 쉽게 실행할 수 있다.

- 가장 큰 장점으로는 스키마를 정하지 않고 데이터 처리를 할 수 있다.
  
  - 외부 데이터를 저장하거나
  
  - 시스템의 데이터 및 로그 저장에 적합하다.

#### MongoDB

- 오픈 소스 분산형 도큐먼트 스토어로 'MongoDB'가 있다.

- 성능을 우선시 하고 신뢰성을 희생했지만, 간편하다.

- 여러 노드에 데이터를 분산할 수 있지만, 그 자체는 대량 데이터의 집계에 적합하지 않다.
  
  - 데이터 분석이 목적인 경우 쿼리 엔진으로 접속하여 데이터를 추출할 필요가 있다.

#### 검색 엔진

- '**검색 엔진(search engine)**'은 '**역 색인**'을 형성하여 텍스트 데이터 및 스키마리스 데이터를 집계하는 데 사용된다.
  
  - 역 색인으로 인해 데이터 기록 시스템의 시스템 부하 및 디스크 소비량은 커지지만 그 덕분에 키워드 검색이 훨씬 고속화된다.

- 장기적으로 데이터를 축적하기보다는 실시간 집계 시스템의 일부로 이용된다.

#### Elasticssearch

- 인기있는 오픈 소스 검색엔진으로 로그 수집 소프트웨어 'Logstash', 시각화 소프트웨어 'Kibana'와 함께 'ELK 스택' 또는 'Elastic 스택'으로 자주 이용된다.

- 임의의 JSON 데이터를 저장할 수 있기 때문에 도큐먼트 스토어와 비슷하지만, 아무것도 지정하지 않으면 모든 필드에 색인이 만들어진다.
  
  - 텍스트 데이터에서는 역 색인이 구축되어 간단한 도큐먼트 스토어와 비교하여 쓰기의 부하가 크고. 필요에 따라 명시적으로 스키마를 결정함으로 색인을 무효화하는 식의 튜닝이 필요하다.

- 자체 쿼리 언어에 의한 고급 집계 기능을 제공한다.
  
  - 표준 쿼리 언어를 사람의 힘으로 작성하는건 너무 복잡하므로 Kibana를 이용하거나 프로그램 내부에서 호출하는 것이 주요한 사용법이다.

#### Splunk

- '**Splunk(스플렁크)'** 는 상용 검색 엔진으로 텍스트 데이터를 집계하기 위한 도구이다.

-  웹 서버나 네트워크 기기로 출력되는 로그 파일이나 JSON 파일을 다루어 텍스트 처리한 비정형 데이터에 적합하다.
  
  - 키워드 입력시 해당 키워드를 포함하는 로그 정보를 찾는 등의 기능을 수행한다.

### 4-5. 정리

- 해당 장에서는 '**데이터를 모아서 분산 스토리지에 저장**'하기까지의 '**데이터 수집의 흐름**'을 설멍하었다.
  
  - 빅데이터의 효율적 집계를 위해 '**장기적인 데이터 분석**'을 가정한 '**스토리지**' 마련이 필수적이다.

- 너무 자주 데이터를 복사하면 데이터가 잘게 분열되어 '**집계 효율**'은 악화된다.
  
  - '**벌크 형의 데이터 전송**'이면 한번에 대량 데이터를 복사하기에 문제가 되지 않지만
  
  - '**스트리밍 형의 데이터 전송**'은 작은 메시지가 대량으로 들어오므로 그것을 정기적으로 모아서 기록하는 아이디어가 필요하다.

- '**다수의 클라이언트**'에서 실시간으로 '**데이터를 수집**'하는데 '**메시지 배송 방식**'이 사용된다.
  
  - '**메시지 브로커**'를 도입함으로 분산 스토리지에 쓰는 '**속도를 안정화**'할 수 있다.
  
  - 메시지를 여러 경로로 '**라우팅**'함으로 동일 데이터를 '**스트리밍 처리 및 배치 처리 모두에서 사용**'할 수 있다.

- 메시지 배송에서는 효율을 중시하여 '**트랜잭션 처리를 하지 않는 경우**'가 많아 잠재적으로 데이터가 중복되거나 누락될 가능성이 있다.
  
  - '**at least once**'를 통해 데이터의 누락을 피하지만 중복 제거의 경우 사용자의 책임이다.
  
  - 실제로 '**약간의 중복을 허용**'한 후에 '**신뢰성이 요구되는 부분에서 벌크 형의 데이터 전송**'하는게 일반적이다.

- 메시지 배송 방식이 아닌 '**NoSQL 데이터베이스와 같은 분산 스토리지**'에 직접 데이터를 쓰는 방법도 있다.
  
  - 읽기/쓰기엔 우수하지만 집계는 비효율적인 NoSQL에서는 '**집계**'를 위해서 '**쿼리엔진과 연결하여 애드 혹 분석**'을 하거나 '**정기적으로 데이터를 꺼내 장기적인 데이터 분석을 준비**'한다.

## 5장. 빅데이터의 파이프라인

- 빅데이터 파이프라인을 자동화하는 구조에 대해 알아보자.

---

- 레퍼런스

> 빅데이터를 지탱하는 기술
