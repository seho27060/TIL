[TOC]

# Apache Kafka 시리즈 – 초보자를 위한 아파치 카프카 강의 v3

## Section 01. 강의 소개

### 1. 강의 소개

- \~ 

### 2. Apache Kafka 간단 소개

- 분산형, 회복성있는, 고장에 내성이 있는 시스템

- 수평적 확장 가능

- 고성능 

## Section 02~03

- 생략

## Section 04. 카프카 이론

### 7. 토픽, 파티션, 오프셋

#### 토픽(topics)

- 특정한 데이터 스트림

- DB의 테이블과 같음

- 이름을 통해 할당함

- 모든 형태의 메시지를 수용한다. 
  
  - 메시지의 순서를 "데이터 스트림"이라고 한다.

- query로 토픽을 다룰 순 없지만, Producer아 Consumer를 통해 데이터를 쓰거나 읽을  있다.

- 카프카의 토픽에 **저장된 데이터는 불변(immutable)** 하다
  
  - 한번 저장된 데이터는 변경될 수 없다.

#### 파티션과 오프셋(Partitions and offsets)

- 토픽은 여러개의 파티션으로 분할 할 수 있다.
  
  - 메시지들은 각 파티션에 **순서대로 정렬되어 저장된다.**
  - 순서는 각 파티션에 국한되며 다른 파티션에 호환되지 않는다.

- 파티션0(0  \~ 10), 파티션1(0 \~ 5)..와 같은 식으로 저장되며 이 순서대로 증가하는 id를 Kafka 파티션 오프셋이라고 한다.

### 8. 프로듀서 & 메시지 키

#### Producer

![](.\01.png)

- 토픽에 데이터를 작성하는 프로듀서

- 프로듀서는 어떤 파티션에 데이터를 작성했는지 인지한다.

- 브로커가 실패한다면 프로듀서는 자동으로 회복한다.

#### Producer: Message keys

- 프로듀서는 메시지와 함께 key를 선택하여 송신할 수 있다.

- 키가 null이라면 라운드 로빈으로 동작한다.

- 널이 아니라면 키에 따라 동일한 파티션에 저장한다.(해싱)

![](.\02.png)

#### Kafka Message Serializer

- 카프카는 입력값을 바이트만 허용하며, 바이트 데이터를 컨슈머로 송신한다.

- key와 value 값의 데이터 형태를 byte로 자동으로 serialize한다.

### 컨슈머 & 역직렬화

#### Consumers

- 기본적으로 Pull model이다.

- 브로커가 컨슈머로 데이터를 송신하는게 아닌, 컨슈머가 브로커로부터 데이터를 끌어온다.

- 프로듀서와 마찬가지로 브로커가 고장나면 컨슈머는 다오으로 어떤 다른 브로커로부터 데이터를 가져올 지 안다(automaticall recover failure)

#### Consumer Deserializer

- 프로듀셔 -> 브로커로는 직렬화된 데이터가 송신되므로, 컨슈머는 브로커로부터 가져온 데이터를 Deserialize 한다.

- 데이터 타입은 사전에 정해짐을 가정하므로 새로운 데이터를 송신하기 위해서는 새로운 토픽을 지정하여 데이터를 송신해야 한다.

### Consumer Groups

- 어플리케이션의 모든 컨슈머는 컨슈머 그룹으로 묶여 데이터를 읽는다.

- ![](.\03.png)

##### Consumer Groups - What if too many consumers?

- 컨슈머가 파티션 개수보다 많으면 어떻게 될까?

![](.\04.png)

- 컨슈머들은 각 파티션에 매핑되고 남는 컨슈머는 대기 상태가 된다.

#### Multiple Consumers on one topic

![](.\05.png)

- 왜 여러개의 그룹이 있을까?

- 각 그룹은 하나의 서비스에 대해 매핑되어 사용한다.

#### Consumer Offsets

- 그룹의 컨슈머가 데이터를 가져오면, 주기적으로 오프셋을 커밋한다.

- 컨슈머가 죽는 경우 오프셋을 통해 어떤 부분부터 데이터를 다시 읽기 시작하면 되는지 알 수 있게 되어 resilience가 가능하다.

#### Delivery semantics for consumers

- 이렇게 컨슈머는 다양한 전달 의미론(delivery semantics)를 갖는다.

- 기본적으로 자바 컨슈머는 최소 한번 오프셋을 커밋하며

- 수동 커밋으로 전환할 경우 3개의 전달 의미론중 선택하여 사용한다.
  
  - 최소 한번(at least once)
  
  - 최대 한번(at most once)
  
  - 정확히 한번(exactly once)

### 11. 브로커 & 토픽

#### Kafka Brokers

- 카프카 클러스터는 다수의 브로커로 구성되어 있다.

- 각 브로커는 id로 구분된다.

- 각각의 브로커는 특정 파티션이 포함된다.

- 어떤 브로커에 연결되면 전체 클러스터에 연결되는 것과 같다.

- 브로커에는 다양한 토픽들의 파이션이 분산되어 존재한다.
  
  - 이걸 수평적 스케일링이라고 한다.
  
  - ![](.\06.png)

#### Kafka Broker Discovery

- 모든 카프카 브로커들은 bootstrap server 라고 한다.

- 카프카 클라이언트가 카프카 클러스터의 어떤 한 브로커와 연결하면, metadata를 받으며 이 메타데이터에는 클러스터에 존재하는 전체 브로커에 대한 정보(토픽, 파티션 정보)를 포함한다.
  
  - 클라이언트가 1개의 브로커를 연결하면 전체 클러스터와 연결된다는게 위를 의미한다.

### 12. 토픽 복제

#### Topic replication factor

- 토픽들은 replication factor(복제 요소)를 1보다 크게 가져야한다.

- 이를 통해 어떤 브로커가 다운되어도 또다른 브로커가 데이터 사본을 소지하여 회복성을 갖는다.
  
  - 브로커가 3개이고 토픽의 복제 계수가 2라면, 총 2개의 브로커에 1개 토픽에 대한 데이터 사본들이 저장된다.

#### Concept of Leader for a Partition

- 복제 계수로 여러개의 토픽 데이터 사본에 사용되는게 아닌, 여러 사본 중 파티션 리더를 통해서만 프로듀서가 브로커로 데이터를 송신한다.
  
  - 컨슈머도 역시 파티션 리더로부터만 데이터를 읽는다.

- 만약 브로커가 다운되어 파티션 리더가 부재하면, 다른 데이터 사본을 리더로 재선출하여 데이터 송신을 지속한다.

##### Kafka Consumers Replica Fetching

- 카프카 2.4 버전 이상에서 추가된 기능

- 컨슈머가 가장 가까운 파티션에서 데이터를 읽는 기능이다.

- 기존에 파티션 리더를 통해서만 데이터를 읽는게 아닌, 리더가 아닌 다른 ISR(in sync replica)로부터 데이터를 읽음으로서 레이턴시를 줄일 수 있다.

### 13. 프로듀서 확인 & 토픽 내구성

#### Producer Acknowledgements(acks)

- 프로듀서는 데이터 쓰기 확인을 선택할 수 있다.
  
  - acks=0: 프로듀서가 확인을 기다리지 않음
  
  - acks=1: 프로듀서가 리더의 확인을 기다림
  
  - acks=2: 리더와 레플리카의 확인을 기다림

### 14. 주키퍼

#### Zookeeper

- 카프카 브로커 매니저

- 파티션 리더의 선출을 담당한다.

- 카프카 내부의 변경을 알린다. 토픽의 생성, 삭제 등등등..

- 다만 카프카 2.x부터는 주키퍼없이 가동된다.

- kafka 3.x부터는 kafka raft로 대체된다.

- 리더와 팔로워로 구성된다.

##### 주키퍼를 사용하는 이유

- 카프카 브로커를 사용할 때는, 카프카 4.0부터는 주키퍼를 전혀 사용하지 않지만 실제 프로덕션 환경에서는 최신 버전 반영이 어려우므로 여전히 사용함에는 다름없다.

- 카프카 클라이언트로는 카프카에서 주키퍼의 역할을 수행하는 것이 안전하기 때문에 사용을 지양한다.

### 15. Kafka Kraft - 주키퍼 지우기

- 카프카 클러스터가 10만개 이상의 파티션을 갖는다면 주키퍼에서 스케일링 이슈가 발생하여 2020부터 주키퍼 사용을 지양하는 방향이다(KIP-500)

- 카프카 3부터는 kraft가 주키퍼 기능을 대체하여 제공되며 4부터는 안쓴다고 한다.

## Section 05. 카프카 시작하기

- 실제로 카프카를 사용해보자!

### 19. Conduktor로 Kafka 시작하기

- 강의에서 제공하는 플랫폼

블라블라. 어쩌고 운영체제에 맞는 환경을 구성하자

#### --. WSL2 로컬에서 Kafka 서버 실행

- kafka-storage.sh 로 저장공간 uuid 생성 및 포매팅 후

- `kafka-server-start.sh ~/kafka_2.13-3.0.0/config/kraft/server.properties`로 카프카 실행

## Section 07. CLI 기초

### 36. 카프카 토픽 CLI

- 토픽 생성, 리스트, 생성, 파티션 증가, 삭제 등

### 37. 카프카 콘솔 프로듀서 CLI

- `kafka-consloe-producer.sh`를 통한 프로듀싱.
  
  - key없이 프로듀싱 - 전체 파티션에 배분
  
  - key를 포함하는 프로듀싱 - 같은 키는 같은 파티션에 배분

- CLI를 통해 특정 토픽에 연결하여 메세지를 프로듀싱할 수 있다.
  
  - 프로퍼티 값을 주어 원하는 옵션도 같이 줄 수 있다.

- 이때 존재하지 않는 토픽에 연결 후 프로듀싱하면 자동으로 해당 토픽이 생성되나, 이는 권장하지 않는다.
  
  - 사전에 브로커에 토픽을 생성 후 사용하도록 한다.

### 38. 카프카 콘솔 컨슈머 CLI

- 브로커의 토픽 메시지를 읽는 법
  
  - 토픽의 최신 메시지부터 읽는 법(Consume from tail of the topic)
  
  - 토픽의 처음 메시지부터 읽는 법(Consume from the beginning of the topic)

- 메시지 프로듀싱 시 토픽의 파티션이 있다면 생성된 메시지들은 여러 파티션에 분배된다.

### 39. 카프카 컨슈머 그룹

- 그룹을 생성하여 같은 그룹내에 여러 컨슈머를 생성할 수 있다.
  
  - 그룹: 컨슈머를 묶는 논리 단위
  
  - 같은 그룹내에서는 오프셋 정보가 공유되어 메시지를 순서대로 읽을 수 있다.

- 토픽의 파티션이 3, 컨슈머가 3개를 초과하여 생성된다면 토픽의 파티션 개수만큼의 컨슈머는 작동하고 나머지 컨슈머들은 대기 상태로 메시지를 읽을 수 없게 된다.

### 39. 카프카 컨슈머 그룹 CLI

- 컨슈머 그룹을 재설정, 삭제 등 수행

- 

## Section 09. Kafka Java 프로그래밍 기초

### 44. Kafka 프로젝트

- Java로 Kafka 프로젝트 만들기    

- 프로듀서
  
  - 데이터 송신
  
  - 콜백 : 레코드가 성공적으로 송신되거나 예외 발생시 실행되는 함수
    
    - 라운드 로빈
    
    - 스티키파티셔너: 짧은 시간내에 여러 메시지가 송신되어 카프카가 일괄처리(batch)를 가능하다고 판단하면 라운드로빈으로 순서대로 레코드를 송신하는게 아닌 같은 파티셔너에 레코드를 송신한다.

### 47. Java 프로듀서와 키

- 같은 키를 같은 레코드는 같은 파티션으로 전송된다.

### 48. Java 컨슈머

- 프로듀서로 생성한 레코드를 읽어보자

- 프로듀서와 같이 프로퍼티를 설정
  
  - `auto-offset-reset`으로 브로커 토픽의 레코드의 처음부터, 현재부터 등 읽을 시점을 설정할 수 있다.

- 토픽(들)을 subscribe하고 poll하여 레코드를 읽는다.

- 컨슈머가 메시지를 읽다가 중단되어도, offset이 커밋되어 메시지를 읽는 순서를 기억하므로, 재기동하면 읽었던 곳부터 다시 읽는다.
  
  - 이때 graceful shutdown이 아니라면 오프셋을 다시 찾는데 시간이 소모되므로, 효율적인 운용을 위해서는 gracefult shutdown 적용이 필요하다.

### 49. Java 컨슈머 - 우아한 종료

- gracefully shutdown : 예상치 못한 상황에서 컨슈머를 안전하게 종료한다.

- `Runtime.getRuntime().addShutdownHook` 로 셧다운후크를 추가하여 컨슈머의 중단을 감지하면 `consumer.wakeup()`과 같은 메서드로 새로운 스레드로 메인스레드에 join한다.

- 컨슈밍하는 부분을 try-catch로 감싸 finally를 통해 `consumer.close()`한다면 예상치 못한 중지에 대응하여 컨슈머를 close하고 읽는 중이던 레코드를 취소하고 오프셋을 커밋한다.

- 이러한 과정으로 예상치 못한 컨슈머 중지 이후에도 재기동 후 기존에 읽던 레코드를 빠르게 찾아 다시 컨슈밍을 시작할 수 있다.

### 50. 컨슈머 그룹 내 Java 컨슈머

- 같은 그룹내에서 컨슈머 리밸런싱이 작동하는 방식

- 파티션이 3개인 토픽에 3개의 컨슈머가 연결되면, 각 컨슈머는 파티션을 1개 씩 가져간다.
  
  - 만약 3개 컨슈머 중 1개가 작동 중지한다면, 나머지 2개 컨슈머 중 1개가 남는 파티션을 가져간다.

### Java 컨슈머 점진적 협력적 리밸린성 & 동적 그룹 멤버십

- 리밸런싱 : 컨슈머들 사이에서 파티션을 이동시키는 동작
  
  - 컨슈머가 그룹에 새로 합류하거나, 떠날 때 리밸런싱이 동작
  
  - 토픽에 새로운 파티션을 추가할때도 동작한다.

#### 리밸런싱 전략

- Eager Rebalance(적극적 리밸런싱)
  
  - 기본 행동 전략
  
  - 그룹에 컨슈머가 새로 추가되면, 컨슈머들의 읽기가 중단되고 파티션과의 연결도 끊긴 후 파티션들을 각 컨슈머에 새롭게 할당한다.
  
  - 컨슈머들의 읽기가 중단되는 걸 "stop the world" 이벤트라고 하는데, 2개 컨슈머가 같은 1개 파티션을 읽는 중이던가과 같은 상황에 stop the world 이벤트를 발생시키고 싶지 않을 수 있다.

- Cooperative Rebalance(Incremental Rebalance, 협력적 리밸런싱, 점진적 리밸런싱)
  
  - 모든 파티션을 모든 컨슈머에 재할당하는 것이 아닌, 1개 컨슈머와 연결된 작은 부분의 파티션을 다른 컨슈머에 재할당한다.
  
  - 모든 파티션이 재할당되는 것이 아니므로, 타겟 컨슈머를 제외하고는 중단되지 않는다.

- 카프카 컨슈머에 `partition.assignment.strategy`에 옵션을 주어 원하는 리밸런싱 전략을 사용할 수 있다.
  
  - Eager Rebalance : RangeAssignor, RoundRobin, StickyAssignor
  
  - Cooperative Rebalance: CooperativeStickyAssignor

- kafka connect, kafka stream에서는 기본 전략이 다르다.

#### Static Group Membership

- 컨슈머가 그룹을 떠날 경우 연결된 파티션은 재할당된다.
  
  - 컨슈머가 다시 그룹에 합류하면 새로운 member id를 할당받고 새로운 파티션들도 할당된다. 즉 리밸런싱은 동적으로 할당한다.

- 이때 컨슈머에 `group.instance.id`를 설정하면 정적 멤버(static member)로 등록되어 컨슈머가 동일한 파티션과 연결할 수 있다.

- 쿠버네티스와 같은 환경에서 유용하다.

### 53. Java 컨슈머 자동 오프셋 커밋 행동

- Java Consumer API는 오프셋을 정기적으로 커밋한다.

- 컨슈머가 `.poll()` 메서드를 호출할때 오프셋은 커밋된다.

## Section 11. 카프카 위키미디어 프로듀서 및 고급 프로듀서 구성

### 58. 위키미디아 프로듀서 프로젝트

- 위키미디아에서 변경되는 데이터 스트림을 프로듀싱하여 컨슈밍을 통한 데이터 활용을 해보자

### 62. 프로듀서 Acknowledgements 더 깊이 살펴보기

#### Producer Acknowledgements(acks)

- 프로듀서는 데이터 쓰기의 Acknowledgements(확인) 수령을 선택할 수 있다.
  
  - acks = 0: 프로듀서는 확인을 기다리지 않는다.
  
  - acks= 1: 리더 브로커의 확인을 기다린다.
  
  - acks= all: 리더와 레플리카 모두에게 확인을 기다린다.

##### Producer: acks=0

- 프로듀서가 메시지가 전송한 순간 메시지 쓰기가 성공했다고 확인한다.

- 실패나 예외가 발생할 경우 프로듀서는 알 수 가 없다.(데이터 손실 가능성 존재)

- 보통 데이터 처리량이 많을때 사용한다.

##### Producer: acks=1

- 프로듀서는 리더 브로커에게 확인을 받으면 데이터 전송에 성공했다고 간주 한다.

- 이때 리더 브로커에게만 확인을 받으므로 레플리카에 데이터가 복제됐는지 확신하지 못한다.(데이터 복제 실패지 데이터 손실 가능성 존재)

##### Producer: acks=all

- 프로듀서는 리더 브로커와 모든 레플리카에게서 데이터 전송 확인을 받는다.
  
  - 카프카 3.0부터는 기본 값

- 해당 옵션과 같이 `min.insync.replicas`가 사용된다.
  
  - 이는 리더 레플리카가 데이터를 성공적으로 쓰기 작업을 완료했다고 간주하는 값이다.
  
  - `min.insync.replicas=1`이라면 리더 브로커만 성공적으로 ack를 반환하고
  
  - 2라면 리더 브로커와 다른 1개의 레플리카가 ack를 반환한다.
  
  - `min.insync.replicas=2`이고 브로커의 복제계수가 3인 상태에서 3개중 2개 브로커가 죽는다면, 리더 브로커는 충분한 확인(acks)가 발생하지 않았으므로 예외를 발생시킨다.

#### Kafka Topic Availability

- 카프카 토픽의 가용성에 대해 고려한다면 acks 옵션과 `min.insync.replicas`와 연관된다. 아래 설명에서 브로커 복제계수가 3이라고 가정한다.
  
  - acks가 0 또는 1이라면 1개 레플리카(리더 포함)만 살아있다면 가용성이 용인되지만
  
  - acks가 2라면 3개 브로커중 1개 브로커의 shutdown까지 용인되는 가용성을 갖는다.
  
  - acks가 3이라면 카프카의 본래 가용성이 무의미하다. 3개 브로커 중 단 한개의 브로커의 shutdown이 용인되지 않으므로
  
  - 따라서 `acks=all`일때, `replication.factor`(복제계수)=N이고 `min.insync.replicas`=M이라고 한다면 해당 브로커에서는 카프카 토픽 가용성은 N-M만큼 용인된다.

- 가용성이란 데이터 쓰기 작업의 가능 여부를 의미한다.

### 63. 프로듀서 재시도

#### Producer Retries

- 데이터 전송 실패를 대비하여 개발자는 예외처리에 고려해야한다. 그렇지 않다면 데이터 손실이 발생할 수 있다.

- `retries` 옵션을 통해 예외 또는 실패 발생 시 데이터 전송을 재시도 할 수 있다.
  
  - 카프카 버전별로 디폴트 값이 상이함을 유의한다.

#### Producer Timeouts

- 재시도 횟수가 1이상이라면 재시도는 timeouts 이내에서 동작해야 한다.

- timeouts으로 설정된 시간동안의 여러번의 재시도에도 데이터 전송 확인(acknowledments)을 못받는다면 데이터 전송 요청은 실패한다.

### 64. 멱등(idempotent) 프로듀서

- 프로듀서가 네트워크 에러와 같은 이유로 브로커로부터 acks를 못받는다면 데이터 전송이 중복되어 발생할 수 있다.
  
  - 프로듀서가 브로커로 데이터 전송(produce) 후 브로커는 반영(commit)하고 프로듀서에게 ack를 반환하지만, 네트워크 에러로 ack가 반환되지 않는다면, 프로듀서는 재시도(retry)하게 된다. 

#### Idemptent Producer

- 위와 같이 데이터 요청 중복을 방지하기 위해 멱등 프로듀서가 사용된다.

- 어떤 이유로 데이터 전송 요청이 중복되면 카프카의 브로커가 이를 인식하여 전송받은 데이터를 중복으로 커밋하지 않는다.

- 카프카 3.0부터는 멱등 프로듀서의 사용이 기본값이지만 그 이전 버전은 그렇지 않다.
  
  - 카프카의 성능 향상을 위해 사용이 권장되며, `producerProps.put("enable.idempotence", true);`로 설정이 가능하다.

### 67. 카프카 메시지 압축

- 프로듀서는 일반적으로 text-base로 데이터를 전송하는데, 이때 데이터를 압축하는 건 매우 중요하다.

- 압축은 프로듀서 또는 브로커, 토픽 등 다양한 시기에 가능하다.

- `compression.type`에 옵션을 주어 설정할 수 있다. 

- 배치의 크기가 클 수록 압축은 효율적으로 이뤄질 수 있다.
  
  - 배치: 반복적인 데이터를 한번에 묶어 송신하는 메시지 단위

- 압축된 배치(compressed batch)는 아래와 같은 이점이 있다.
  
  - 훨씬 작은 크기의 프로듀서 요청 사이즈
  
  - 네트워크를 통한 전송이 빨라짐
  
  - 많은 처리량과 디스크 사용의 효율

- 단점은 압축에 CPU cycle이 돈다는 점이지만, 매우 미미하다.

- 압축 해제는 컨슈머에 의해서만 이뤄진다.

#### Message Compression at the Broker/ Topic Level

- 메시지 압축은 브로커나 토픽 레벨에서도 가능하다.

- 브로커에서 설정 시 모든 토픽에 적용되며, 토픽의 경우 특정 토픽에 한해서 압축을 적용할 수 있다.

### 68. linger.ms와 batch.size 프로듀서 설정

#### `linger.ms`  & `batch.zise`

- 기본적으로 카프카 프로듀서는 asap으로 레코드를 전송한다.
  
  - `max.in.flight.requests.per.connection=5`라는 옵션은 최대 5개의 메시지 배치들이 프로듀서와 브로커사이에 전송될 수 있다는 의미이다.
  
  - 이때 위 옵션 값보다 더 많은 메시지 레코드를 반드시 보내야 한다면, 카프카는 smart하게 다음 배치(smart batching, 스마트배칭)에 할당한다.

- 스마트 배칭은 처리량을 증가시키고, 매우 낮은 레이턴시를 유지시킨다.
  
  - 2개의 옵션이 배칭 알고리즘에 영향을 준다.
  
  - `linger.ms`: 배치를 전송할때까지 기다리는 시간으로, 해당 시간동안 배치에 메시지를 추가한다.
  
  - `batch.size`: `linger.ms`에서 설정한 시간 전에 배치가 모두 차면, `batch.size`의 값을 증가시킨다.

##### `batch.size`(default: 16KB)

- 배치에 들어갈 수 있는 최대 크기의 바이트 값

- 배치 사이즈를 증가하는것은 압축률, 처리량, 요청의 효율성을 증가하는데 도움을 줄 수 있다.

- 만약 메시지가 배치 사이즈보다 크다면, 해당 메시지는 배치되지 않는다.

- 배치는 각 파티션에 할당되므로 너무 큰 값을 배치사이즈로 지정하면 메모리 유실이 발생하므로 주의한다.

### 69. 위키미디아 프로듀서 처리량 향상 구현

#### High Throughput Producer

- 프로듀서의 처리량 향상을 위해 `snappy` 메시지 압축을 추가한다.

### 70. 프로듀서 디폴트 파티셔너 및 스티키 파티셔너

#### Producer Default Partitioner when key!=null

- 레코드는 프로듀서의 파티셔너 로직에 따라 어떤 파티션에 전송될지 결정된다.
  
  - 이처럼 key와 파티션의 매핑을 결정하는 과정을 Key Hashing이라고 한다.

#### Producer Default Partitioner when key=null

- 키값이 null인 경우 기본값으로 세팅된 파티셔너 로직을 사용한다.
  
  - Round Robin: for Kafka 2.3 and below
  
  - Sticky Partitioner: for Kafka 2.4 and above
    
    - 레코드가 한 배치에 묶어 동일한 파티션으로 전송한다.
    
    - 배치가 모두 다 차거나, `linger.ms`에 설정한 시간이 지나면 현재 고정(stick)된 파티션에 데이터를 전송한다.
    
    - 배치 송신후에는 전송할 다음 파티션으로 변경한다(sticky change)

### 71. max.block.ms & buffer.memory

- 고급 옵션으로 사용되는 설정들로, 만약 브로커가 처리하는 속도보다 프로듀서가 데이터를 전송하는 량이 많을 때 사용한다.
  
  - 이 경우, 프로듀서에는 버퍼 메모리가 쌓인다.

- `buffer.memory`가 32MB로 설정되었고 버퍼 메모리가 모두 찬 후 `.send()`로 데이터를 전송한다면 이를 중단(block)한다.(프로듀서는 동기로 전환된다.)

- `max.block.ms`는 `buffer.memory`에 의해 `.send()` 메서드의 중단이 허용되는 시간이다.
  
  - 중단 시간을 넘기게 되면 프로듀서는 예외를 던진다.

- 예외가 발생한다는 의미는 프로듀서의 메모리가 버퍼가 걸렸거나, 브로커가 응답하지 않거나, 프로듀서의 메시지 송신의 중단이 설정 시간을 초과하였다는 의미로 매우 중대한 의미이다.

## Section 12. OpenSearch 컨슈머 및 고급 컨슈머 구성

### 72. OpenSearch 컨슈머 - 프로젝트 개요

### 79. 컨슈머 전달 의미론

#### Delivery Semantics - At Most Once

- at most once(최대한 한번): 배치를 받자마자 오프셋이 커밋
  
  - 컨슈머가 배치를 받자마자 오프셋에 커밋하지만, 그 순간에 컨슈머 그룹의 컨슈머가 shutdown되어 메시지를 정상적으로 읽지 못한다면 실패한 메시지들은 영원히 읽지 못한다.(배치를 받자마자 커밋하므로 실패한 메시지의 순서는 이미 건너 뛰어짐)

#### Delivery Semantics - At Least Once

- at least once(최소한 한번): 메시지가 처리된 후 최소한 한번 메시지를 커밋한다.
  
  - 오프셋은 메시지가 처리된 후 커밋된다. 처리중 컨슈머 shutdown과 같은 문제가 발생하면 메시지는 커밋된 오프셋부터 다시 읽는다. 중복 처리가 발생할 수 있으므로 메시지 처리과정은 멱등적(메시지를 중복 처리한다해도 시스템에 영향이 없음)이여야 한다.

### 80. OpenSearch 컨슈머 구현 3부 - 멱등(Idempotence)

- 컨슈머에서 멱등이란, 같은 메시지를 2번 보낼때 동일한 메시지로 인식하지 못하고 2번의 다른 요청의 메시지를 읽는 걸 의미한다.
  
  - 멱등한 구성이라면, 같은 메시지를 2번 보낼때 같은 요청으로 정의하여 전송하게 되어 2번의 메시지 전송을 같은 요청으로 간주한다.

- 멱등한 컨슈머를 구현하기 위해서는, 유니크한 값을 id로 할당하여 데이터를 전송한다.
  
  - 브로커는 해당 id로 멱등성을 지킬 수 있다.

### 81. 컨슈머 오프셋 커밋 전략

#### Consumer Offset Commit Strategies

- 2개의 전략이 있다.
  
  - `enable.auto.commit = true` & 배치의 동시 처리(synchronous processing of batches)
  
  - `enable.auto.commit = false` & 오프셋의 수동 커밋

#### Kafka Consumer - Auto Offset Commit Behavior

##### `enable.auto.commit = true` & synchronous processing of batches

- 기본으로 설정되는 최소한 한번(at least once) 읽기 시나리오

- 오프셋은 컨슈머가 `.poll()` 메서드를 호출 하고 `auto.commit.interval.ms`가 초과하면 커밋된다.
  
  - `.poll()`을 호출하면서 `auto.commit.interval.ms=5000`초의 시간이 지나면 커밋한다.

- 동기화 커밋을 사용하지 않으면 최대한 한번 전략을 사용하게 되어 메시지 손실이 발생 할 수 있다.

##### `enable.auto.commit = false` & synchronous processing of batches

- 배치에 `consumer.poll()`로 불러온 데이터를 쌓으면서, 특정 조건을 만족한다면 동기/비동기적으로 커밋한다.
  
  - 오토 커밋이 비활성화 된 상태로, 개발자가 커밋의 타이밍을 결정할 수 있다.

### 84. Consumer Offset Reset Behavior

- 컨슈머의 오프셋 리셋 행동
  
  - `auto.offset.reset = lastest`: 로그의 끝(최신, latest)부터 읽기 시작
  
  - `auto.offset.reset = earliest`: 로그의 처음부터 읽기 시작
  
  - `auto.offset.reset = none`: 오프셋을 못찾으면 예외를 던짐 

- 컨슈머 오프셋은 리센션 기간을 지나면 소멸하게 된다.

## Section 13. 개발자를 위한 카프카 확장 API

### 88. 카프카 확장 API - 개요

- 프로듀서 - 컨슈머로 단순히 메시지를 보내고 읽는 로우레빌이 아니라 여러 Extended API로 다양한 기능을 하이레벨에서 구성할 수 있다.

- Kafka Connect, Kafka Streams, Schema Registry..etc

### 89. Kafka Connect 개요

#### Kafka Connect Introduction

- 카프카 커넥트는 코드와 재사용을 통해 문제를 해결하는 도구이다.

- Kafka가 아닌 다른 소스에서 데이터를 가져오거나, 다른 소스로 데이터를 보낼 때 카프카 커넥트를 사용한다.

##### Kafka Connect - High Level

- Source Connector는 공용 데이터 소스(Common Data Source)에서 데이터를 가져오고

- Sink Connector는 공용 데이터 소스에 데이터를 퍼블리싱한다.

- 경험해보지 못한 개발을 빠르게 수행할 수 있다.

- ETL 파이프라인의 일부이며 스케일링 또한 간편하다.

- Connector들은 장애 감내(fault tolerance), 멱등성(Idempotence), 분배(Distribution), 순서(Odering)이 가능하다.

### 91. Kafka Connect Demo - Wikimedia Flow

- 위키미디아에서 데이터를 가져오는 connector로 카프카에 적재 후,

- 오픈서치로 데이터를 보내는 Sink를 구현

### 92. Kafka Streams 개요

#### Kafka Streams Instroduction

- 카프카 스트림이란, 카프카에 포함된 라이브러리로 데이터 처리(data processing)과 변환(transformation)을 쉽게 할 수 있는 라이브러리이다.

- 구분되는 클러스터를 만들 필요가 없고, 스케일링이 간편하고 유연하며 내구성을 갖는다.

### 94. Kafka Schema Registry 개요

#### The need for a schema registry

- 카프카는 데이터를 byte로 받고 이것들을 퍼블리쉬한다. 이때 데이터 확인은 하지 않는다.
  
  - 만약 프로듀서가 잘못된 데이터를 보낸다면?
  
  - 준비되지 않는 데이터로 인해 역직렬화 과정에서 컨슈머는 에러가 발생한다.

- 예상하지 못한 데이터의 역직렬화로 인한 컨슈머 다운을 방지하기 위해 스키마(schema)와 스키마 저장소(schema regisrty)가 필요하다.

- 스키마 저장소는 컨슈머, 프로듀서와 분리된 구성으로 존재하며, 그들과 통신이 가능해야 한다.
  
  - 사전에 등록된 스키마와 매칭되지 않는 데이터에 대해 거절할 수 있다.
  
  - 공용 데이터 포맷에 대해서는 허용한다.

### 96. 어떤 카프카 API를 쓸까?

![화면 캡처 2024-09-12 225828.png](.\07.png)

## Section 14. 실 사례를 통한 인사이트 얻기(빅데이터/ 빠른 데이터)

### 97. 파티션 수와 복제 계수 정하기

#### Partitions Count & Replication Factor

- 토픽 생성시 가장 중요한 두개의 파라미터

- 시스템의 성능과 지속성에 영향을 끼친다.

##### Choosing the Partitions Count

- 파티션의 개수를 잘 설정하려면 각 파티션의 초당 처리량(보통 MB/s)을 고려해야 한다.
  
  - 많은 파티션은 병렬처리를로 좋은 처리량을 갖는다.
  
  - 동시에 많은 컨슈머를 사용한다.
  
  - 하지만 브로커가 다운되면, 선출과정에 부하가 발생한다.

##### Guidelines

- 해당 과정에서는 직관적으로 브로커가 6개 이하시 브로커 개수\*3/ 12개 이상시 브로커 개수 \* 2 로 산출한다.

##### Choosing the Replication Factor

- 최소 2, 보통 3, 최대 4로 설정한다.

- 복제 계수(Replication Factor, N이라고 하자)가 높을 수록
  
  - 좋은 시스템 지속성(Better durablility of system)을 갖는다.(N-1 개의 브로커는 실패 가능성이 있다.)
  
  - 좋은 시스템 가용성(Better availabaility of system)을 갖는다.(N-`min.insync.replicas`만 큼 가용 가능하다. )
  
  - (kafka 3.0부터는 `acks=all`이 디폴트인 관계로) 많은 복제로 높은 레이턴시가 발생한다.
  
  - 시스템의 디스크를 더 많이 사용한다.

##### Guidelines

- 복제 계수는 3으로 시작하자.

- 레플리카의 성능이 문제라면, 브로커의 개수가 문제이다.

#### Cluster guidelines

- 클러스터 안 파티션 최대치는 
  
  - 주키퍼와 같이 사용시에는 20만개이다.
  
  - KRaft와 사용한다면, 수백만개

- 클러스터에 더 많은 파티션이 필요하다면 브로커를 추가한다.
  
  - 20만개 이상이 필요하다면 netflix 모델을 참고한다.

### 99~104. 사례를 통한 카프카 구성

- 이전에 구현한 어플리케이션의 기능 중, 카프카로 대체하여 효율, 효과적으로 개선할 수 있는 방안은 뭐가 있을까?

#### 빅데이터 적재(Big Data Ingestion)

- 일반적 솔류션들은 데이터 발생지에서 적재지를 연결한다.(카프카 포함)

- 여기서 카프카는 2가지 기능을 추가로 제공하는데
  
  - 실시간 어플리케이션을 위한 '빠른 레이어'(speed layer)
  
  - 데이터분석이나 데이터 스토어 적재를 위한 배치와 같은 '느린 레이어'(slwo layer)

## Section 15. 어드민을 위한 기업에서의 Kafka 가이드

### 105. Kafka 클러스터 구성 상위 아키텍쳐 개요

- 주키퍼와 브로커가 묶인 클러스터를 여러개를 구성한다고 하면, 고려해야 할 사항이 많다.(이게 제일 기본적인 구성)
  
  - AWS에 구성한다면 각 클러스터는 다른 리전에 구성되어야 하고(특정 데이터센터에 몰리지 않기 위해)
  
  - 클러스터에는 주키퍼와 브로커가 각기 다른 서버에서 작동해야 한다.
  
  - 그럼과 동시에 모니터링또한 실시되어야 한다.
  
  - 마지막으로 Kakfa 기능을 활용하여 Kafka 어드민으로서의 역할을 수행해야 한다.(Kakfa as service 로 제품화 된 경우도 있음)

### 106. Kafka 모니터링과 운영

#### Kafka Monitoring and Operation

- 모든 카프카 지표는 JMX를 통해 확인 할 수 있다.

- ELK나 Datadog과 같은 여러 도구에서 JMX에서 확인 가능하다.

##### Kafka monitoring

- 몇개의 중요한 지표는 아래와 같다

- Under Replicated Partitions(URP): ISR(in-sync replicas)에 문제가 있는 파티션 개수, 파티션 싱크가 안되고 있다는 뜻으로 URP가 높다면 시스템 부하가 높다는 뜻이다.

- Request Handlers: IO, network 등의 스레드 사용량, 카프카 브로커의 사용량을 의미한다.

- Request timing: 요청에 걸리는 시간으로 낮을수록 좋으며 레이턴시가 개선된다.

##### Kafka Operations

- 카프카 운영 팀은 아래의 테스트 태스크를 수행해야 한다.
  
  - 브로커들의 롤링 리스타트
  
  - 토픽 및 브로커 설정 업데이트
  
  - 파티션 리밸런싱
  
  - 복제계수 증가, 브로커 관리

### 108. Kafka 멀티 클러스터 및 Mirror Maker

#### Kafka Multi Cluster & Replication

- 카프카 클러스터를 구성할때, 여러개의 클러스터를 각기 다른 리전에 구성가능 하다.

- 컨슈머와 브로커는 같은 리전의 클러스터를 사용한다고 하여도, 다른 리전간의 클러스터끼리 복제(replica)는 가능하다.
  
  - 복제 도구로 사용되는 Mirror Maker2, Flink 등등이 있다.

- 클러스터 구성은 Active/Active, Active/Passive가 있다.

## Section 17. 고급 토픽 구성

### 111. 토픽 구성 변경하기

#### Why should i care about topic configuration?

- 브로커들은 토픽 설정 매개변수가 딸려오는데, 해당 매개변수들은 성능과 토픽 행동에 영향을 끼친다.

### 112. 세그먼트 및 인덱스

#### Partitions and Segments

- 토픽은 파티션들로 구성되고, 파티션들은 세그멘트(segments, 즉 파일)들로 구성된다.

- 각 세그먼트들은 오프셋을 가지며, 마지막 세그멘트는 액티브 세그멘트라고 하여 현재 작성(write)중인 세그멘트로 마지막 오프셋이 정해지지 않은 상태이다.
  
  - 오직 1개의 세그멘트만 Active할 수 있다.

- 관련된 2개 세팅으로
  
  - `log.segment.bytes`: 단일 세그먼트의 최대 바이트 크기(기본 1GB), 1개 세그멘트가 설정값을 넘어가면 새로운 세그멘트가 생성된다.
  
  - `log.segment.ms`: 카프카가 세그멘트가 다 채워지지 않아도 커밋까지 기다리는 시간, 해당 시간이 지나면 카프카는 세그멘트 크기에 무관하게 커밋한다.

- 세그멘트는 2개의 인덱스를 갖는다.
  
  - An offset to position index: 카프카가 메시지를 찾기위해 읽을 곳을 찾게해줌
  
  - A timestamp to offset index: 카프카가 특정 타임스탬프의 메시지를 찾게 해줌

#### Segments: Why should i care?

- 작은 `log.segment.bytes`는
  
  - 파티션단 많은 세그멘트
  
  - 잦은 로그 컴팩션
  
  - 카프카카 많은 파일(세그멘트)를 연 상태를 유지해야한다.
  
  - 처리량에 따라 얼마나 빨리 새로운 세그멘트를 가져야하는지 자문해볼것

- 작은 `log.segment.ms`는 
  
  - 최대 빈도의 로그 컴팩션을 의미함

### 115. 로그 컴팩션 이론

#### Log Cleanup Policy: Compact

- 적어도 파티션에 있는 특정 키의 마지막으로 알려진 값이 포함되어 있다는 의미

- 전체 히스토리 대신 각 키의 최신값으로 스냅샷이 필요할때 유용하다.

- 키에 대한 업데이트 기록만 갖고 있는것이 핵심

- key, value의 쌍이 세그멘트들에 저장된다고 할때,
  
  - a, b, c의 키들과 각 값들이 처음 생성되고
  
  - 추후 세그멘트에서 a, c 키들의 값들이 갱신되면
  
  - 마지막 세그멘트에서는 기존의 키 b와 그 값, 새로운 a, c와 그 값들로 이뤄진다.
  
  - 오프셋을 바꾸는 것이 아닌, 동일한 키가 생성되면 이전의 키의 값들을 삭제한다.

#### Log Compaction Guarantees

- 로그의 꼬리(최신 데이터)를 읽는 어떤 컨슈머든, 여전히 토픽으로 전송된 모든 메시지를 볼 수 있다.

- 메시지들의 순서는 유지되며, 로그 컴팩션은 일부 메시지만 삭제할 뿐이다. 재정렬하지 않는다.

- 메시지의 오프셋은 immutable, 메시지가 사라지면 오프셋은 skip

### 118. 카프카에서 대용량 메시지 전송하기

#### Large Messages in Apache Kafka

- 카프카는 토픽안의 메시지당 1MB 제한이 기본이다.
  
  - 1MB보다 큰 메시지는 비효율적이고 안티 패턴이다

- 대용량 메시지를 보내야할때 2가지 접근법
  
  - 외부 저장소 사용하기: HDFS, S3 와 같은 저장소에 보내고 해당 메시지들의 대한 레퍼런스를 카프카에 전송한다.
  
  - 카프카 매개변수 수정: 브로커의 개수, 프로듀서와 컨슈머의 설정값 변경

#### Option 1: Large Messages using External Store

- 카프카의 바깥쪽에 위치한 저장소에 크기가 큰 메시지를 보내고

- 카프카에는 레퍼런스를 메시지로 보낸다.

- 프로듀서, 컨슈머 레벨에서 코드를 수정하여 레퍼런스를 통하여 저장소의 메시지를 읽어온다

#### Option 2: Sending large messages in Kafka

- Topic-wise, Kafka-side: 메시지의 최대 크기를 10MB로 늘린다.
  
  - Brokers side: `message.max.bytes` 값을 수정
  
  - Topic side: `max.essage.bytes` 값을 수정

- Broker-wise: 레플리카의 fetch 사이즈를 10MB로 설정한다.
  
  - `replica.fetch.max.bytes=10485880`로 변경

- Consumer-side: 컨슈머의 fetch 사이즈를 늘려준다.

- Producer-side: 최대 요청 크기를 늘려준다.

---

- 레퍼런스

> 
