# TIL/Spark

| 폴더이름                                                                                                                              | 요약                                                          |
| --------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------------------- |
| [230105_Spark-with-Python_00](https://github.com/seho27060/TIL/tree/master/Spark/230105_Spark-with-Python_00)                     | 스파크 환경 설정 및 설치                                              |
| [230106_Spark-with-Python_01](https://github.com/seho27060/TIL/tree/master/Spark/230106_Spark-with-Python_01)                     | 스파크3 소개 및 구성                                                |
| [230107_Spark-with-Python_02](https://github.com/seho27060/TIL/tree/master/Spark/230107_Spark-with-Python_02)                     | 스파크3로 실제 데이터 처리해보기 - 기본, RDD                                |
| [230111_Spark-with-Python_03](https://github.com/seho27060/TIL/tree/master/Spark/230111_Spark-with-Python_03)                     | SparkSQL, DataFrames 및 DateSets - DataFrame활용 데이터 처리        |
| [230112_udemy_Spark-프로그램의-고급-예제_01](https://github.com/seho27060/TIL/tree/master/Spark/230112_udemy_Spark-프로그램의-고급-예제_01)         | Broadcast, UDF로 다양한 쿼리 활용하기                                 |
| [230113_udemy_Spark-프로그램의-고급-예제_02](https://github.com/seho27060/TIL/tree/master/Spark/230113_udemy_Spark-프로그램의-고급-예제_02)         | 스파크에서 BFS, 아이템 협업 필터링 구현. .cach()와 .persist()를 통한 데이터프레임 캐싱 |
| [230115_udemy_Spark-클러스터에서 Spark 실행_01](https://github.com/seho27060/TIL/tree/master/Spark/230115_udemy_Spark-클러스터에서 Spark 실행_01) | AWS EMR을 통해 클라우드에서 클러스터를 실행해보자.                             |
| [230117_udemy_Spark-클러스터에서 Spark 실행_02](https://github.com/seho27060/TIL/tree/master/Spark/230117_udemy_Spark-클러스터에서 Spark 실행_02) | 실행중인 클러스터에 스크립트와 데이터를 활용하여 분산 작업을 처리해보자.                    |
